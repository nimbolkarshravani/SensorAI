{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MotionDetection Main NOtebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m_hDpgJsKbE"
      },
      "source": [
        "#take raw data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zXTACpplucX",
        "outputId": "04ff16ad-dc27-4ae5-af8d-af6c4148caad"
      },
      "source": [
        "!wget https://github.com/mmalekzadeh/motion-sense/raw/master/data/A_DeviceMotion_data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-08 15:46:24--  https://github.com/mmalekzadeh/motion-sense/raw/master/data/A_DeviceMotion_data.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mmalekzadeh/motion-sense/master/data/A_DeviceMotion_data.zip [following]\n",
            "--2021-12-08 15:46:24--  https://raw.githubusercontent.com/mmalekzadeh/motion-sense/master/data/A_DeviceMotion_data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 73696396 (70M) [application/zip]\n",
            "Saving to: ‘A_DeviceMotion_data.zip’\n",
            "\n",
            "A_DeviceMotion_data 100%[===================>]  70.28M   193MB/s    in 0.4s    \n",
            "\n",
            "2021-12-08 15:46:54 (193 MB/s) - ‘A_DeviceMotion_data.zip’ saved [73696396/73696396]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAdkDMSdsYWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823b8a71-a7c5-43f3-d0a9-f77151565523"
      },
      "source": [
        "!unzip A_DeviceMotion_data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  A_DeviceMotion_data.zip\n",
            "   creating: A_DeviceMotion_data/\n",
            "   creating: A_DeviceMotion_data/dws_11/\n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_11/sub_23.csv  \n",
            "   creating: A_DeviceMotion_data/ups_12/\n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_12/sub_23.csv  \n",
            "   creating: A_DeviceMotion_data/wlk_7/\n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_13.csv  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/A_DeviceMotion_data/\n",
            "   creating: __MACOSX/A_DeviceMotion_data/wlk_7/\n",
            "  inflating: __MACOSX/A_DeviceMotion_data/wlk_7/._sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_7/sub_23.csv  \n",
            "   creating: A_DeviceMotion_data/std_14/\n",
            "  inflating: A_DeviceMotion_data/std_14/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/std_14/sub_23.csv  \n",
            "   creating: A_DeviceMotion_data/wlk_15/\n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_15/sub_23.csv  \n",
            "   creating: A_DeviceMotion_data/wlk_8/\n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/wlk_8/sub_23.csv  \n",
            "   creating: A_DeviceMotion_data/dws_2/\n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_2/sub_23.csv  \n",
            "   creating: A_DeviceMotion_data/sit_13/\n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_13/sub_23.csv  \n",
            "   creating: A_DeviceMotion_data/jog_9/\n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_4.csv  \n",
            "   creating: __MACOSX/A_DeviceMotion_data/jog_9/\n",
            "  inflating: __MACOSX/A_DeviceMotion_data/jog_9/._sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_5.csv  \n",
            "  inflating: __MACOSX/A_DeviceMotion_data/jog_9/._sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_9/sub_23.csv  \n",
            "   creating: A_DeviceMotion_data/ups_3/\n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_3/sub_23.csv  \n",
            "   creating: A_DeviceMotion_data/ups_4/\n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/ups_4/sub_23.csv  \n",
            "   creating: A_DeviceMotion_data/jog_16/\n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/jog_16/sub_23.csv  \n",
            "   creating: A_DeviceMotion_data/dws_1/\n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_1.csv  \n",
            "   creating: __MACOSX/A_DeviceMotion_data/dws_1/\n",
            "  inflating: __MACOSX/A_DeviceMotion_data/dws_1/._sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/dws_1/sub_23.csv  \n",
            "   creating: A_DeviceMotion_data/sit_5/\n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/sit_5/sub_23.csv  \n",
            "   creating: A_DeviceMotion_data/std_6/\n",
            "  inflating: A_DeviceMotion_data/std_6/sub_12.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_1.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_13.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_11.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_2.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_3.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_10.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_14.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_7.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_6.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_15.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_17.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_4.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_5.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_16.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_8.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_9.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_18.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_24.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_19.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_21.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_20.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_22.csv  \n",
            "  inflating: A_DeviceMotion_data/std_6/sub_23.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjs7oLPHs7Ci"
      },
      "source": [
        "As we can see, there are 15 trials:\n",
        "\n",
        "Long trials: those with number 1 to 9 with around 2 to 3 minutes duration.\n",
        "Short trials: those with number 11 to 16 that are around 30 seconds to 1 minutes duration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP0bE9eDtSnp"
      },
      "source": [
        "Lets look into one of the sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "2YXNATUxscqh",
        "outputId": "aab426f2-768e-4d87-d8ce-ed95c61a4061"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.read_csv(\"/content/A_DeviceMotion_data/dws_1/sub_2.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>attitude.roll</th>\n",
              "      <th>attitude.pitch</th>\n",
              "      <th>attitude.yaw</th>\n",
              "      <th>gravity.x</th>\n",
              "      <th>gravity.y</th>\n",
              "      <th>gravity.z</th>\n",
              "      <th>rotationRate.x</th>\n",
              "      <th>rotationRate.y</th>\n",
              "      <th>rotationRate.z</th>\n",
              "      <th>userAcceleration.x</th>\n",
              "      <th>userAcceleration.y</th>\n",
              "      <th>userAcceleration.z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.469622</td>\n",
              "      <td>-1.105773</td>\n",
              "      <td>-0.183192</td>\n",
              "      <td>0.202940</td>\n",
              "      <td>0.893811</td>\n",
              "      <td>-0.399888</td>\n",
              "      <td>-2.191344</td>\n",
              "      <td>1.836105</td>\n",
              "      <td>-0.723019</td>\n",
              "      <td>-0.232847</td>\n",
              "      <td>-0.688916</td>\n",
              "      <td>0.381181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.515396</td>\n",
              "      <td>-1.156214</td>\n",
              "      <td>-0.173921</td>\n",
              "      <td>0.198531</td>\n",
              "      <td>0.915285</td>\n",
              "      <td>-0.350474</td>\n",
              "      <td>-2.363008</td>\n",
              "      <td>1.904480</td>\n",
              "      <td>-1.155867</td>\n",
              "      <td>-0.057052</td>\n",
              "      <td>-0.607515</td>\n",
              "      <td>0.339946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.557269</td>\n",
              "      <td>-1.211266</td>\n",
              "      <td>-0.162511</td>\n",
              "      <td>0.186069</td>\n",
              "      <td>0.936062</td>\n",
              "      <td>-0.298593</td>\n",
              "      <td>-2.559274</td>\n",
              "      <td>1.177604</td>\n",
              "      <td>-1.169257</td>\n",
              "      <td>0.086240</td>\n",
              "      <td>0.302249</td>\n",
              "      <td>-0.259253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.601952</td>\n",
              "      <td>-1.255618</td>\n",
              "      <td>-0.113787</td>\n",
              "      <td>0.175522</td>\n",
              "      <td>0.950741</td>\n",
              "      <td>-0.255488</td>\n",
              "      <td>-2.081134</td>\n",
              "      <td>-1.058971</td>\n",
              "      <td>-0.112989</td>\n",
              "      <td>0.024963</td>\n",
              "      <td>0.770023</td>\n",
              "      <td>-0.537816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.674214</td>\n",
              "      <td>-1.284314</td>\n",
              "      <td>0.008391</td>\n",
              "      <td>0.176399</td>\n",
              "      <td>0.959244</td>\n",
              "      <td>-0.220738</td>\n",
              "      <td>-2.415788</td>\n",
              "      <td>-2.580961</td>\n",
              "      <td>0.902503</td>\n",
              "      <td>0.011223</td>\n",
              "      <td>0.471664</td>\n",
              "      <td>-0.478298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2139</th>\n",
              "      <td>2139</td>\n",
              "      <td>0.813843</td>\n",
              "      <td>-1.331119</td>\n",
              "      <td>-3.035326</td>\n",
              "      <td>0.172536</td>\n",
              "      <td>0.971415</td>\n",
              "      <td>-0.162989</td>\n",
              "      <td>-0.618365</td>\n",
              "      <td>1.173837</td>\n",
              "      <td>0.650500</td>\n",
              "      <td>-0.266469</td>\n",
              "      <td>-0.316111</td>\n",
              "      <td>-0.055715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2140</th>\n",
              "      <td>2140</td>\n",
              "      <td>0.879379</td>\n",
              "      <td>-1.325529</td>\n",
              "      <td>-2.991277</td>\n",
              "      <td>0.187021</td>\n",
              "      <td>0.970072</td>\n",
              "      <td>-0.154801</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>1.134140</td>\n",
              "      <td>0.469919</td>\n",
              "      <td>-0.140100</td>\n",
              "      <td>-0.555506</td>\n",
              "      <td>0.325486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2141</th>\n",
              "      <td>2141</td>\n",
              "      <td>0.904079</td>\n",
              "      <td>-1.315387</td>\n",
              "      <td>-3.000093</td>\n",
              "      <td>0.198510</td>\n",
              "      <td>0.967560</td>\n",
              "      <td>-0.156212</td>\n",
              "      <td>0.701637</td>\n",
              "      <td>2.030475</td>\n",
              "      <td>0.266585</td>\n",
              "      <td>-0.018349</td>\n",
              "      <td>-0.225571</td>\n",
              "      <td>0.434838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2142</th>\n",
              "      <td>2142</td>\n",
              "      <td>0.901456</td>\n",
              "      <td>-1.301959</td>\n",
              "      <td>-3.041258</td>\n",
              "      <td>0.208272</td>\n",
              "      <td>0.964080</td>\n",
              "      <td>-0.164781</td>\n",
              "      <td>0.824519</td>\n",
              "      <td>1.516910</td>\n",
              "      <td>0.185848</td>\n",
              "      <td>0.049586</td>\n",
              "      <td>0.027970</td>\n",
              "      <td>0.174836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2143</th>\n",
              "      <td>2143</td>\n",
              "      <td>0.938729</td>\n",
              "      <td>-1.307166</td>\n",
              "      <td>-3.012079</td>\n",
              "      <td>0.210215</td>\n",
              "      <td>0.965450</td>\n",
              "      <td>-0.153937</td>\n",
              "      <td>-1.337355</td>\n",
              "      <td>-0.228025</td>\n",
              "      <td>-0.067366</td>\n",
              "      <td>0.843435</td>\n",
              "      <td>0.771397</td>\n",
              "      <td>-1.096795</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2144 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  attitude.roll  ...  userAcceleration.y  userAcceleration.z\n",
              "0              0       0.469622  ...           -0.688916            0.381181\n",
              "1              1       0.515396  ...           -0.607515            0.339946\n",
              "2              2       0.557269  ...            0.302249           -0.259253\n",
              "3              3       0.601952  ...            0.770023           -0.537816\n",
              "4              4       0.674214  ...            0.471664           -0.478298\n",
              "...          ...            ...  ...                 ...                 ...\n",
              "2139        2139       0.813843  ...           -0.316111           -0.055715\n",
              "2140        2140       0.879379  ...           -0.555506            0.325486\n",
              "2141        2141       0.904079  ...           -0.225571            0.434838\n",
              "2142        2142       0.901456  ...            0.027970            0.174836\n",
              "2143        2143       0.938729  ...            0.771397           -1.096795\n",
              "\n",
              "[2144 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amwfa9Uztcts"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7z-NBzc9H1o"
      },
      "source": [
        "#combine all csvs to one csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeMF4Whe9KOy",
        "outputId": "598b44e9-0aed-4295-9166-c0ec0a18d1f3"
      },
      "source": [
        "# Activety types dict:\n",
        "Activety_Types = {'dws':1,'jog':2,'sit':3,'std':4,'ups':5,'wlk':6}        \n",
        "listDict = list(Activety_Types.keys())\n",
        "# Data Folders:\n",
        "from glob import glob\n",
        "Folders = glob('A_DeviceMotion_data/*_*')\n",
        "Df_all_list = []\n",
        "Exp = 0\n",
        "# Segment the data to 400 sampels frames , each one will be a different Expirament\n",
        "Segment_Size = 400\n",
        "# Load All data:\n",
        "for folder  in Folders:\n",
        "    Csvs = glob(folder + '/*' )\n",
        "    print(Csvs)\n",
        "    for csv in Csvs:\n",
        "        df = pd.read_csv(csv)\n",
        "        # Add Activety label, Subject name and Experiment number\n",
        "        df['Activity'] = Activety_Types[folder[20:23]]\n",
        "        #df['Sub_Num'] = csv[len(folder)+5:-4]\n",
        "        ExpNum = np.zeros((df.shape[0])) \n",
        "        for i in range(0,df.shape[0]-Segment_Size,Segment_Size):\n",
        "            ExpNum[range(i,i+Segment_Size)] = Exp\n",
        "            Exp+=1 \n",
        "        df['Exp_num'] = ExpNum\n",
        "        df=df[df['Exp_num']!=0]\n",
        "        Df_all_list.append(df)       \n",
        "\n",
        "Df_all = pd.concat(Df_all_list,axis=0)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A_DeviceMotion_data/ups_3/sub_18.csv', 'A_DeviceMotion_data/ups_3/sub_1.csv', 'A_DeviceMotion_data/ups_3/sub_13.csv', 'A_DeviceMotion_data/ups_3/sub_22.csv', 'A_DeviceMotion_data/ups_3/sub_5.csv', 'A_DeviceMotion_data/ups_3/sub_21.csv', 'A_DeviceMotion_data/ups_3/sub_17.csv', 'A_DeviceMotion_data/ups_3/sub_14.csv', 'A_DeviceMotion_data/ups_3/sub_20.csv', 'A_DeviceMotion_data/ups_3/sub_19.csv', 'A_DeviceMotion_data/ups_3/sub_9.csv', 'A_DeviceMotion_data/ups_3/sub_10.csv', 'A_DeviceMotion_data/ups_3/sub_11.csv', 'A_DeviceMotion_data/ups_3/sub_4.csv', 'A_DeviceMotion_data/ups_3/sub_6.csv', 'A_DeviceMotion_data/ups_3/sub_2.csv', 'A_DeviceMotion_data/ups_3/sub_8.csv', 'A_DeviceMotion_data/ups_3/sub_23.csv', 'A_DeviceMotion_data/ups_3/sub_16.csv', 'A_DeviceMotion_data/ups_3/sub_12.csv', 'A_DeviceMotion_data/ups_3/sub_24.csv', 'A_DeviceMotion_data/ups_3/sub_3.csv', 'A_DeviceMotion_data/ups_3/sub_15.csv', 'A_DeviceMotion_data/ups_3/sub_7.csv']\n",
            "['A_DeviceMotion_data/jog_16/sub_18.csv', 'A_DeviceMotion_data/jog_16/sub_1.csv', 'A_DeviceMotion_data/jog_16/sub_13.csv', 'A_DeviceMotion_data/jog_16/sub_22.csv', 'A_DeviceMotion_data/jog_16/sub_5.csv', 'A_DeviceMotion_data/jog_16/sub_21.csv', 'A_DeviceMotion_data/jog_16/sub_17.csv', 'A_DeviceMotion_data/jog_16/sub_14.csv', 'A_DeviceMotion_data/jog_16/sub_20.csv', 'A_DeviceMotion_data/jog_16/sub_19.csv', 'A_DeviceMotion_data/jog_16/sub_9.csv', 'A_DeviceMotion_data/jog_16/sub_10.csv', 'A_DeviceMotion_data/jog_16/sub_11.csv', 'A_DeviceMotion_data/jog_16/sub_4.csv', 'A_DeviceMotion_data/jog_16/sub_6.csv', 'A_DeviceMotion_data/jog_16/sub_2.csv', 'A_DeviceMotion_data/jog_16/sub_8.csv', 'A_DeviceMotion_data/jog_16/sub_23.csv', 'A_DeviceMotion_data/jog_16/sub_16.csv', 'A_DeviceMotion_data/jog_16/sub_12.csv', 'A_DeviceMotion_data/jog_16/sub_24.csv', 'A_DeviceMotion_data/jog_16/sub_3.csv', 'A_DeviceMotion_data/jog_16/sub_15.csv', 'A_DeviceMotion_data/jog_16/sub_7.csv']\n",
            "['A_DeviceMotion_data/dws_1/sub_18.csv', 'A_DeviceMotion_data/dws_1/sub_1.csv', 'A_DeviceMotion_data/dws_1/sub_13.csv', 'A_DeviceMotion_data/dws_1/sub_22.csv', 'A_DeviceMotion_data/dws_1/sub_5.csv', 'A_DeviceMotion_data/dws_1/sub_21.csv', 'A_DeviceMotion_data/dws_1/sub_17.csv', 'A_DeviceMotion_data/dws_1/sub_14.csv', 'A_DeviceMotion_data/dws_1/sub_20.csv', 'A_DeviceMotion_data/dws_1/sub_19.csv', 'A_DeviceMotion_data/dws_1/sub_9.csv', 'A_DeviceMotion_data/dws_1/sub_10.csv', 'A_DeviceMotion_data/dws_1/sub_11.csv', 'A_DeviceMotion_data/dws_1/sub_4.csv', 'A_DeviceMotion_data/dws_1/sub_6.csv', 'A_DeviceMotion_data/dws_1/sub_2.csv', 'A_DeviceMotion_data/dws_1/sub_8.csv', 'A_DeviceMotion_data/dws_1/sub_23.csv', 'A_DeviceMotion_data/dws_1/sub_16.csv', 'A_DeviceMotion_data/dws_1/sub_12.csv', 'A_DeviceMotion_data/dws_1/sub_24.csv', 'A_DeviceMotion_data/dws_1/sub_3.csv', 'A_DeviceMotion_data/dws_1/sub_15.csv', 'A_DeviceMotion_data/dws_1/sub_7.csv']\n",
            "['A_DeviceMotion_data/wlk_15/sub_18.csv', 'A_DeviceMotion_data/wlk_15/sub_1.csv', 'A_DeviceMotion_data/wlk_15/sub_13.csv', 'A_DeviceMotion_data/wlk_15/sub_22.csv', 'A_DeviceMotion_data/wlk_15/sub_5.csv', 'A_DeviceMotion_data/wlk_15/sub_21.csv', 'A_DeviceMotion_data/wlk_15/sub_17.csv', 'A_DeviceMotion_data/wlk_15/sub_14.csv', 'A_DeviceMotion_data/wlk_15/sub_20.csv', 'A_DeviceMotion_data/wlk_15/sub_19.csv', 'A_DeviceMotion_data/wlk_15/sub_9.csv', 'A_DeviceMotion_data/wlk_15/sub_10.csv', 'A_DeviceMotion_data/wlk_15/sub_11.csv', 'A_DeviceMotion_data/wlk_15/sub_4.csv', 'A_DeviceMotion_data/wlk_15/sub_6.csv', 'A_DeviceMotion_data/wlk_15/sub_2.csv', 'A_DeviceMotion_data/wlk_15/sub_8.csv', 'A_DeviceMotion_data/wlk_15/sub_23.csv', 'A_DeviceMotion_data/wlk_15/sub_16.csv', 'A_DeviceMotion_data/wlk_15/sub_12.csv', 'A_DeviceMotion_data/wlk_15/sub_24.csv', 'A_DeviceMotion_data/wlk_15/sub_3.csv', 'A_DeviceMotion_data/wlk_15/sub_15.csv', 'A_DeviceMotion_data/wlk_15/sub_7.csv']\n",
            "['A_DeviceMotion_data/std_14/sub_18.csv', 'A_DeviceMotion_data/std_14/sub_1.csv', 'A_DeviceMotion_data/std_14/sub_13.csv', 'A_DeviceMotion_data/std_14/sub_22.csv', 'A_DeviceMotion_data/std_14/sub_5.csv', 'A_DeviceMotion_data/std_14/sub_21.csv', 'A_DeviceMotion_data/std_14/sub_17.csv', 'A_DeviceMotion_data/std_14/sub_14.csv', 'A_DeviceMotion_data/std_14/sub_20.csv', 'A_DeviceMotion_data/std_14/sub_19.csv', 'A_DeviceMotion_data/std_14/sub_9.csv', 'A_DeviceMotion_data/std_14/sub_10.csv', 'A_DeviceMotion_data/std_14/sub_11.csv', 'A_DeviceMotion_data/std_14/sub_4.csv', 'A_DeviceMotion_data/std_14/sub_6.csv', 'A_DeviceMotion_data/std_14/sub_2.csv', 'A_DeviceMotion_data/std_14/sub_8.csv', 'A_DeviceMotion_data/std_14/sub_23.csv', 'A_DeviceMotion_data/std_14/sub_16.csv', 'A_DeviceMotion_data/std_14/sub_12.csv', 'A_DeviceMotion_data/std_14/sub_24.csv', 'A_DeviceMotion_data/std_14/sub_3.csv', 'A_DeviceMotion_data/std_14/sub_15.csv', 'A_DeviceMotion_data/std_14/sub_7.csv']\n",
            "['A_DeviceMotion_data/sit_5/sub_18.csv', 'A_DeviceMotion_data/sit_5/sub_1.csv', 'A_DeviceMotion_data/sit_5/sub_13.csv', 'A_DeviceMotion_data/sit_5/sub_22.csv', 'A_DeviceMotion_data/sit_5/sub_5.csv', 'A_DeviceMotion_data/sit_5/sub_21.csv', 'A_DeviceMotion_data/sit_5/sub_17.csv', 'A_DeviceMotion_data/sit_5/sub_14.csv', 'A_DeviceMotion_data/sit_5/sub_20.csv', 'A_DeviceMotion_data/sit_5/sub_19.csv', 'A_DeviceMotion_data/sit_5/sub_9.csv', 'A_DeviceMotion_data/sit_5/sub_10.csv', 'A_DeviceMotion_data/sit_5/sub_11.csv', 'A_DeviceMotion_data/sit_5/sub_4.csv', 'A_DeviceMotion_data/sit_5/sub_6.csv', 'A_DeviceMotion_data/sit_5/sub_2.csv', 'A_DeviceMotion_data/sit_5/sub_8.csv', 'A_DeviceMotion_data/sit_5/sub_23.csv', 'A_DeviceMotion_data/sit_5/sub_16.csv', 'A_DeviceMotion_data/sit_5/sub_12.csv', 'A_DeviceMotion_data/sit_5/sub_24.csv', 'A_DeviceMotion_data/sit_5/sub_3.csv', 'A_DeviceMotion_data/sit_5/sub_15.csv', 'A_DeviceMotion_data/sit_5/sub_7.csv']\n",
            "['A_DeviceMotion_data/dws_2/sub_18.csv', 'A_DeviceMotion_data/dws_2/sub_1.csv', 'A_DeviceMotion_data/dws_2/sub_13.csv', 'A_DeviceMotion_data/dws_2/sub_22.csv', 'A_DeviceMotion_data/dws_2/sub_5.csv', 'A_DeviceMotion_data/dws_2/sub_21.csv', 'A_DeviceMotion_data/dws_2/sub_17.csv', 'A_DeviceMotion_data/dws_2/sub_14.csv', 'A_DeviceMotion_data/dws_2/sub_20.csv', 'A_DeviceMotion_data/dws_2/sub_19.csv', 'A_DeviceMotion_data/dws_2/sub_9.csv', 'A_DeviceMotion_data/dws_2/sub_10.csv', 'A_DeviceMotion_data/dws_2/sub_11.csv', 'A_DeviceMotion_data/dws_2/sub_4.csv', 'A_DeviceMotion_data/dws_2/sub_6.csv', 'A_DeviceMotion_data/dws_2/sub_2.csv', 'A_DeviceMotion_data/dws_2/sub_8.csv', 'A_DeviceMotion_data/dws_2/sub_23.csv', 'A_DeviceMotion_data/dws_2/sub_16.csv', 'A_DeviceMotion_data/dws_2/sub_12.csv', 'A_DeviceMotion_data/dws_2/sub_24.csv', 'A_DeviceMotion_data/dws_2/sub_3.csv', 'A_DeviceMotion_data/dws_2/sub_15.csv', 'A_DeviceMotion_data/dws_2/sub_7.csv']\n",
            "['A_DeviceMotion_data/dws_11/sub_18.csv', 'A_DeviceMotion_data/dws_11/sub_1.csv', 'A_DeviceMotion_data/dws_11/sub_13.csv', 'A_DeviceMotion_data/dws_11/sub_22.csv', 'A_DeviceMotion_data/dws_11/sub_5.csv', 'A_DeviceMotion_data/dws_11/sub_21.csv', 'A_DeviceMotion_data/dws_11/sub_17.csv', 'A_DeviceMotion_data/dws_11/sub_14.csv', 'A_DeviceMotion_data/dws_11/sub_20.csv', 'A_DeviceMotion_data/dws_11/sub_19.csv', 'A_DeviceMotion_data/dws_11/sub_9.csv', 'A_DeviceMotion_data/dws_11/sub_10.csv', 'A_DeviceMotion_data/dws_11/sub_11.csv', 'A_DeviceMotion_data/dws_11/sub_4.csv', 'A_DeviceMotion_data/dws_11/sub_6.csv', 'A_DeviceMotion_data/dws_11/sub_2.csv', 'A_DeviceMotion_data/dws_11/sub_8.csv', 'A_DeviceMotion_data/dws_11/sub_23.csv', 'A_DeviceMotion_data/dws_11/sub_16.csv', 'A_DeviceMotion_data/dws_11/sub_12.csv', 'A_DeviceMotion_data/dws_11/sub_24.csv', 'A_DeviceMotion_data/dws_11/sub_3.csv', 'A_DeviceMotion_data/dws_11/sub_15.csv', 'A_DeviceMotion_data/dws_11/sub_7.csv']\n",
            "['A_DeviceMotion_data/wlk_8/sub_18.csv', 'A_DeviceMotion_data/wlk_8/sub_1.csv', 'A_DeviceMotion_data/wlk_8/sub_13.csv', 'A_DeviceMotion_data/wlk_8/sub_22.csv', 'A_DeviceMotion_data/wlk_8/sub_5.csv', 'A_DeviceMotion_data/wlk_8/sub_21.csv', 'A_DeviceMotion_data/wlk_8/sub_17.csv', 'A_DeviceMotion_data/wlk_8/sub_14.csv', 'A_DeviceMotion_data/wlk_8/sub_20.csv', 'A_DeviceMotion_data/wlk_8/sub_19.csv', 'A_DeviceMotion_data/wlk_8/sub_9.csv', 'A_DeviceMotion_data/wlk_8/sub_10.csv', 'A_DeviceMotion_data/wlk_8/sub_11.csv', 'A_DeviceMotion_data/wlk_8/sub_4.csv', 'A_DeviceMotion_data/wlk_8/sub_6.csv', 'A_DeviceMotion_data/wlk_8/sub_2.csv', 'A_DeviceMotion_data/wlk_8/sub_8.csv', 'A_DeviceMotion_data/wlk_8/sub_23.csv', 'A_DeviceMotion_data/wlk_8/sub_16.csv', 'A_DeviceMotion_data/wlk_8/sub_12.csv', 'A_DeviceMotion_data/wlk_8/sub_24.csv', 'A_DeviceMotion_data/wlk_8/sub_3.csv', 'A_DeviceMotion_data/wlk_8/sub_15.csv', 'A_DeviceMotion_data/wlk_8/sub_7.csv']\n",
            "['A_DeviceMotion_data/sit_13/sub_18.csv', 'A_DeviceMotion_data/sit_13/sub_1.csv', 'A_DeviceMotion_data/sit_13/sub_13.csv', 'A_DeviceMotion_data/sit_13/sub_22.csv', 'A_DeviceMotion_data/sit_13/sub_5.csv', 'A_DeviceMotion_data/sit_13/sub_21.csv', 'A_DeviceMotion_data/sit_13/sub_17.csv', 'A_DeviceMotion_data/sit_13/sub_14.csv', 'A_DeviceMotion_data/sit_13/sub_20.csv', 'A_DeviceMotion_data/sit_13/sub_19.csv', 'A_DeviceMotion_data/sit_13/sub_9.csv', 'A_DeviceMotion_data/sit_13/sub_10.csv', 'A_DeviceMotion_data/sit_13/sub_11.csv', 'A_DeviceMotion_data/sit_13/sub_4.csv', 'A_DeviceMotion_data/sit_13/sub_6.csv', 'A_DeviceMotion_data/sit_13/sub_2.csv', 'A_DeviceMotion_data/sit_13/sub_8.csv', 'A_DeviceMotion_data/sit_13/sub_23.csv', 'A_DeviceMotion_data/sit_13/sub_16.csv', 'A_DeviceMotion_data/sit_13/sub_12.csv', 'A_DeviceMotion_data/sit_13/sub_24.csv', 'A_DeviceMotion_data/sit_13/sub_3.csv', 'A_DeviceMotion_data/sit_13/sub_15.csv', 'A_DeviceMotion_data/sit_13/sub_7.csv']\n",
            "['A_DeviceMotion_data/wlk_7/sub_18.csv', 'A_DeviceMotion_data/wlk_7/sub_1.csv', 'A_DeviceMotion_data/wlk_7/sub_13.csv', 'A_DeviceMotion_data/wlk_7/sub_22.csv', 'A_DeviceMotion_data/wlk_7/sub_5.csv', 'A_DeviceMotion_data/wlk_7/sub_21.csv', 'A_DeviceMotion_data/wlk_7/sub_17.csv', 'A_DeviceMotion_data/wlk_7/sub_14.csv', 'A_DeviceMotion_data/wlk_7/sub_20.csv', 'A_DeviceMotion_data/wlk_7/sub_19.csv', 'A_DeviceMotion_data/wlk_7/sub_9.csv', 'A_DeviceMotion_data/wlk_7/sub_10.csv', 'A_DeviceMotion_data/wlk_7/sub_11.csv', 'A_DeviceMotion_data/wlk_7/sub_4.csv', 'A_DeviceMotion_data/wlk_7/sub_6.csv', 'A_DeviceMotion_data/wlk_7/sub_2.csv', 'A_DeviceMotion_data/wlk_7/sub_8.csv', 'A_DeviceMotion_data/wlk_7/sub_23.csv', 'A_DeviceMotion_data/wlk_7/sub_16.csv', 'A_DeviceMotion_data/wlk_7/sub_12.csv', 'A_DeviceMotion_data/wlk_7/sub_24.csv', 'A_DeviceMotion_data/wlk_7/sub_3.csv', 'A_DeviceMotion_data/wlk_7/sub_15.csv', 'A_DeviceMotion_data/wlk_7/sub_7.csv']\n",
            "['A_DeviceMotion_data/ups_4/sub_18.csv', 'A_DeviceMotion_data/ups_4/sub_1.csv', 'A_DeviceMotion_data/ups_4/sub_13.csv', 'A_DeviceMotion_data/ups_4/sub_22.csv', 'A_DeviceMotion_data/ups_4/sub_5.csv', 'A_DeviceMotion_data/ups_4/sub_21.csv', 'A_DeviceMotion_data/ups_4/sub_17.csv', 'A_DeviceMotion_data/ups_4/sub_14.csv', 'A_DeviceMotion_data/ups_4/sub_20.csv', 'A_DeviceMotion_data/ups_4/sub_19.csv', 'A_DeviceMotion_data/ups_4/sub_9.csv', 'A_DeviceMotion_data/ups_4/sub_10.csv', 'A_DeviceMotion_data/ups_4/sub_11.csv', 'A_DeviceMotion_data/ups_4/sub_4.csv', 'A_DeviceMotion_data/ups_4/sub_6.csv', 'A_DeviceMotion_data/ups_4/sub_2.csv', 'A_DeviceMotion_data/ups_4/sub_8.csv', 'A_DeviceMotion_data/ups_4/sub_23.csv', 'A_DeviceMotion_data/ups_4/sub_16.csv', 'A_DeviceMotion_data/ups_4/sub_12.csv', 'A_DeviceMotion_data/ups_4/sub_24.csv', 'A_DeviceMotion_data/ups_4/sub_3.csv', 'A_DeviceMotion_data/ups_4/sub_15.csv', 'A_DeviceMotion_data/ups_4/sub_7.csv']\n",
            "['A_DeviceMotion_data/std_6/sub_18.csv', 'A_DeviceMotion_data/std_6/sub_1.csv', 'A_DeviceMotion_data/std_6/sub_13.csv', 'A_DeviceMotion_data/std_6/sub_22.csv', 'A_DeviceMotion_data/std_6/sub_5.csv', 'A_DeviceMotion_data/std_6/sub_21.csv', 'A_DeviceMotion_data/std_6/sub_17.csv', 'A_DeviceMotion_data/std_6/sub_14.csv', 'A_DeviceMotion_data/std_6/sub_20.csv', 'A_DeviceMotion_data/std_6/sub_19.csv', 'A_DeviceMotion_data/std_6/sub_9.csv', 'A_DeviceMotion_data/std_6/sub_10.csv', 'A_DeviceMotion_data/std_6/sub_11.csv', 'A_DeviceMotion_data/std_6/sub_4.csv', 'A_DeviceMotion_data/std_6/sub_6.csv', 'A_DeviceMotion_data/std_6/sub_2.csv', 'A_DeviceMotion_data/std_6/sub_8.csv', 'A_DeviceMotion_data/std_6/sub_23.csv', 'A_DeviceMotion_data/std_6/sub_16.csv', 'A_DeviceMotion_data/std_6/sub_12.csv', 'A_DeviceMotion_data/std_6/sub_24.csv', 'A_DeviceMotion_data/std_6/sub_3.csv', 'A_DeviceMotion_data/std_6/sub_15.csv', 'A_DeviceMotion_data/std_6/sub_7.csv']\n",
            "['A_DeviceMotion_data/jog_9/sub_18.csv', 'A_DeviceMotion_data/jog_9/sub_1.csv', 'A_DeviceMotion_data/jog_9/sub_13.csv', 'A_DeviceMotion_data/jog_9/sub_22.csv', 'A_DeviceMotion_data/jog_9/sub_5.csv', 'A_DeviceMotion_data/jog_9/sub_21.csv', 'A_DeviceMotion_data/jog_9/sub_17.csv', 'A_DeviceMotion_data/jog_9/sub_14.csv', 'A_DeviceMotion_data/jog_9/sub_20.csv', 'A_DeviceMotion_data/jog_9/sub_19.csv', 'A_DeviceMotion_data/jog_9/sub_9.csv', 'A_DeviceMotion_data/jog_9/sub_10.csv', 'A_DeviceMotion_data/jog_9/sub_11.csv', 'A_DeviceMotion_data/jog_9/sub_4.csv', 'A_DeviceMotion_data/jog_9/sub_6.csv', 'A_DeviceMotion_data/jog_9/sub_2.csv', 'A_DeviceMotion_data/jog_9/sub_8.csv', 'A_DeviceMotion_data/jog_9/sub_23.csv', 'A_DeviceMotion_data/jog_9/sub_16.csv', 'A_DeviceMotion_data/jog_9/sub_12.csv', 'A_DeviceMotion_data/jog_9/sub_24.csv', 'A_DeviceMotion_data/jog_9/sub_3.csv', 'A_DeviceMotion_data/jog_9/sub_15.csv', 'A_DeviceMotion_data/jog_9/sub_7.csv']\n",
            "['A_DeviceMotion_data/ups_12/sub_18.csv', 'A_DeviceMotion_data/ups_12/sub_1.csv', 'A_DeviceMotion_data/ups_12/sub_13.csv', 'A_DeviceMotion_data/ups_12/sub_22.csv', 'A_DeviceMotion_data/ups_12/sub_5.csv', 'A_DeviceMotion_data/ups_12/sub_21.csv', 'A_DeviceMotion_data/ups_12/sub_17.csv', 'A_DeviceMotion_data/ups_12/sub_14.csv', 'A_DeviceMotion_data/ups_12/sub_20.csv', 'A_DeviceMotion_data/ups_12/sub_19.csv', 'A_DeviceMotion_data/ups_12/sub_9.csv', 'A_DeviceMotion_data/ups_12/sub_10.csv', 'A_DeviceMotion_data/ups_12/sub_11.csv', 'A_DeviceMotion_data/ups_12/sub_4.csv', 'A_DeviceMotion_data/ups_12/sub_6.csv', 'A_DeviceMotion_data/ups_12/sub_2.csv', 'A_DeviceMotion_data/ups_12/sub_8.csv', 'A_DeviceMotion_data/ups_12/sub_23.csv', 'A_DeviceMotion_data/ups_12/sub_16.csv', 'A_DeviceMotion_data/ups_12/sub_12.csv', 'A_DeviceMotion_data/ups_12/sub_24.csv', 'A_DeviceMotion_data/ups_12/sub_3.csv', 'A_DeviceMotion_data/ups_12/sub_15.csv', 'A_DeviceMotion_data/ups_12/sub_7.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqpLocwSu0wi",
        "outputId": "e5edbfc5-7f9f-4615-9d96-c056a5e422e0"
      },
      "source": [
        "len(Folders)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "yokAkXsZ9T7O",
        "outputId": "375b8efb-3018-48b0-b7e4-1249f6516f52"
      },
      "source": [
        "Df_all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>attitude.roll</th>\n",
              "      <th>attitude.pitch</th>\n",
              "      <th>attitude.yaw</th>\n",
              "      <th>gravity.x</th>\n",
              "      <th>gravity.y</th>\n",
              "      <th>gravity.z</th>\n",
              "      <th>rotationRate.x</th>\n",
              "      <th>rotationRate.y</th>\n",
              "      <th>rotationRate.z</th>\n",
              "      <th>userAcceleration.x</th>\n",
              "      <th>userAcceleration.y</th>\n",
              "      <th>userAcceleration.z</th>\n",
              "      <th>Activity</th>\n",
              "      <th>Exp_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>400</td>\n",
              "      <td>-1.657295</td>\n",
              "      <td>-1.469802</td>\n",
              "      <td>-2.033190</td>\n",
              "      <td>-0.100415</td>\n",
              "      <td>0.994904</td>\n",
              "      <td>0.008708</td>\n",
              "      <td>-0.772317</td>\n",
              "      <td>-0.095979</td>\n",
              "      <td>0.175448</td>\n",
              "      <td>-0.025562</td>\n",
              "      <td>-0.076051</td>\n",
              "      <td>-0.093272</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>401</td>\n",
              "      <td>-1.822499</td>\n",
              "      <td>-1.468313</td>\n",
              "      <td>-2.198956</td>\n",
              "      <td>-0.099049</td>\n",
              "      <td>0.994753</td>\n",
              "      <td>0.025471</td>\n",
              "      <td>-0.865902</td>\n",
              "      <td>0.040314</td>\n",
              "      <td>0.005840</td>\n",
              "      <td>0.062657</td>\n",
              "      <td>-0.099093</td>\n",
              "      <td>-0.121769</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>402</td>\n",
              "      <td>-1.958603</td>\n",
              "      <td>-1.460929</td>\n",
              "      <td>-2.338076</td>\n",
              "      <td>-0.101476</td>\n",
              "      <td>0.993971</td>\n",
              "      <td>0.041452</td>\n",
              "      <td>-0.768465</td>\n",
              "      <td>0.167499</td>\n",
              "      <td>-0.182717</td>\n",
              "      <td>0.094915</td>\n",
              "      <td>-0.088377</td>\n",
              "      <td>-0.126261</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>403</td>\n",
              "      <td>-2.051936</td>\n",
              "      <td>-1.450599</td>\n",
              "      <td>-2.437153</td>\n",
              "      <td>-0.106270</td>\n",
              "      <td>0.992785</td>\n",
              "      <td>0.055480</td>\n",
              "      <td>-0.736745</td>\n",
              "      <td>0.281613</td>\n",
              "      <td>-0.242463</td>\n",
              "      <td>0.087655</td>\n",
              "      <td>-0.059206</td>\n",
              "      <td>-0.125273</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>404</td>\n",
              "      <td>-2.133176</td>\n",
              "      <td>-1.438758</td>\n",
              "      <td>-2.524887</td>\n",
              "      <td>-0.111356</td>\n",
              "      <td>0.991296</td>\n",
              "      <td>0.070185</td>\n",
              "      <td>-0.769635</td>\n",
              "      <td>0.321148</td>\n",
              "      <td>-0.243811</td>\n",
              "      <td>-0.024508</td>\n",
              "      <td>0.005805</td>\n",
              "      <td>-0.135584</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1195</td>\n",
              "      <td>1.024323</td>\n",
              "      <td>-1.211499</td>\n",
              "      <td>-2.276536</td>\n",
              "      <td>0.300405</td>\n",
              "      <td>0.936144</td>\n",
              "      <td>-0.182726</td>\n",
              "      <td>0.883836</td>\n",
              "      <td>-1.477110</td>\n",
              "      <td>1.093226</td>\n",
              "      <td>-0.106558</td>\n",
              "      <td>-0.244814</td>\n",
              "      <td>0.077745</td>\n",
              "      <td>5</td>\n",
              "      <td>3358.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1196</td>\n",
              "      <td>0.981764</td>\n",
              "      <td>-1.181092</td>\n",
              "      <td>-2.291272</td>\n",
              "      <td>0.315889</td>\n",
              "      <td>0.925021</td>\n",
              "      <td>-0.211063</td>\n",
              "      <td>1.158976</td>\n",
              "      <td>-1.447401</td>\n",
              "      <td>1.150658</td>\n",
              "      <td>-0.159731</td>\n",
              "      <td>-0.253665</td>\n",
              "      <td>0.020466</td>\n",
              "      <td>5</td>\n",
              "      <td>3358.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1197</td>\n",
              "      <td>0.933343</td>\n",
              "      <td>-1.147542</td>\n",
              "      <td>-2.309318</td>\n",
              "      <td>0.330066</td>\n",
              "      <td>0.911757</td>\n",
              "      <td>-0.244445</td>\n",
              "      <td>1.268669</td>\n",
              "      <td>-1.677025</td>\n",
              "      <td>1.202993</td>\n",
              "      <td>-0.164356</td>\n",
              "      <td>-0.247451</td>\n",
              "      <td>0.060363</td>\n",
              "      <td>5</td>\n",
              "      <td>3358.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1198</td>\n",
              "      <td>0.895885</td>\n",
              "      <td>-1.110927</td>\n",
              "      <td>-2.315204</td>\n",
              "      <td>0.346525</td>\n",
              "      <td>0.896110</td>\n",
              "      <td>-0.277317</td>\n",
              "      <td>1.190342</td>\n",
              "      <td>-1.490413</td>\n",
              "      <td>1.489558</td>\n",
              "      <td>-0.123304</td>\n",
              "      <td>-0.165596</td>\n",
              "      <td>0.138538</td>\n",
              "      <td>5</td>\n",
              "      <td>3358.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1199</td>\n",
              "      <td>0.875638</td>\n",
              "      <td>-1.071878</td>\n",
              "      <td>-2.309792</td>\n",
              "      <td>0.367445</td>\n",
              "      <td>0.878101</td>\n",
              "      <td>-0.306466</td>\n",
              "      <td>1.085830</td>\n",
              "      <td>-1.132562</td>\n",
              "      <td>1.600533</td>\n",
              "      <td>-0.129027</td>\n",
              "      <td>-0.251377</td>\n",
              "      <td>0.180063</td>\n",
              "      <td>5</td>\n",
              "      <td>3358.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1343200 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  attitude.roll  ...  Activity  Exp_num\n",
              "400          400      -1.657295  ...         5      1.0\n",
              "401          401      -1.822499  ...         5      1.0\n",
              "402          402      -1.958603  ...         5      1.0\n",
              "403          403      -2.051936  ...         5      1.0\n",
              "404          404      -2.133176  ...         5      1.0\n",
              "...          ...            ...  ...       ...      ...\n",
              "1195        1195       1.024323  ...         5   3358.0\n",
              "1196        1196       0.981764  ...         5   3358.0\n",
              "1197        1197       0.933343  ...         5   3358.0\n",
              "1198        1198       0.895885  ...         5   3358.0\n",
              "1199        1199       0.875638  ...         5   3358.0\n",
              "\n",
              "[1343200 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sckecsj_EDp",
        "outputId": "28c1540d-f38d-40ba-d355-455761f28377"
      },
      "source": [
        "#sanity check to ensure that total_exp_num*400==rows_in_df\n",
        "print((Df_all[\"Exp_num\"].value_counts()==400 ).all())\n",
        "len(Df_all[\"Exp_num\"].value_counts())*400"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1343200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxgkhc33EiAd"
      },
      "source": [
        "#remove sensor features not accessible by js "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "N7WjPt0c-_Kl",
        "outputId": "73172c46-c453-4f04-b519-1b30499e7c4b"
      },
      "source": [
        "Df_all=Df_all.drop(['attitude.roll', 'attitude.pitch','attitude.yaw'],1)\n",
        "Df_all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>gravity.x</th>\n",
              "      <th>gravity.y</th>\n",
              "      <th>gravity.z</th>\n",
              "      <th>rotationRate.x</th>\n",
              "      <th>rotationRate.y</th>\n",
              "      <th>rotationRate.z</th>\n",
              "      <th>userAcceleration.x</th>\n",
              "      <th>userAcceleration.y</th>\n",
              "      <th>userAcceleration.z</th>\n",
              "      <th>Activity</th>\n",
              "      <th>Exp_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>400</td>\n",
              "      <td>-0.100415</td>\n",
              "      <td>0.994904</td>\n",
              "      <td>0.008708</td>\n",
              "      <td>-0.772317</td>\n",
              "      <td>-0.095979</td>\n",
              "      <td>0.175448</td>\n",
              "      <td>-0.025562</td>\n",
              "      <td>-0.076051</td>\n",
              "      <td>-0.093272</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>401</td>\n",
              "      <td>-0.099049</td>\n",
              "      <td>0.994753</td>\n",
              "      <td>0.025471</td>\n",
              "      <td>-0.865902</td>\n",
              "      <td>0.040314</td>\n",
              "      <td>0.005840</td>\n",
              "      <td>0.062657</td>\n",
              "      <td>-0.099093</td>\n",
              "      <td>-0.121769</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>402</td>\n",
              "      <td>-0.101476</td>\n",
              "      <td>0.993971</td>\n",
              "      <td>0.041452</td>\n",
              "      <td>-0.768465</td>\n",
              "      <td>0.167499</td>\n",
              "      <td>-0.182717</td>\n",
              "      <td>0.094915</td>\n",
              "      <td>-0.088377</td>\n",
              "      <td>-0.126261</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>403</td>\n",
              "      <td>-0.106270</td>\n",
              "      <td>0.992785</td>\n",
              "      <td>0.055480</td>\n",
              "      <td>-0.736745</td>\n",
              "      <td>0.281613</td>\n",
              "      <td>-0.242463</td>\n",
              "      <td>0.087655</td>\n",
              "      <td>-0.059206</td>\n",
              "      <td>-0.125273</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>404</td>\n",
              "      <td>-0.111356</td>\n",
              "      <td>0.991296</td>\n",
              "      <td>0.070185</td>\n",
              "      <td>-0.769635</td>\n",
              "      <td>0.321148</td>\n",
              "      <td>-0.243811</td>\n",
              "      <td>-0.024508</td>\n",
              "      <td>0.005805</td>\n",
              "      <td>-0.135584</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1195</td>\n",
              "      <td>0.300405</td>\n",
              "      <td>0.936144</td>\n",
              "      <td>-0.182726</td>\n",
              "      <td>0.883836</td>\n",
              "      <td>-1.477110</td>\n",
              "      <td>1.093226</td>\n",
              "      <td>-0.106558</td>\n",
              "      <td>-0.244814</td>\n",
              "      <td>0.077745</td>\n",
              "      <td>5</td>\n",
              "      <td>3358.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1196</td>\n",
              "      <td>0.315889</td>\n",
              "      <td>0.925021</td>\n",
              "      <td>-0.211063</td>\n",
              "      <td>1.158976</td>\n",
              "      <td>-1.447401</td>\n",
              "      <td>1.150658</td>\n",
              "      <td>-0.159731</td>\n",
              "      <td>-0.253665</td>\n",
              "      <td>0.020466</td>\n",
              "      <td>5</td>\n",
              "      <td>3358.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1197</td>\n",
              "      <td>0.330066</td>\n",
              "      <td>0.911757</td>\n",
              "      <td>-0.244445</td>\n",
              "      <td>1.268669</td>\n",
              "      <td>-1.677025</td>\n",
              "      <td>1.202993</td>\n",
              "      <td>-0.164356</td>\n",
              "      <td>-0.247451</td>\n",
              "      <td>0.060363</td>\n",
              "      <td>5</td>\n",
              "      <td>3358.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1198</td>\n",
              "      <td>0.346525</td>\n",
              "      <td>0.896110</td>\n",
              "      <td>-0.277317</td>\n",
              "      <td>1.190342</td>\n",
              "      <td>-1.490413</td>\n",
              "      <td>1.489558</td>\n",
              "      <td>-0.123304</td>\n",
              "      <td>-0.165596</td>\n",
              "      <td>0.138538</td>\n",
              "      <td>5</td>\n",
              "      <td>3358.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1199</td>\n",
              "      <td>0.367445</td>\n",
              "      <td>0.878101</td>\n",
              "      <td>-0.306466</td>\n",
              "      <td>1.085830</td>\n",
              "      <td>-1.132562</td>\n",
              "      <td>1.600533</td>\n",
              "      <td>-0.129027</td>\n",
              "      <td>-0.251377</td>\n",
              "      <td>0.180063</td>\n",
              "      <td>5</td>\n",
              "      <td>3358.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1343200 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  gravity.x  gravity.y  ...  userAcceleration.z  Activity  Exp_num\n",
              "400          400  -0.100415   0.994904  ...           -0.093272         5      1.0\n",
              "401          401  -0.099049   0.994753  ...           -0.121769         5      1.0\n",
              "402          402  -0.101476   0.993971  ...           -0.126261         5      1.0\n",
              "403          403  -0.106270   0.992785  ...           -0.125273         5      1.0\n",
              "404          404  -0.111356   0.991296  ...           -0.135584         5      1.0\n",
              "...          ...        ...        ...  ...                 ...       ...      ...\n",
              "1195        1195   0.300405   0.936144  ...            0.077745         5   3358.0\n",
              "1196        1196   0.315889   0.925021  ...            0.020466         5   3358.0\n",
              "1197        1197   0.330066   0.911757  ...            0.060363         5   3358.0\n",
              "1198        1198   0.346525   0.896110  ...            0.138538         5   3358.0\n",
              "1199        1199   0.367445   0.878101  ...            0.180063         5   3358.0\n",
              "\n",
              "[1343200 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eIpiYAfzN4L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49wBbtkbKlyP"
      },
      "source": [
        "Drop gravity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA_Nac3rKnlP"
      },
      "source": [
        "#Df_all=Df_all.drop([\"gravity.x\",\"gravity.y\",\"gravity.z\",\"rotationRate.x\",\"rotationRate.y\",\"rotationRate.z\"],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79sVvNjiE6_o"
      },
      "source": [
        "#Extract features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrR3_W4DE4w6"
      },
      "source": [
        "df_sum = Df_all.groupby('Exp_num', axis=0).mean().reset_index()#mean not SUM\n",
        "df_sum.columns = df_sum.columns.str.replace('.','_sum_')\n",
        "\n",
        "#df_sum_SS = np.power(Df_all.astype(float),2).groupby('Exp_num', axis=0).median().reset_index() # median of squares \n",
        "#df_sum_SS.columns = df_sum_SS.columns.str.replace('.','_sumSS_')\n",
        "\n",
        "df_max = Df_all.groupby('Exp_num', axis=0).max().reset_index()\n",
        "df_max.columns = df_max.columns.str.replace('.','_max_')\n",
        "\n",
        "df_min = Df_all.groupby('Exp_num', axis=0).min().reset_index()\n",
        "df_min.columns = df_min.columns.str.replace('.','_min_')\n",
        "\n",
        "df_skew = Df_all.groupby('Exp_num', axis=0).skew().reset_index()\n",
        "df_skew.columns = df_skew.columns.str.replace('.','_skew_')\n",
        "\n",
        "df_std = Df_all.groupby('Exp_num', axis=0).std().reset_index()\n",
        "df_std.columns = df_std.columns.str.replace('.','_std_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxbsVvBi0p5C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUGCugxVFuhT",
        "outputId": "d0d622bf-3068-4152-e6ea-36c929b52b03"
      },
      "source": [
        "df_sum.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Exp_num', 'Unnamed: 0', 'gravity_sum_x', 'gravity_sum_y',\n",
              "       'gravity_sum_z', 'rotationRate_sum_x', 'rotationRate_sum_y',\n",
              "       'rotationRate_sum_z', 'userAcceleration_sum_x',\n",
              "       'userAcceleration_sum_y', 'userAcceleration_sum_z', 'Activity'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Stl9C_1FMUC"
      },
      "source": [
        "#combine features to single df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JVA6jPcFF15"
      },
      "source": [
        "Df_Features = pd.concat([ df_max , df_sum, \n",
        "                         df_min,# df_sum_SS, \n",
        "                         df_std, df_skew], axis=1)\n",
        "# Features\n",
        "Df_Features_1 = Df_Features.drop(['Exp_num','Unnamed: 0','Activity'],axis=1)\n",
        "Labels = df_max[\"Activity\"]#pd.get_dummies(df_max['Activity'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "i0O1-CuXF99N",
        "outputId": "93466f7a-70d8-48b5-ad57-2a862530c7b4"
      },
      "source": [
        "Df_Features_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gravity_max_x</th>\n",
              "      <th>gravity_max_y</th>\n",
              "      <th>gravity_max_z</th>\n",
              "      <th>rotationRate_max_x</th>\n",
              "      <th>rotationRate_max_y</th>\n",
              "      <th>rotationRate_max_z</th>\n",
              "      <th>userAcceleration_max_x</th>\n",
              "      <th>userAcceleration_max_y</th>\n",
              "      <th>userAcceleration_max_z</th>\n",
              "      <th>gravity_sum_x</th>\n",
              "      <th>gravity_sum_y</th>\n",
              "      <th>gravity_sum_z</th>\n",
              "      <th>rotationRate_sum_x</th>\n",
              "      <th>rotationRate_sum_y</th>\n",
              "      <th>rotationRate_sum_z</th>\n",
              "      <th>userAcceleration_sum_x</th>\n",
              "      <th>userAcceleration_sum_y</th>\n",
              "      <th>userAcceleration_sum_z</th>\n",
              "      <th>gravity_min_x</th>\n",
              "      <th>gravity_min_y</th>\n",
              "      <th>gravity_min_z</th>\n",
              "      <th>rotationRate_min_x</th>\n",
              "      <th>rotationRate_min_y</th>\n",
              "      <th>rotationRate_min_z</th>\n",
              "      <th>userAcceleration_min_x</th>\n",
              "      <th>userAcceleration_min_y</th>\n",
              "      <th>userAcceleration_min_z</th>\n",
              "      <th>gravity_std_x</th>\n",
              "      <th>gravity_std_y</th>\n",
              "      <th>gravity_std_z</th>\n",
              "      <th>rotationRate_std_x</th>\n",
              "      <th>rotationRate_std_y</th>\n",
              "      <th>rotationRate_std_z</th>\n",
              "      <th>userAcceleration_std_x</th>\n",
              "      <th>userAcceleration_std_y</th>\n",
              "      <th>userAcceleration_std_z</th>\n",
              "      <th>gravity_skew_x</th>\n",
              "      <th>gravity_skew_y</th>\n",
              "      <th>gravity_skew_z</th>\n",
              "      <th>rotationRate_skew_x</th>\n",
              "      <th>rotationRate_skew_y</th>\n",
              "      <th>rotationRate_skew_z</th>\n",
              "      <th>userAcceleration_skew_x</th>\n",
              "      <th>userAcceleration_skew_y</th>\n",
              "      <th>userAcceleration_skew_z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000429</td>\n",
              "      <td>0.999994</td>\n",
              "      <td>0.110238</td>\n",
              "      <td>2.090501</td>\n",
              "      <td>1.603431</td>\n",
              "      <td>0.832833</td>\n",
              "      <td>0.377211</td>\n",
              "      <td>1.324886</td>\n",
              "      <td>0.634577</td>\n",
              "      <td>-0.112480</td>\n",
              "      <td>0.966630</td>\n",
              "      <td>-0.159818</td>\n",
              "      <td>0.022561</td>\n",
              "      <td>0.041188</td>\n",
              "      <td>0.028994</td>\n",
              "      <td>0.017273</td>\n",
              "      <td>0.025495</td>\n",
              "      <td>0.071220</td>\n",
              "      <td>-0.226191</td>\n",
              "      <td>0.891816</td>\n",
              "      <td>-0.404558</td>\n",
              "      <td>-1.265925</td>\n",
              "      <td>-1.519571</td>\n",
              "      <td>-0.945641</td>\n",
              "      <td>-0.532938</td>\n",
              "      <td>-0.567793</td>\n",
              "      <td>-0.424605</td>\n",
              "      <td>0.058887</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.151391</td>\n",
              "      <td>0.882560</td>\n",
              "      <td>0.463168</td>\n",
              "      <td>0.372646</td>\n",
              "      <td>0.123934</td>\n",
              "      <td>0.283940</td>\n",
              "      <td>0.158105</td>\n",
              "      <td>0.033894</td>\n",
              "      <td>-0.788101</td>\n",
              "      <td>0.032659</td>\n",
              "      <td>0.570982</td>\n",
              "      <td>-0.006615</td>\n",
              "      <td>-0.180977</td>\n",
              "      <td>-0.817339</td>\n",
              "      <td>1.204200</td>\n",
              "      <td>0.191379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.078044</td>\n",
              "      <td>0.999961</td>\n",
              "      <td>0.223307</td>\n",
              "      <td>2.078723</td>\n",
              "      <td>2.319320</td>\n",
              "      <td>0.905562</td>\n",
              "      <td>0.332426</td>\n",
              "      <td>0.976779</td>\n",
              "      <td>0.532986</td>\n",
              "      <td>-0.050655</td>\n",
              "      <td>0.982689</td>\n",
              "      <td>-0.065722</td>\n",
              "      <td>-0.004225</td>\n",
              "      <td>0.438282</td>\n",
              "      <td>0.002157</td>\n",
              "      <td>-0.045212</td>\n",
              "      <td>0.008023</td>\n",
              "      <td>-0.029645</td>\n",
              "      <td>-0.207342</td>\n",
              "      <td>0.928015</td>\n",
              "      <td>-0.324298</td>\n",
              "      <td>-1.140827</td>\n",
              "      <td>-0.653351</td>\n",
              "      <td>-0.824146</td>\n",
              "      <td>-0.709399</td>\n",
              "      <td>-0.490435</td>\n",
              "      <td>-0.475458</td>\n",
              "      <td>0.076815</td>\n",
              "      <td>0.019042</td>\n",
              "      <td>0.145740</td>\n",
              "      <td>0.825633</td>\n",
              "      <td>0.641367</td>\n",
              "      <td>0.384540</td>\n",
              "      <td>0.138828</td>\n",
              "      <td>0.234485</td>\n",
              "      <td>0.144311</td>\n",
              "      <td>-0.262908</td>\n",
              "      <td>-1.207322</td>\n",
              "      <td>-0.097961</td>\n",
              "      <td>0.752290</td>\n",
              "      <td>0.683046</td>\n",
              "      <td>-0.133736</td>\n",
              "      <td>-1.437771</td>\n",
              "      <td>1.114276</td>\n",
              "      <td>0.156520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.004626</td>\n",
              "      <td>0.999766</td>\n",
              "      <td>0.089838</td>\n",
              "      <td>1.947281</td>\n",
              "      <td>2.435517</td>\n",
              "      <td>0.757099</td>\n",
              "      <td>0.391830</td>\n",
              "      <td>0.914462</td>\n",
              "      <td>0.592273</td>\n",
              "      <td>-0.127156</td>\n",
              "      <td>0.969631</td>\n",
              "      <td>-0.132329</td>\n",
              "      <td>-0.020450</td>\n",
              "      <td>0.306552</td>\n",
              "      <td>0.023626</td>\n",
              "      <td>0.010796</td>\n",
              "      <td>0.008240</td>\n",
              "      <td>0.027060</td>\n",
              "      <td>-0.254742</td>\n",
              "      <td>0.895021</td>\n",
              "      <td>-0.382264</td>\n",
              "      <td>-1.303084</td>\n",
              "      <td>-1.053098</td>\n",
              "      <td>-0.956010</td>\n",
              "      <td>-0.638237</td>\n",
              "      <td>-0.450981</td>\n",
              "      <td>-0.573945</td>\n",
              "      <td>0.068318</td>\n",
              "      <td>0.033530</td>\n",
              "      <td>0.142837</td>\n",
              "      <td>0.803937</td>\n",
              "      <td>0.648194</td>\n",
              "      <td>0.420260</td>\n",
              "      <td>0.126181</td>\n",
              "      <td>0.235373</td>\n",
              "      <td>0.144240</td>\n",
              "      <td>-0.078092</td>\n",
              "      <td>-0.907649</td>\n",
              "      <td>-0.301217</td>\n",
              "      <td>0.621242</td>\n",
              "      <td>0.915147</td>\n",
              "      <td>-0.202231</td>\n",
              "      <td>-1.274557</td>\n",
              "      <td>1.030537</td>\n",
              "      <td>-0.465451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.031238</td>\n",
              "      <td>0.999967</td>\n",
              "      <td>0.147023</td>\n",
              "      <td>1.834258</td>\n",
              "      <td>1.978075</td>\n",
              "      <td>0.735999</td>\n",
              "      <td>0.309147</td>\n",
              "      <td>0.786638</td>\n",
              "      <td>0.391305</td>\n",
              "      <td>-0.090226</td>\n",
              "      <td>0.975951</td>\n",
              "      <td>-0.104667</td>\n",
              "      <td>0.021190</td>\n",
              "      <td>0.391350</td>\n",
              "      <td>-0.040642</td>\n",
              "      <td>-0.037119</td>\n",
              "      <td>0.016059</td>\n",
              "      <td>-0.002408</td>\n",
              "      <td>-0.243513</td>\n",
              "      <td>0.882789</td>\n",
              "      <td>-0.403518</td>\n",
              "      <td>-1.097577</td>\n",
              "      <td>-0.694958</td>\n",
              "      <td>-1.018665</td>\n",
              "      <td>-0.600454</td>\n",
              "      <td>-0.496501</td>\n",
              "      <td>-0.489351</td>\n",
              "      <td>0.078543</td>\n",
              "      <td>0.028896</td>\n",
              "      <td>0.146586</td>\n",
              "      <td>0.808617</td>\n",
              "      <td>0.542754</td>\n",
              "      <td>0.406946</td>\n",
              "      <td>0.129404</td>\n",
              "      <td>0.225972</td>\n",
              "      <td>0.135613</td>\n",
              "      <td>-0.237860</td>\n",
              "      <td>-1.437148</td>\n",
              "      <td>-0.163121</td>\n",
              "      <td>0.746894</td>\n",
              "      <td>0.726951</td>\n",
              "      <td>-0.209633</td>\n",
              "      <td>-1.321456</td>\n",
              "      <td>0.889641</td>\n",
              "      <td>-0.496985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.026873</td>\n",
              "      <td>0.999832</td>\n",
              "      <td>0.145571</td>\n",
              "      <td>1.928876</td>\n",
              "      <td>2.267244</td>\n",
              "      <td>0.756117</td>\n",
              "      <td>0.291181</td>\n",
              "      <td>1.230035</td>\n",
              "      <td>0.674568</td>\n",
              "      <td>-0.118194</td>\n",
              "      <td>0.972552</td>\n",
              "      <td>-0.104095</td>\n",
              "      <td>-0.031709</td>\n",
              "      <td>0.385806</td>\n",
              "      <td>0.009342</td>\n",
              "      <td>-0.016269</td>\n",
              "      <td>0.008219</td>\n",
              "      <td>-0.017715</td>\n",
              "      <td>-0.277357</td>\n",
              "      <td>0.894542</td>\n",
              "      <td>-0.374809</td>\n",
              "      <td>-1.168579</td>\n",
              "      <td>-0.884106</td>\n",
              "      <td>-0.898270</td>\n",
              "      <td>-0.633793</td>\n",
              "      <td>-0.486475</td>\n",
              "      <td>-0.552400</td>\n",
              "      <td>0.076309</td>\n",
              "      <td>0.028592</td>\n",
              "      <td>0.150890</td>\n",
              "      <td>0.790383</td>\n",
              "      <td>0.624054</td>\n",
              "      <td>0.412224</td>\n",
              "      <td>0.125712</td>\n",
              "      <td>0.253970</td>\n",
              "      <td>0.151216</td>\n",
              "      <td>0.023333</td>\n",
              "      <td>-0.961641</td>\n",
              "      <td>-0.066300</td>\n",
              "      <td>0.703676</td>\n",
              "      <td>0.933546</td>\n",
              "      <td>-0.256429</td>\n",
              "      <td>-1.450020</td>\n",
              "      <td>1.660179</td>\n",
              "      <td>0.061378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3353</th>\n",
              "      <td>0.504743</td>\n",
              "      <td>0.999438</td>\n",
              "      <td>0.359144</td>\n",
              "      <td>6.478538</td>\n",
              "      <td>4.655244</td>\n",
              "      <td>2.442333</td>\n",
              "      <td>0.993554</td>\n",
              "      <td>1.922272</td>\n",
              "      <td>1.730681</td>\n",
              "      <td>-0.049764</td>\n",
              "      <td>0.887220</td>\n",
              "      <td>-0.266792</td>\n",
              "      <td>0.127582</td>\n",
              "      <td>0.672636</td>\n",
              "      <td>-0.101083</td>\n",
              "      <td>-0.076524</td>\n",
              "      <td>0.031826</td>\n",
              "      <td>-0.008726</td>\n",
              "      <td>-0.578652</td>\n",
              "      <td>0.481345</td>\n",
              "      <td>-0.666042</td>\n",
              "      <td>-3.044744</td>\n",
              "      <td>-4.394538</td>\n",
              "      <td>-3.192693</td>\n",
              "      <td>-1.145613</td>\n",
              "      <td>-1.395230</td>\n",
              "      <td>-1.269927</td>\n",
              "      <td>0.208170</td>\n",
              "      <td>0.110161</td>\n",
              "      <td>0.289922</td>\n",
              "      <td>2.143808</td>\n",
              "      <td>1.654642</td>\n",
              "      <td>1.065543</td>\n",
              "      <td>0.273190</td>\n",
              "      <td>0.577900</td>\n",
              "      <td>0.380353</td>\n",
              "      <td>0.055904</td>\n",
              "      <td>-1.459920</td>\n",
              "      <td>0.508085</td>\n",
              "      <td>0.790299</td>\n",
              "      <td>-0.110069</td>\n",
              "      <td>-0.279998</td>\n",
              "      <td>-0.358255</td>\n",
              "      <td>0.305541</td>\n",
              "      <td>0.066554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3354</th>\n",
              "      <td>0.387688</td>\n",
              "      <td>0.999990</td>\n",
              "      <td>0.205182</td>\n",
              "      <td>5.057985</td>\n",
              "      <td>4.710542</td>\n",
              "      <td>1.960430</td>\n",
              "      <td>0.567546</td>\n",
              "      <td>1.617881</td>\n",
              "      <td>1.024322</td>\n",
              "      <td>-0.095614</td>\n",
              "      <td>0.834230</td>\n",
              "      <td>-0.384524</td>\n",
              "      <td>0.049412</td>\n",
              "      <td>0.427980</td>\n",
              "      <td>-0.014155</td>\n",
              "      <td>-0.003680</td>\n",
              "      <td>0.074278</td>\n",
              "      <td>0.109654</td>\n",
              "      <td>-0.503259</td>\n",
              "      <td>0.418579</td>\n",
              "      <td>-0.795185</td>\n",
              "      <td>-2.765968</td>\n",
              "      <td>-4.438360</td>\n",
              "      <td>-2.467041</td>\n",
              "      <td>-0.806027</td>\n",
              "      <td>-0.842341</td>\n",
              "      <td>-1.200072</td>\n",
              "      <td>0.212644</td>\n",
              "      <td>0.157913</td>\n",
              "      <td>0.277969</td>\n",
              "      <td>2.100168</td>\n",
              "      <td>1.430208</td>\n",
              "      <td>0.872063</td>\n",
              "      <td>0.216565</td>\n",
              "      <td>0.473915</td>\n",
              "      <td>0.339354</td>\n",
              "      <td>0.336459</td>\n",
              "      <td>-0.980673</td>\n",
              "      <td>0.365275</td>\n",
              "      <td>0.693694</td>\n",
              "      <td>-0.106495</td>\n",
              "      <td>-0.168431</td>\n",
              "      <td>-0.474319</td>\n",
              "      <td>0.399960</td>\n",
              "      <td>-0.336559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3355</th>\n",
              "      <td>0.460589</td>\n",
              "      <td>0.998442</td>\n",
              "      <td>0.252124</td>\n",
              "      <td>2.705108</td>\n",
              "      <td>3.347442</td>\n",
              "      <td>2.102437</td>\n",
              "      <td>0.692583</td>\n",
              "      <td>1.053557</td>\n",
              "      <td>0.466842</td>\n",
              "      <td>0.179514</td>\n",
              "      <td>0.954295</td>\n",
              "      <td>-0.038175</td>\n",
              "      <td>0.017552</td>\n",
              "      <td>0.375124</td>\n",
              "      <td>0.015418</td>\n",
              "      <td>-0.046538</td>\n",
              "      <td>0.011334</td>\n",
              "      <td>-0.015819</td>\n",
              "      <td>-0.111560</td>\n",
              "      <td>0.807563</td>\n",
              "      <td>-0.371944</td>\n",
              "      <td>-1.524104</td>\n",
              "      <td>-1.680035</td>\n",
              "      <td>-1.844906</td>\n",
              "      <td>-1.098000</td>\n",
              "      <td>-0.595277</td>\n",
              "      <td>-0.805170</td>\n",
              "      <td>0.142949</td>\n",
              "      <td>0.049865</td>\n",
              "      <td>0.181242</td>\n",
              "      <td>0.906431</td>\n",
              "      <td>0.861575</td>\n",
              "      <td>0.909611</td>\n",
              "      <td>0.206497</td>\n",
              "      <td>0.262500</td>\n",
              "      <td>0.140660</td>\n",
              "      <td>0.317025</td>\n",
              "      <td>-1.439422</td>\n",
              "      <td>-0.102200</td>\n",
              "      <td>0.540236</td>\n",
              "      <td>0.631908</td>\n",
              "      <td>0.222315</td>\n",
              "      <td>-0.878347</td>\n",
              "      <td>0.933871</td>\n",
              "      <td>-1.069737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3356</th>\n",
              "      <td>0.502553</td>\n",
              "      <td>0.999327</td>\n",
              "      <td>0.248331</td>\n",
              "      <td>2.513858</td>\n",
              "      <td>2.970547</td>\n",
              "      <td>2.242588</td>\n",
              "      <td>0.522967</td>\n",
              "      <td>1.138693</td>\n",
              "      <td>0.371182</td>\n",
              "      <td>0.180726</td>\n",
              "      <td>0.947569</td>\n",
              "      <td>-0.060306</td>\n",
              "      <td>0.031966</td>\n",
              "      <td>0.391918</td>\n",
              "      <td>0.025237</td>\n",
              "      <td>-0.009955</td>\n",
              "      <td>0.023866</td>\n",
              "      <td>-0.004181</td>\n",
              "      <td>-0.054874</td>\n",
              "      <td>0.765213</td>\n",
              "      <td>-0.448346</td>\n",
              "      <td>-1.840441</td>\n",
              "      <td>-2.012918</td>\n",
              "      <td>-2.053387</td>\n",
              "      <td>-0.690403</td>\n",
              "      <td>-0.449313</td>\n",
              "      <td>-0.459457</td>\n",
              "      <td>0.158033</td>\n",
              "      <td>0.063193</td>\n",
              "      <td>0.192372</td>\n",
              "      <td>0.965284</td>\n",
              "      <td>0.813172</td>\n",
              "      <td>0.951326</td>\n",
              "      <td>0.189748</td>\n",
              "      <td>0.263612</td>\n",
              "      <td>0.115420</td>\n",
              "      <td>0.375625</td>\n",
              "      <td>-1.395739</td>\n",
              "      <td>-0.362497</td>\n",
              "      <td>0.638323</td>\n",
              "      <td>0.165097</td>\n",
              "      <td>0.295183</td>\n",
              "      <td>-0.605589</td>\n",
              "      <td>1.192888</td>\n",
              "      <td>-0.235505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3357</th>\n",
              "      <td>0.482841</td>\n",
              "      <td>0.996959</td>\n",
              "      <td>0.290104</td>\n",
              "      <td>2.376766</td>\n",
              "      <td>2.640168</td>\n",
              "      <td>2.261015</td>\n",
              "      <td>0.523204</td>\n",
              "      <td>0.919621</td>\n",
              "      <td>0.363755</td>\n",
              "      <td>0.207829</td>\n",
              "      <td>0.947966</td>\n",
              "      <td>-0.037399</td>\n",
              "      <td>0.088508</td>\n",
              "      <td>0.353318</td>\n",
              "      <td>0.086717</td>\n",
              "      <td>-0.044499</td>\n",
              "      <td>0.018809</td>\n",
              "      <td>-0.016729</td>\n",
              "      <td>-0.078663</td>\n",
              "      <td>0.786706</td>\n",
              "      <td>-0.424952</td>\n",
              "      <td>-1.669332</td>\n",
              "      <td>-1.677025</td>\n",
              "      <td>-2.317634</td>\n",
              "      <td>-0.717791</td>\n",
              "      <td>-0.404146</td>\n",
              "      <td>-0.600297</td>\n",
              "      <td>0.136934</td>\n",
              "      <td>0.057381</td>\n",
              "      <td>0.186716</td>\n",
              "      <td>0.938439</td>\n",
              "      <td>0.821689</td>\n",
              "      <td>0.922838</td>\n",
              "      <td>0.188558</td>\n",
              "      <td>0.247777</td>\n",
              "      <td>0.127774</td>\n",
              "      <td>0.425219</td>\n",
              "      <td>-1.531435</td>\n",
              "      <td>-0.267531</td>\n",
              "      <td>0.473414</td>\n",
              "      <td>0.153339</td>\n",
              "      <td>0.219912</td>\n",
              "      <td>-0.478588</td>\n",
              "      <td>0.924369</td>\n",
              "      <td>-0.491625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3358 rows × 45 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gravity_max_x  ...  userAcceleration_skew_z\n",
              "0          0.000429  ...                 0.191379\n",
              "1          0.078044  ...                 0.156520\n",
              "2          0.004626  ...                -0.465451\n",
              "3          0.031238  ...                -0.496985\n",
              "4          0.026873  ...                 0.061378\n",
              "...             ...  ...                      ...\n",
              "3353       0.504743  ...                 0.066554\n",
              "3354       0.387688  ...                -0.336559\n",
              "3355       0.460589  ...                -1.069737\n",
              "3356       0.502553  ...                -0.235505\n",
              "3357       0.482841  ...                -0.491625\n",
              "\n",
              "[3358 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC817D-0HVsx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxwcwpGrNOc5"
      },
      "source": [
        "#plot graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "arWsnuXq3SvV",
        "outputId": "8f2ed862-8601-46ee-a293-93bed886620e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "Df_plot=pd.concat([Df_Features_1,Labels],1)\n",
        "Df_plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gravity_max_x</th>\n",
              "      <th>gravity_max_y</th>\n",
              "      <th>gravity_max_z</th>\n",
              "      <th>rotationRate_max_x</th>\n",
              "      <th>rotationRate_max_y</th>\n",
              "      <th>rotationRate_max_z</th>\n",
              "      <th>userAcceleration_max_x</th>\n",
              "      <th>userAcceleration_max_y</th>\n",
              "      <th>userAcceleration_max_z</th>\n",
              "      <th>gravity_sum_x</th>\n",
              "      <th>gravity_sum_y</th>\n",
              "      <th>gravity_sum_z</th>\n",
              "      <th>rotationRate_sum_x</th>\n",
              "      <th>rotationRate_sum_y</th>\n",
              "      <th>rotationRate_sum_z</th>\n",
              "      <th>userAcceleration_sum_x</th>\n",
              "      <th>userAcceleration_sum_y</th>\n",
              "      <th>userAcceleration_sum_z</th>\n",
              "      <th>gravity_min_x</th>\n",
              "      <th>gravity_min_y</th>\n",
              "      <th>gravity_min_z</th>\n",
              "      <th>rotationRate_min_x</th>\n",
              "      <th>rotationRate_min_y</th>\n",
              "      <th>rotationRate_min_z</th>\n",
              "      <th>userAcceleration_min_x</th>\n",
              "      <th>userAcceleration_min_y</th>\n",
              "      <th>userAcceleration_min_z</th>\n",
              "      <th>gravity_std_x</th>\n",
              "      <th>gravity_std_y</th>\n",
              "      <th>gravity_std_z</th>\n",
              "      <th>rotationRate_std_x</th>\n",
              "      <th>rotationRate_std_y</th>\n",
              "      <th>rotationRate_std_z</th>\n",
              "      <th>userAcceleration_std_x</th>\n",
              "      <th>userAcceleration_std_y</th>\n",
              "      <th>userAcceleration_std_z</th>\n",
              "      <th>gravity_skew_x</th>\n",
              "      <th>gravity_skew_y</th>\n",
              "      <th>gravity_skew_z</th>\n",
              "      <th>rotationRate_skew_x</th>\n",
              "      <th>rotationRate_skew_y</th>\n",
              "      <th>rotationRate_skew_z</th>\n",
              "      <th>userAcceleration_skew_x</th>\n",
              "      <th>userAcceleration_skew_y</th>\n",
              "      <th>userAcceleration_skew_z</th>\n",
              "      <th>Activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000429</td>\n",
              "      <td>0.999994</td>\n",
              "      <td>0.110238</td>\n",
              "      <td>2.090501</td>\n",
              "      <td>1.603431</td>\n",
              "      <td>0.832833</td>\n",
              "      <td>0.377211</td>\n",
              "      <td>1.324886</td>\n",
              "      <td>0.634577</td>\n",
              "      <td>-0.112480</td>\n",
              "      <td>0.966630</td>\n",
              "      <td>-0.159818</td>\n",
              "      <td>0.022561</td>\n",
              "      <td>0.041188</td>\n",
              "      <td>0.028994</td>\n",
              "      <td>0.017273</td>\n",
              "      <td>0.025495</td>\n",
              "      <td>0.071220</td>\n",
              "      <td>-0.226191</td>\n",
              "      <td>0.891816</td>\n",
              "      <td>-0.404558</td>\n",
              "      <td>-1.265925</td>\n",
              "      <td>-1.519571</td>\n",
              "      <td>-0.945641</td>\n",
              "      <td>-0.532938</td>\n",
              "      <td>-0.567793</td>\n",
              "      <td>-0.424605</td>\n",
              "      <td>0.058887</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.151391</td>\n",
              "      <td>0.882560</td>\n",
              "      <td>0.463168</td>\n",
              "      <td>0.372646</td>\n",
              "      <td>0.123934</td>\n",
              "      <td>0.283940</td>\n",
              "      <td>0.158105</td>\n",
              "      <td>0.033894</td>\n",
              "      <td>-0.788101</td>\n",
              "      <td>0.032659</td>\n",
              "      <td>0.570982</td>\n",
              "      <td>-0.006615</td>\n",
              "      <td>-0.180977</td>\n",
              "      <td>-0.817339</td>\n",
              "      <td>1.204200</td>\n",
              "      <td>0.191379</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.078044</td>\n",
              "      <td>0.999961</td>\n",
              "      <td>0.223307</td>\n",
              "      <td>2.078723</td>\n",
              "      <td>2.319320</td>\n",
              "      <td>0.905562</td>\n",
              "      <td>0.332426</td>\n",
              "      <td>0.976779</td>\n",
              "      <td>0.532986</td>\n",
              "      <td>-0.050655</td>\n",
              "      <td>0.982689</td>\n",
              "      <td>-0.065722</td>\n",
              "      <td>-0.004225</td>\n",
              "      <td>0.438282</td>\n",
              "      <td>0.002157</td>\n",
              "      <td>-0.045212</td>\n",
              "      <td>0.008023</td>\n",
              "      <td>-0.029645</td>\n",
              "      <td>-0.207342</td>\n",
              "      <td>0.928015</td>\n",
              "      <td>-0.324298</td>\n",
              "      <td>-1.140827</td>\n",
              "      <td>-0.653351</td>\n",
              "      <td>-0.824146</td>\n",
              "      <td>-0.709399</td>\n",
              "      <td>-0.490435</td>\n",
              "      <td>-0.475458</td>\n",
              "      <td>0.076815</td>\n",
              "      <td>0.019042</td>\n",
              "      <td>0.145740</td>\n",
              "      <td>0.825633</td>\n",
              "      <td>0.641367</td>\n",
              "      <td>0.384540</td>\n",
              "      <td>0.138828</td>\n",
              "      <td>0.234485</td>\n",
              "      <td>0.144311</td>\n",
              "      <td>-0.262908</td>\n",
              "      <td>-1.207322</td>\n",
              "      <td>-0.097961</td>\n",
              "      <td>0.752290</td>\n",
              "      <td>0.683046</td>\n",
              "      <td>-0.133736</td>\n",
              "      <td>-1.437771</td>\n",
              "      <td>1.114276</td>\n",
              "      <td>0.156520</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.004626</td>\n",
              "      <td>0.999766</td>\n",
              "      <td>0.089838</td>\n",
              "      <td>1.947281</td>\n",
              "      <td>2.435517</td>\n",
              "      <td>0.757099</td>\n",
              "      <td>0.391830</td>\n",
              "      <td>0.914462</td>\n",
              "      <td>0.592273</td>\n",
              "      <td>-0.127156</td>\n",
              "      <td>0.969631</td>\n",
              "      <td>-0.132329</td>\n",
              "      <td>-0.020450</td>\n",
              "      <td>0.306552</td>\n",
              "      <td>0.023626</td>\n",
              "      <td>0.010796</td>\n",
              "      <td>0.008240</td>\n",
              "      <td>0.027060</td>\n",
              "      <td>-0.254742</td>\n",
              "      <td>0.895021</td>\n",
              "      <td>-0.382264</td>\n",
              "      <td>-1.303084</td>\n",
              "      <td>-1.053098</td>\n",
              "      <td>-0.956010</td>\n",
              "      <td>-0.638237</td>\n",
              "      <td>-0.450981</td>\n",
              "      <td>-0.573945</td>\n",
              "      <td>0.068318</td>\n",
              "      <td>0.033530</td>\n",
              "      <td>0.142837</td>\n",
              "      <td>0.803937</td>\n",
              "      <td>0.648194</td>\n",
              "      <td>0.420260</td>\n",
              "      <td>0.126181</td>\n",
              "      <td>0.235373</td>\n",
              "      <td>0.144240</td>\n",
              "      <td>-0.078092</td>\n",
              "      <td>-0.907649</td>\n",
              "      <td>-0.301217</td>\n",
              "      <td>0.621242</td>\n",
              "      <td>0.915147</td>\n",
              "      <td>-0.202231</td>\n",
              "      <td>-1.274557</td>\n",
              "      <td>1.030537</td>\n",
              "      <td>-0.465451</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.031238</td>\n",
              "      <td>0.999967</td>\n",
              "      <td>0.147023</td>\n",
              "      <td>1.834258</td>\n",
              "      <td>1.978075</td>\n",
              "      <td>0.735999</td>\n",
              "      <td>0.309147</td>\n",
              "      <td>0.786638</td>\n",
              "      <td>0.391305</td>\n",
              "      <td>-0.090226</td>\n",
              "      <td>0.975951</td>\n",
              "      <td>-0.104667</td>\n",
              "      <td>0.021190</td>\n",
              "      <td>0.391350</td>\n",
              "      <td>-0.040642</td>\n",
              "      <td>-0.037119</td>\n",
              "      <td>0.016059</td>\n",
              "      <td>-0.002408</td>\n",
              "      <td>-0.243513</td>\n",
              "      <td>0.882789</td>\n",
              "      <td>-0.403518</td>\n",
              "      <td>-1.097577</td>\n",
              "      <td>-0.694958</td>\n",
              "      <td>-1.018665</td>\n",
              "      <td>-0.600454</td>\n",
              "      <td>-0.496501</td>\n",
              "      <td>-0.489351</td>\n",
              "      <td>0.078543</td>\n",
              "      <td>0.028896</td>\n",
              "      <td>0.146586</td>\n",
              "      <td>0.808617</td>\n",
              "      <td>0.542754</td>\n",
              "      <td>0.406946</td>\n",
              "      <td>0.129404</td>\n",
              "      <td>0.225972</td>\n",
              "      <td>0.135613</td>\n",
              "      <td>-0.237860</td>\n",
              "      <td>-1.437148</td>\n",
              "      <td>-0.163121</td>\n",
              "      <td>0.746894</td>\n",
              "      <td>0.726951</td>\n",
              "      <td>-0.209633</td>\n",
              "      <td>-1.321456</td>\n",
              "      <td>0.889641</td>\n",
              "      <td>-0.496985</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.026873</td>\n",
              "      <td>0.999832</td>\n",
              "      <td>0.145571</td>\n",
              "      <td>1.928876</td>\n",
              "      <td>2.267244</td>\n",
              "      <td>0.756117</td>\n",
              "      <td>0.291181</td>\n",
              "      <td>1.230035</td>\n",
              "      <td>0.674568</td>\n",
              "      <td>-0.118194</td>\n",
              "      <td>0.972552</td>\n",
              "      <td>-0.104095</td>\n",
              "      <td>-0.031709</td>\n",
              "      <td>0.385806</td>\n",
              "      <td>0.009342</td>\n",
              "      <td>-0.016269</td>\n",
              "      <td>0.008219</td>\n",
              "      <td>-0.017715</td>\n",
              "      <td>-0.277357</td>\n",
              "      <td>0.894542</td>\n",
              "      <td>-0.374809</td>\n",
              "      <td>-1.168579</td>\n",
              "      <td>-0.884106</td>\n",
              "      <td>-0.898270</td>\n",
              "      <td>-0.633793</td>\n",
              "      <td>-0.486475</td>\n",
              "      <td>-0.552400</td>\n",
              "      <td>0.076309</td>\n",
              "      <td>0.028592</td>\n",
              "      <td>0.150890</td>\n",
              "      <td>0.790383</td>\n",
              "      <td>0.624054</td>\n",
              "      <td>0.412224</td>\n",
              "      <td>0.125712</td>\n",
              "      <td>0.253970</td>\n",
              "      <td>0.151216</td>\n",
              "      <td>0.023333</td>\n",
              "      <td>-0.961641</td>\n",
              "      <td>-0.066300</td>\n",
              "      <td>0.703676</td>\n",
              "      <td>0.933546</td>\n",
              "      <td>-0.256429</td>\n",
              "      <td>-1.450020</td>\n",
              "      <td>1.660179</td>\n",
              "      <td>0.061378</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3353</th>\n",
              "      <td>0.504743</td>\n",
              "      <td>0.999438</td>\n",
              "      <td>0.359144</td>\n",
              "      <td>6.478538</td>\n",
              "      <td>4.655244</td>\n",
              "      <td>2.442333</td>\n",
              "      <td>0.993554</td>\n",
              "      <td>1.922272</td>\n",
              "      <td>1.730681</td>\n",
              "      <td>-0.049764</td>\n",
              "      <td>0.887220</td>\n",
              "      <td>-0.266792</td>\n",
              "      <td>0.127582</td>\n",
              "      <td>0.672636</td>\n",
              "      <td>-0.101083</td>\n",
              "      <td>-0.076524</td>\n",
              "      <td>0.031826</td>\n",
              "      <td>-0.008726</td>\n",
              "      <td>-0.578652</td>\n",
              "      <td>0.481345</td>\n",
              "      <td>-0.666042</td>\n",
              "      <td>-3.044744</td>\n",
              "      <td>-4.394538</td>\n",
              "      <td>-3.192693</td>\n",
              "      <td>-1.145613</td>\n",
              "      <td>-1.395230</td>\n",
              "      <td>-1.269927</td>\n",
              "      <td>0.208170</td>\n",
              "      <td>0.110161</td>\n",
              "      <td>0.289922</td>\n",
              "      <td>2.143808</td>\n",
              "      <td>1.654642</td>\n",
              "      <td>1.065543</td>\n",
              "      <td>0.273190</td>\n",
              "      <td>0.577900</td>\n",
              "      <td>0.380353</td>\n",
              "      <td>0.055904</td>\n",
              "      <td>-1.459920</td>\n",
              "      <td>0.508085</td>\n",
              "      <td>0.790299</td>\n",
              "      <td>-0.110069</td>\n",
              "      <td>-0.279998</td>\n",
              "      <td>-0.358255</td>\n",
              "      <td>0.305541</td>\n",
              "      <td>0.066554</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3354</th>\n",
              "      <td>0.387688</td>\n",
              "      <td>0.999990</td>\n",
              "      <td>0.205182</td>\n",
              "      <td>5.057985</td>\n",
              "      <td>4.710542</td>\n",
              "      <td>1.960430</td>\n",
              "      <td>0.567546</td>\n",
              "      <td>1.617881</td>\n",
              "      <td>1.024322</td>\n",
              "      <td>-0.095614</td>\n",
              "      <td>0.834230</td>\n",
              "      <td>-0.384524</td>\n",
              "      <td>0.049412</td>\n",
              "      <td>0.427980</td>\n",
              "      <td>-0.014155</td>\n",
              "      <td>-0.003680</td>\n",
              "      <td>0.074278</td>\n",
              "      <td>0.109654</td>\n",
              "      <td>-0.503259</td>\n",
              "      <td>0.418579</td>\n",
              "      <td>-0.795185</td>\n",
              "      <td>-2.765968</td>\n",
              "      <td>-4.438360</td>\n",
              "      <td>-2.467041</td>\n",
              "      <td>-0.806027</td>\n",
              "      <td>-0.842341</td>\n",
              "      <td>-1.200072</td>\n",
              "      <td>0.212644</td>\n",
              "      <td>0.157913</td>\n",
              "      <td>0.277969</td>\n",
              "      <td>2.100168</td>\n",
              "      <td>1.430208</td>\n",
              "      <td>0.872063</td>\n",
              "      <td>0.216565</td>\n",
              "      <td>0.473915</td>\n",
              "      <td>0.339354</td>\n",
              "      <td>0.336459</td>\n",
              "      <td>-0.980673</td>\n",
              "      <td>0.365275</td>\n",
              "      <td>0.693694</td>\n",
              "      <td>-0.106495</td>\n",
              "      <td>-0.168431</td>\n",
              "      <td>-0.474319</td>\n",
              "      <td>0.399960</td>\n",
              "      <td>-0.336559</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3355</th>\n",
              "      <td>0.460589</td>\n",
              "      <td>0.998442</td>\n",
              "      <td>0.252124</td>\n",
              "      <td>2.705108</td>\n",
              "      <td>3.347442</td>\n",
              "      <td>2.102437</td>\n",
              "      <td>0.692583</td>\n",
              "      <td>1.053557</td>\n",
              "      <td>0.466842</td>\n",
              "      <td>0.179514</td>\n",
              "      <td>0.954295</td>\n",
              "      <td>-0.038175</td>\n",
              "      <td>0.017552</td>\n",
              "      <td>0.375124</td>\n",
              "      <td>0.015418</td>\n",
              "      <td>-0.046538</td>\n",
              "      <td>0.011334</td>\n",
              "      <td>-0.015819</td>\n",
              "      <td>-0.111560</td>\n",
              "      <td>0.807563</td>\n",
              "      <td>-0.371944</td>\n",
              "      <td>-1.524104</td>\n",
              "      <td>-1.680035</td>\n",
              "      <td>-1.844906</td>\n",
              "      <td>-1.098000</td>\n",
              "      <td>-0.595277</td>\n",
              "      <td>-0.805170</td>\n",
              "      <td>0.142949</td>\n",
              "      <td>0.049865</td>\n",
              "      <td>0.181242</td>\n",
              "      <td>0.906431</td>\n",
              "      <td>0.861575</td>\n",
              "      <td>0.909611</td>\n",
              "      <td>0.206497</td>\n",
              "      <td>0.262500</td>\n",
              "      <td>0.140660</td>\n",
              "      <td>0.317025</td>\n",
              "      <td>-1.439422</td>\n",
              "      <td>-0.102200</td>\n",
              "      <td>0.540236</td>\n",
              "      <td>0.631908</td>\n",
              "      <td>0.222315</td>\n",
              "      <td>-0.878347</td>\n",
              "      <td>0.933871</td>\n",
              "      <td>-1.069737</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3356</th>\n",
              "      <td>0.502553</td>\n",
              "      <td>0.999327</td>\n",
              "      <td>0.248331</td>\n",
              "      <td>2.513858</td>\n",
              "      <td>2.970547</td>\n",
              "      <td>2.242588</td>\n",
              "      <td>0.522967</td>\n",
              "      <td>1.138693</td>\n",
              "      <td>0.371182</td>\n",
              "      <td>0.180726</td>\n",
              "      <td>0.947569</td>\n",
              "      <td>-0.060306</td>\n",
              "      <td>0.031966</td>\n",
              "      <td>0.391918</td>\n",
              "      <td>0.025237</td>\n",
              "      <td>-0.009955</td>\n",
              "      <td>0.023866</td>\n",
              "      <td>-0.004181</td>\n",
              "      <td>-0.054874</td>\n",
              "      <td>0.765213</td>\n",
              "      <td>-0.448346</td>\n",
              "      <td>-1.840441</td>\n",
              "      <td>-2.012918</td>\n",
              "      <td>-2.053387</td>\n",
              "      <td>-0.690403</td>\n",
              "      <td>-0.449313</td>\n",
              "      <td>-0.459457</td>\n",
              "      <td>0.158033</td>\n",
              "      <td>0.063193</td>\n",
              "      <td>0.192372</td>\n",
              "      <td>0.965284</td>\n",
              "      <td>0.813172</td>\n",
              "      <td>0.951326</td>\n",
              "      <td>0.189748</td>\n",
              "      <td>0.263612</td>\n",
              "      <td>0.115420</td>\n",
              "      <td>0.375625</td>\n",
              "      <td>-1.395739</td>\n",
              "      <td>-0.362497</td>\n",
              "      <td>0.638323</td>\n",
              "      <td>0.165097</td>\n",
              "      <td>0.295183</td>\n",
              "      <td>-0.605589</td>\n",
              "      <td>1.192888</td>\n",
              "      <td>-0.235505</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3357</th>\n",
              "      <td>0.482841</td>\n",
              "      <td>0.996959</td>\n",
              "      <td>0.290104</td>\n",
              "      <td>2.376766</td>\n",
              "      <td>2.640168</td>\n",
              "      <td>2.261015</td>\n",
              "      <td>0.523204</td>\n",
              "      <td>0.919621</td>\n",
              "      <td>0.363755</td>\n",
              "      <td>0.207829</td>\n",
              "      <td>0.947966</td>\n",
              "      <td>-0.037399</td>\n",
              "      <td>0.088508</td>\n",
              "      <td>0.353318</td>\n",
              "      <td>0.086717</td>\n",
              "      <td>-0.044499</td>\n",
              "      <td>0.018809</td>\n",
              "      <td>-0.016729</td>\n",
              "      <td>-0.078663</td>\n",
              "      <td>0.786706</td>\n",
              "      <td>-0.424952</td>\n",
              "      <td>-1.669332</td>\n",
              "      <td>-1.677025</td>\n",
              "      <td>-2.317634</td>\n",
              "      <td>-0.717791</td>\n",
              "      <td>-0.404146</td>\n",
              "      <td>-0.600297</td>\n",
              "      <td>0.136934</td>\n",
              "      <td>0.057381</td>\n",
              "      <td>0.186716</td>\n",
              "      <td>0.938439</td>\n",
              "      <td>0.821689</td>\n",
              "      <td>0.922838</td>\n",
              "      <td>0.188558</td>\n",
              "      <td>0.247777</td>\n",
              "      <td>0.127774</td>\n",
              "      <td>0.425219</td>\n",
              "      <td>-1.531435</td>\n",
              "      <td>-0.267531</td>\n",
              "      <td>0.473414</td>\n",
              "      <td>0.153339</td>\n",
              "      <td>0.219912</td>\n",
              "      <td>-0.478588</td>\n",
              "      <td>0.924369</td>\n",
              "      <td>-0.491625</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3358 rows × 46 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gravity_max_x  gravity_max_y  ...  userAcceleration_skew_z  Activity\n",
              "0          0.000429       0.999994  ...                 0.191379         5\n",
              "1          0.078044       0.999961  ...                 0.156520         5\n",
              "2          0.004626       0.999766  ...                -0.465451         5\n",
              "3          0.031238       0.999967  ...                -0.496985         5\n",
              "4          0.026873       0.999832  ...                 0.061378         5\n",
              "...             ...            ...  ...                      ...       ...\n",
              "3353       0.504743       0.999438  ...                 0.066554         5\n",
              "3354       0.387688       0.999990  ...                -0.336559         5\n",
              "3355       0.460589       0.998442  ...                -1.069737         5\n",
              "3356       0.502553       0.999327  ...                -0.235505         5\n",
              "3357       0.482841       0.996959  ...                -0.491625         5\n",
              "\n",
              "[3358 rows x 46 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-swLGXf3xLG",
        "outputId": "1abc99d0-b771-45a0-aed3-04d7bb2f056a"
      },
      "source": [
        "Df_plot[\"Activity\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6    826\n",
              "3    823\n",
              "4    745\n",
              "5    357\n",
              "2    313\n",
              "1    294\n",
              "Name: Activity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7gbrCfg4dgC",
        "outputId": "fc453112-9001-493b-93c4-bef0cdc30f45"
      },
      "source": [
        "Df_plot.corr()[\"Activity\"].abs().sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Activity                   1.000000\n",
              "rotationRate_sum_y         0.483153\n",
              "userAcceleration_sum_z     0.373745\n",
              "gravity_std_z              0.324735\n",
              "gravity_max_y              0.272782\n",
              "gravity_sum_y              0.241441\n",
              "gravity_std_y              0.236612\n",
              "userAcceleration_sum_x     0.204815\n",
              "gravity_min_y              0.183156\n",
              "userAcceleration_sum_y     0.177333\n",
              "gravity_std_x              0.142579\n",
              "rotationRate_std_x         0.125222\n",
              "gravity_max_z              0.114808\n",
              "rotationRate_min_y         0.097734\n",
              "rotationRate_max_x         0.090625\n",
              "gravity_min_z              0.089858\n",
              "rotationRate_max_y         0.088470\n",
              "userAcceleration_skew_z    0.087311\n",
              "rotationRate_std_y         0.086636\n",
              "rotationRate_skew_y        0.082986\n",
              "userAcceleration_skew_y    0.080446\n",
              "rotationRate_skew_x        0.070707\n",
              "rotationRate_std_z         0.065861\n",
              "gravity_min_x              0.065220\n",
              "userAcceleration_std_z     0.062298\n",
              "userAcceleration_std_y     0.059024\n",
              "rotationRate_sum_z         0.055254\n",
              "rotationRate_min_x         0.046827\n",
              "userAcceleration_skew_x    0.041774\n",
              "userAcceleration_min_z     0.041506\n",
              "userAcceleration_max_x     0.037241\n",
              "gravity_sum_x              0.037142\n",
              "userAcceleration_max_y     0.033986\n",
              "rotationRate_skew_z        0.026322\n",
              "userAcceleration_max_z     0.017818\n",
              "gravity_skew_y             0.015874\n",
              "gravity_skew_z             0.012388\n",
              "rotationRate_min_z         0.011320\n",
              "gravity_sum_z              0.011022\n",
              "gravity_skew_x             0.009573\n",
              "rotationRate_max_z         0.007411\n",
              "userAcceleration_min_y     0.005926\n",
              "userAcceleration_std_x     0.005829\n",
              "userAcceleration_min_x     0.004964\n",
              "rotationRate_sum_x         0.000390\n",
              "gravity_max_x              0.000085\n",
              "Name: Activity, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUXx0efa7GEW",
        "outputId": "6edbc22d-1431-4c2f-9a23-3e0e65237316"
      },
      "source": [
        "impcols=list(Df_plot.corr()[\"Activity\"].abs().sort_values(ascending=False)[1:].index)\n",
        "impcols.sort()\n",
        "impcols"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gravity_max_x',\n",
              " 'gravity_max_y',\n",
              " 'gravity_max_z',\n",
              " 'gravity_min_x',\n",
              " 'gravity_min_y',\n",
              " 'gravity_min_z',\n",
              " 'gravity_skew_x',\n",
              " 'gravity_skew_y',\n",
              " 'gravity_skew_z',\n",
              " 'gravity_std_x',\n",
              " 'gravity_std_y',\n",
              " 'gravity_std_z',\n",
              " 'gravity_sum_x',\n",
              " 'gravity_sum_y',\n",
              " 'gravity_sum_z',\n",
              " 'rotationRate_max_x',\n",
              " 'rotationRate_max_y',\n",
              " 'rotationRate_max_z',\n",
              " 'rotationRate_min_x',\n",
              " 'rotationRate_min_y',\n",
              " 'rotationRate_min_z',\n",
              " 'rotationRate_skew_x',\n",
              " 'rotationRate_skew_y',\n",
              " 'rotationRate_skew_z',\n",
              " 'rotationRate_std_x',\n",
              " 'rotationRate_std_y',\n",
              " 'rotationRate_std_z',\n",
              " 'rotationRate_sum_x',\n",
              " 'rotationRate_sum_y',\n",
              " 'rotationRate_sum_z',\n",
              " 'userAcceleration_max_x',\n",
              " 'userAcceleration_max_y',\n",
              " 'userAcceleration_max_z',\n",
              " 'userAcceleration_min_x',\n",
              " 'userAcceleration_min_y',\n",
              " 'userAcceleration_min_z',\n",
              " 'userAcceleration_skew_x',\n",
              " 'userAcceleration_skew_y',\n",
              " 'userAcceleration_skew_z',\n",
              " 'userAcceleration_std_x',\n",
              " 'userAcceleration_std_y',\n",
              " 'userAcceleration_std_z',\n",
              " 'userAcceleration_sum_x',\n",
              " 'userAcceleration_sum_y',\n",
              " 'userAcceleration_sum_z']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB2ikhJF5BS1"
      },
      "source": [
        "#pd.plotting.scatter_matrix(Df_plot[impcols],figsize=[100,100])\n",
        "#plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvBa_ZVjNQIp"
      },
      "source": [
        "#Train models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMy6tLpIPTdI"
      },
      "source": [
        "##split into train test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fat0pyQ5GVYp"
      },
      "source": [
        "Labels=pd.get_dummies(Labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw8I4kR5PQ3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f29a9a-1215-4119-bab1-1ffe6593da2d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(Df_Features_1, Labels, test_size=0.25, random_state=0)\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2518, 45)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuQpyKQ3V_Zw"
      },
      "source": [
        "def augmentation(df):\n",
        "  cols=list(df.columns)\n",
        "  cols.sort()\n",
        "  from copy import deepcopy\n",
        "  g=deepcopy(df)\n",
        "  g[cols[0:15]]=0\n",
        "\n",
        "  r=deepcopy(df)\n",
        "  r[cols[16:30]]=0\n",
        "  \n",
        "  u=deepcopy(df)\n",
        "  u[cols[31:45]]=0\n",
        "  \n",
        "  gr=deepcopy(df)\n",
        "  gr[cols[0:30]]=0\n",
        "  \n",
        "  ru=deepcopy(df)\n",
        "  ru[cols[16:45]]=0\n",
        "\n",
        "  gu=deepcopy(df)\n",
        "  gu[cols[0:15]]=0\n",
        "  gu[cols[31:45]]=0\n",
        "  \n",
        "  \n",
        "  return pd.concat([g,r,u,gr,ru,gu])\n",
        "X_train_aug=augmentation(X_train)  \n",
        "X_train_aug\n",
        "y_train_aug=pd.concat([y_train,]*6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ay-Bxj0a2y8",
        "outputId": "098e449b-2801-4810-e677-8c82e848439f"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "#X_train_aug_s,y_train_aug_s=shuffle([X_train_aug,y_train_aug],random_state=0)\n",
        "X_train_aug_s,_,y_train_aug_s, _ = train_test_split(X_train_aug,y_train_aug, test_size=pow(99999,-10),)\n",
        "X_train_aug_s,y_train_aug_s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(      gravity_max_x  ...  userAcceleration_skew_z\n",
              " 477        0.000000  ...                -0.061549\n",
              " 3270       0.156370  ...                 0.000000\n",
              " 2893       0.017894  ...                 0.000000\n",
              " 2332       0.100906  ...                 0.215150\n",
              " 1144       0.000000  ...                 0.000000\n",
              " ...             ...  ...                      ...\n",
              " 1279      -0.020631  ...                 0.000000\n",
              " 2273       0.999998  ...                 0.000000\n",
              " 1095      -0.653350  ...                 0.000000\n",
              " 795        0.000000  ...                 0.000000\n",
              " 1653       0.000000  ...                 0.856658\n",
              " \n",
              " [15107 rows x 45 columns],       1  2  3  4  5  6\n",
              " 477   0  0  0  1  0  0\n",
              " 3270  0  1  0  0  0  0\n",
              " 2893  0  0  0  1  0  0\n",
              " 2332  0  0  0  0  1  0\n",
              " 1144  0  0  1  0  0  0\n",
              " ...  .. .. .. .. .. ..\n",
              " 1279  1  0  0  0  0  0\n",
              " 2273  0  0  0  0  0  1\n",
              " 1095  0  0  1  0  0  0\n",
              " 795   0  0  1  0  0  0\n",
              " 1653  0  0  0  0  0  1\n",
              " \n",
              " [15107 rows x 6 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP9xH6luPYL9"
      },
      "source": [
        "##model1 (10,10,6) relu,relu,sigmoid adam , 1000, 512 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTNCcl1VPnXd",
        "outputId": "b5231505-b1e3-449b-f141-70934e74f522"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(10, activation='relu', input_shape = (X_train_aug.shape[1],)))\n",
        "model.add(layers.Dense(10, activation='relu',kernel_regularizer=\"l2\"))\n",
        "model.add(layers.Dense(6, activation='softmax',))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_71 (Dense)             (None, 10)                460       \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 6)                 66        \n",
            "=================================================================\n",
            "Total params: 636\n",
            "Trainable params: 636\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGkWI0f-PrQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4d5c8f-05ba-4e28-95fe-b2f469aed81e"
      },
      "source": [
        "history = model.fit(X_train_aug,\n",
        "                   y_train_aug,\n",
        "                   epochs=1000,\n",
        "                   batch_size=512,verbose=1,validation_split=0.25,shuffle=True,use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "23/23 [==============================] - 1s 16ms/step - loss: 2.0324 - accuracy: 0.2318 - val_loss: 1.9127 - val_accuracy: 0.3320\n",
            "Epoch 2/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.8648 - accuracy: 0.3124 - val_loss: 1.8205 - val_accuracy: 0.3945\n",
            "Epoch 3/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.7839 - accuracy: 0.3789 - val_loss: 1.7517 - val_accuracy: 0.4151\n",
            "Epoch 4/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7019 - accuracy: 0.4595 - val_loss: 1.6795 - val_accuracy: 0.4273\n",
            "Epoch 5/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6100 - accuracy: 0.4978 - val_loss: 1.6012 - val_accuracy: 0.4414\n",
            "Epoch 6/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5033 - accuracy: 0.5201 - val_loss: 1.5207 - val_accuracy: 0.4530\n",
            "Epoch 7/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4051 - accuracy: 0.5294 - val_loss: 1.4424 - val_accuracy: 0.4604\n",
            "Epoch 8/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3247 - accuracy: 0.5332 - val_loss: 1.3646 - val_accuracy: 0.4713\n",
            "Epoch 9/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2419 - accuracy: 0.5519 - val_loss: 1.2894 - val_accuracy: 0.4784\n",
            "Epoch 10/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1697 - accuracy: 0.5713 - val_loss: 1.2297 - val_accuracy: 0.4983\n",
            "Epoch 11/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1219 - accuracy: 0.5860 - val_loss: 1.1811 - val_accuracy: 0.5465\n",
            "Epoch 12/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0776 - accuracy: 0.6060 - val_loss: 1.1372 - val_accuracy: 0.5637\n",
            "Epoch 13/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.0340 - accuracy: 0.6160 - val_loss: 1.1036 - val_accuracy: 0.5700\n",
            "Epoch 14/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0066 - accuracy: 0.6229 - val_loss: 1.0762 - val_accuracy: 0.5740\n",
            "Epoch 15/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9724 - accuracy: 0.6410 - val_loss: 1.0501 - val_accuracy: 0.5801\n",
            "Epoch 16/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9391 - accuracy: 0.6471 - val_loss: 1.0257 - val_accuracy: 0.5862\n",
            "Epoch 17/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9198 - accuracy: 0.6570 - val_loss: 1.0056 - val_accuracy: 0.5899\n",
            "Epoch 18/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8946 - accuracy: 0.6624 - val_loss: 0.9846 - val_accuracy: 0.6039\n",
            "Epoch 19/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8718 - accuracy: 0.6721 - val_loss: 0.9679 - val_accuracy: 0.6105\n",
            "Epoch 20/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8589 - accuracy: 0.6752 - val_loss: 0.9537 - val_accuracy: 0.6201\n",
            "Epoch 21/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8348 - accuracy: 0.6908 - val_loss: 0.9343 - val_accuracy: 0.6312\n",
            "Epoch 22/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8219 - accuracy: 0.6956 - val_loss: 0.9183 - val_accuracy: 0.6439\n",
            "Epoch 23/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8006 - accuracy: 0.7049 - val_loss: 0.9024 - val_accuracy: 0.6537\n",
            "Epoch 24/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7907 - accuracy: 0.7084 - val_loss: 0.8912 - val_accuracy: 0.6595\n",
            "Epoch 25/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7641 - accuracy: 0.7244 - val_loss: 0.8758 - val_accuracy: 0.6714\n",
            "Epoch 26/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7539 - accuracy: 0.7343 - val_loss: 0.8665 - val_accuracy: 0.6746\n",
            "Epoch 27/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7318 - accuracy: 0.7433 - val_loss: 0.8555 - val_accuracy: 0.6794\n",
            "Epoch 28/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7367 - accuracy: 0.7425 - val_loss: 0.8472 - val_accuracy: 0.6826\n",
            "Epoch 29/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7117 - accuracy: 0.7478 - val_loss: 0.8386 - val_accuracy: 0.6878\n",
            "Epoch 30/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7113 - accuracy: 0.7491 - val_loss: 0.8270 - val_accuracy: 0.6966\n",
            "Epoch 31/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.6972 - accuracy: 0.7582 - val_loss: 0.8189 - val_accuracy: 0.7040\n",
            "Epoch 32/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6824 - accuracy: 0.7620 - val_loss: 0.8147 - val_accuracy: 0.6976\n",
            "Epoch 33/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.6681 - accuracy: 0.7685 - val_loss: 0.8081 - val_accuracy: 0.7059\n",
            "Epoch 34/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.6701 - accuracy: 0.7654 - val_loss: 0.7994 - val_accuracy: 0.7119\n",
            "Epoch 35/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.7732 - val_loss: 0.7949 - val_accuracy: 0.7188\n",
            "Epoch 36/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.7807 - val_loss: 0.7886 - val_accuracy: 0.7156\n",
            "Epoch 37/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6397 - accuracy: 0.7799 - val_loss: 0.7806 - val_accuracy: 0.7207\n",
            "Epoch 38/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6294 - accuracy: 0.7864 - val_loss: 0.7768 - val_accuracy: 0.7268\n",
            "Epoch 39/1000\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6250 - accuracy: 0.7878 - val_loss: 0.7718 - val_accuracy: 0.7334\n",
            "Epoch 40/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.7917 - val_loss: 0.7646 - val_accuracy: 0.7321\n",
            "Epoch 41/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.7973 - val_loss: 0.7600 - val_accuracy: 0.7350\n",
            "Epoch 42/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5989 - accuracy: 0.7964 - val_loss: 0.7607 - val_accuracy: 0.7434\n",
            "Epoch 43/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5995 - accuracy: 0.7982 - val_loss: 0.7490 - val_accuracy: 0.7501\n",
            "Epoch 44/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5912 - accuracy: 0.7993 - val_loss: 0.7477 - val_accuracy: 0.7440\n",
            "Epoch 45/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5935 - accuracy: 0.7965 - val_loss: 0.7410 - val_accuracy: 0.7538\n",
            "Epoch 46/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5922 - accuracy: 0.8017 - val_loss: 0.7395 - val_accuracy: 0.7495\n",
            "Epoch 47/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.8134 - val_loss: 0.7348 - val_accuracy: 0.7548\n",
            "Epoch 48/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5647 - accuracy: 0.8139 - val_loss: 0.7271 - val_accuracy: 0.7522\n",
            "Epoch 49/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5675 - accuracy: 0.8089 - val_loss: 0.7307 - val_accuracy: 0.7569\n",
            "Epoch 50/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.8169 - val_loss: 0.7183 - val_accuracy: 0.7660\n",
            "Epoch 51/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5481 - accuracy: 0.8222 - val_loss: 0.7101 - val_accuracy: 0.7620\n",
            "Epoch 52/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5458 - accuracy: 0.8160 - val_loss: 0.7009 - val_accuracy: 0.7633\n",
            "Epoch 53/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.8175 - val_loss: 0.6989 - val_accuracy: 0.7718\n",
            "Epoch 54/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.8205 - val_loss: 0.6953 - val_accuracy: 0.7710\n",
            "Epoch 55/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.8220 - val_loss: 0.6922 - val_accuracy: 0.7691\n",
            "Epoch 56/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.8252 - val_loss: 0.6896 - val_accuracy: 0.7665\n",
            "Epoch 57/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5192 - accuracy: 0.8316 - val_loss: 0.6908 - val_accuracy: 0.7691\n",
            "Epoch 58/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5240 - accuracy: 0.8237 - val_loss: 0.6795 - val_accuracy: 0.7726\n",
            "Epoch 59/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.8285 - val_loss: 0.6736 - val_accuracy: 0.7808\n",
            "Epoch 60/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.8273 - val_loss: 0.6662 - val_accuracy: 0.7810\n",
            "Epoch 61/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5085 - accuracy: 0.8303 - val_loss: 0.6664 - val_accuracy: 0.7784\n",
            "Epoch 62/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.8379 - val_loss: 0.6610 - val_accuracy: 0.7802\n",
            "Epoch 63/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5031 - accuracy: 0.8371 - val_loss: 0.6567 - val_accuracy: 0.7832\n",
            "Epoch 64/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.8350 - val_loss: 0.6552 - val_accuracy: 0.7784\n",
            "Epoch 65/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.8433 - val_loss: 0.6511 - val_accuracy: 0.7816\n",
            "Epoch 66/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.8421 - val_loss: 0.6547 - val_accuracy: 0.7795\n",
            "Epoch 67/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.8442 - val_loss: 0.6459 - val_accuracy: 0.7829\n",
            "Epoch 68/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.8453 - val_loss: 0.6380 - val_accuracy: 0.7845\n",
            "Epoch 69/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.8426 - val_loss: 0.6341 - val_accuracy: 0.7919\n",
            "Epoch 70/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.8458 - val_loss: 0.6404 - val_accuracy: 0.7877\n",
            "Epoch 71/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.8456 - val_loss: 0.6315 - val_accuracy: 0.7906\n",
            "Epoch 72/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.8461 - val_loss: 0.6310 - val_accuracy: 0.7818\n",
            "Epoch 73/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.8370 - val_loss: 0.6256 - val_accuracy: 0.7885\n",
            "Epoch 74/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.8459 - val_loss: 0.6249 - val_accuracy: 0.7853\n",
            "Epoch 75/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.8498 - val_loss: 0.6228 - val_accuracy: 0.7885\n",
            "Epoch 76/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.8418 - val_loss: 0.6194 - val_accuracy: 0.7890\n",
            "Epoch 77/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.8503 - val_loss: 0.6173 - val_accuracy: 0.7877\n",
            "Epoch 78/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.8504 - val_loss: 0.6127 - val_accuracy: 0.7908\n",
            "Epoch 79/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4533 - accuracy: 0.8513 - val_loss: 0.6112 - val_accuracy: 0.7898\n",
            "Epoch 80/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.8509 - val_loss: 0.6053 - val_accuracy: 0.7940\n",
            "Epoch 81/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.8542 - val_loss: 0.6040 - val_accuracy: 0.8017\n",
            "Epoch 82/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.8548 - val_loss: 0.6022 - val_accuracy: 0.7983\n",
            "Epoch 83/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.8555 - val_loss: 0.5990 - val_accuracy: 0.7967\n",
            "Epoch 84/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.8592 - val_loss: 0.5994 - val_accuracy: 0.7977\n",
            "Epoch 85/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.8532 - val_loss: 0.5989 - val_accuracy: 0.7964\n",
            "Epoch 86/1000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.4386 - accuracy: 0.8587 - val_loss: 0.5970 - val_accuracy: 0.7953\n",
            "Epoch 87/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.8612 - val_loss: 0.5947 - val_accuracy: 0.7975\n",
            "Epoch 88/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.8636 - val_loss: 0.5880 - val_accuracy: 0.7977\n",
            "Epoch 89/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8655 - val_loss: 0.5856 - val_accuracy: 0.8006\n",
            "Epoch 90/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.8655 - val_loss: 0.5897 - val_accuracy: 0.7990\n",
            "Epoch 91/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.8571 - val_loss: 0.5888 - val_accuracy: 0.7985\n",
            "Epoch 92/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8635 - val_loss: 0.5827 - val_accuracy: 0.8030\n",
            "Epoch 93/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8671 - val_loss: 0.5838 - val_accuracy: 0.8020\n",
            "Epoch 94/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8619 - val_loss: 0.5824 - val_accuracy: 0.7975\n",
            "Epoch 95/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8661 - val_loss: 0.5850 - val_accuracy: 0.7998\n",
            "Epoch 96/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8660 - val_loss: 0.5751 - val_accuracy: 0.8017\n",
            "Epoch 97/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8648 - val_loss: 0.5768 - val_accuracy: 0.8022\n",
            "Epoch 98/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8716 - val_loss: 0.5696 - val_accuracy: 0.8102\n",
            "Epoch 99/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.8683 - val_loss: 0.5767 - val_accuracy: 0.8062\n",
            "Epoch 100/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8753 - val_loss: 0.5760 - val_accuracy: 0.8022\n",
            "Epoch 101/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.8644 - val_loss: 0.5665 - val_accuracy: 0.8107\n",
            "Epoch 102/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8683 - val_loss: 0.5716 - val_accuracy: 0.8086\n",
            "Epoch 103/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8738 - val_loss: 0.5671 - val_accuracy: 0.8094\n",
            "Epoch 104/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8703 - val_loss: 0.5703 - val_accuracy: 0.8065\n",
            "Epoch 105/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8725 - val_loss: 0.5623 - val_accuracy: 0.8083\n",
            "Epoch 106/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8769 - val_loss: 0.5634 - val_accuracy: 0.8104\n",
            "Epoch 107/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8678 - val_loss: 0.5649 - val_accuracy: 0.8067\n",
            "Epoch 108/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8746 - val_loss: 0.5626 - val_accuracy: 0.8104\n",
            "Epoch 109/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8741 - val_loss: 0.5706 - val_accuracy: 0.8073\n",
            "Epoch 110/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8729 - val_loss: 0.5540 - val_accuracy: 0.8160\n",
            "Epoch 111/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8752 - val_loss: 0.5582 - val_accuracy: 0.8102\n",
            "Epoch 112/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8754 - val_loss: 0.5526 - val_accuracy: 0.8165\n",
            "Epoch 113/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8771 - val_loss: 0.5540 - val_accuracy: 0.8133\n",
            "Epoch 114/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8782 - val_loss: 0.5572 - val_accuracy: 0.8118\n",
            "Epoch 115/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3884 - accuracy: 0.8814 - val_loss: 0.5561 - val_accuracy: 0.8125\n",
            "Epoch 116/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8801 - val_loss: 0.5523 - val_accuracy: 0.8131\n",
            "Epoch 117/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8740 - val_loss: 0.5502 - val_accuracy: 0.8136\n",
            "Epoch 118/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8773 - val_loss: 0.5502 - val_accuracy: 0.8131\n",
            "Epoch 119/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8763 - val_loss: 0.5452 - val_accuracy: 0.8171\n",
            "Epoch 120/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8748 - val_loss: 0.5561 - val_accuracy: 0.8128\n",
            "Epoch 121/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8768 - val_loss: 0.5477 - val_accuracy: 0.8171\n",
            "Epoch 122/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8854 - val_loss: 0.5442 - val_accuracy: 0.8168\n",
            "Epoch 123/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.8820 - val_loss: 0.5527 - val_accuracy: 0.8149\n",
            "Epoch 124/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8814 - val_loss: 0.5508 - val_accuracy: 0.8152\n",
            "Epoch 125/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8814 - val_loss: 0.5450 - val_accuracy: 0.8155\n",
            "Epoch 126/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8815 - val_loss: 0.5431 - val_accuracy: 0.8168\n",
            "Epoch 127/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.8813 - val_loss: 0.5494 - val_accuracy: 0.8133\n",
            "Epoch 128/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8784 - val_loss: 0.5472 - val_accuracy: 0.8128\n",
            "Epoch 129/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3763 - accuracy: 0.8853 - val_loss: 0.5410 - val_accuracy: 0.8171\n",
            "Epoch 130/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8797 - val_loss: 0.5465 - val_accuracy: 0.8141\n",
            "Epoch 131/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8838 - val_loss: 0.5470 - val_accuracy: 0.8118\n",
            "Epoch 132/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8836 - val_loss: 0.5435 - val_accuracy: 0.8163\n",
            "Epoch 133/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8790 - val_loss: 0.5419 - val_accuracy: 0.8163\n",
            "Epoch 134/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8789 - val_loss: 0.5478 - val_accuracy: 0.8147\n",
            "Epoch 135/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.8843 - val_loss: 0.5457 - val_accuracy: 0.8155\n",
            "Epoch 136/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3822 - accuracy: 0.8840 - val_loss: 0.5392 - val_accuracy: 0.8147\n",
            "Epoch 137/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8825 - val_loss: 0.5281 - val_accuracy: 0.8234\n",
            "Epoch 138/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8846 - val_loss: 0.5324 - val_accuracy: 0.8258\n",
            "Epoch 139/1000\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.3744 - accuracy: 0.8847 - val_loss: 0.5352 - val_accuracy: 0.8247\n",
            "Epoch 140/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8786 - val_loss: 0.5372 - val_accuracy: 0.8178\n",
            "Epoch 141/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8896 - val_loss: 0.5368 - val_accuracy: 0.8194\n",
            "Epoch 142/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8858 - val_loss: 0.5370 - val_accuracy: 0.8218\n",
            "Epoch 143/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8849 - val_loss: 0.5252 - val_accuracy: 0.8271\n",
            "Epoch 144/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8832 - val_loss: 0.5285 - val_accuracy: 0.8242\n",
            "Epoch 145/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.8861 - val_loss: 0.5347 - val_accuracy: 0.8210\n",
            "Epoch 146/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8838 - val_loss: 0.5365 - val_accuracy: 0.8186\n",
            "Epoch 147/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8914 - val_loss: 0.5408 - val_accuracy: 0.8176\n",
            "Epoch 148/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8842 - val_loss: 0.5384 - val_accuracy: 0.8186\n",
            "Epoch 149/1000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3611 - accuracy: 0.8877 - val_loss: 0.5266 - val_accuracy: 0.8245\n",
            "Epoch 150/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8911 - val_loss: 0.5245 - val_accuracy: 0.8239\n",
            "Epoch 151/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3629 - accuracy: 0.8882 - val_loss: 0.5356 - val_accuracy: 0.8173\n",
            "Epoch 152/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3631 - accuracy: 0.8898 - val_loss: 0.5316 - val_accuracy: 0.8210\n",
            "Epoch 153/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8872 - val_loss: 0.5275 - val_accuracy: 0.8223\n",
            "Epoch 154/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3576 - accuracy: 0.8896 - val_loss: 0.5317 - val_accuracy: 0.8216\n",
            "Epoch 155/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3628 - accuracy: 0.8871 - val_loss: 0.5405 - val_accuracy: 0.8157\n",
            "Epoch 156/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3535 - accuracy: 0.8907 - val_loss: 0.5424 - val_accuracy: 0.8136\n",
            "Epoch 157/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3546 - accuracy: 0.8899 - val_loss: 0.5290 - val_accuracy: 0.8226\n",
            "Epoch 158/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3625 - accuracy: 0.8873 - val_loss: 0.5325 - val_accuracy: 0.8197\n",
            "Epoch 159/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3556 - accuracy: 0.8907 - val_loss: 0.5304 - val_accuracy: 0.8216\n",
            "Epoch 160/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3579 - accuracy: 0.8897 - val_loss: 0.5218 - val_accuracy: 0.8263\n",
            "Epoch 161/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3594 - accuracy: 0.8845 - val_loss: 0.5215 - val_accuracy: 0.8247\n",
            "Epoch 162/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3519 - accuracy: 0.8942 - val_loss: 0.5273 - val_accuracy: 0.8213\n",
            "Epoch 163/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3553 - accuracy: 0.8886 - val_loss: 0.5195 - val_accuracy: 0.8263\n",
            "Epoch 164/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8874 - val_loss: 0.5181 - val_accuracy: 0.8261\n",
            "Epoch 165/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.8889 - val_loss: 0.5160 - val_accuracy: 0.8271\n",
            "Epoch 166/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8944 - val_loss: 0.5140 - val_accuracy: 0.8295\n",
            "Epoch 167/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3510 - accuracy: 0.8885 - val_loss: 0.5148 - val_accuracy: 0.8255\n",
            "Epoch 168/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8919 - val_loss: 0.5158 - val_accuracy: 0.8276\n",
            "Epoch 169/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8943 - val_loss: 0.5163 - val_accuracy: 0.8261\n",
            "Epoch 170/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.8924 - val_loss: 0.5221 - val_accuracy: 0.8229\n",
            "Epoch 171/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8904 - val_loss: 0.5236 - val_accuracy: 0.8210\n",
            "Epoch 172/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3429 - accuracy: 0.8922 - val_loss: 0.5190 - val_accuracy: 0.8253\n",
            "Epoch 173/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8914 - val_loss: 0.5179 - val_accuracy: 0.8261\n",
            "Epoch 174/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3432 - accuracy: 0.8976 - val_loss: 0.5132 - val_accuracy: 0.8279\n",
            "Epoch 175/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8965 - val_loss: 0.5188 - val_accuracy: 0.8284\n",
            "Epoch 176/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8919 - val_loss: 0.5035 - val_accuracy: 0.8327\n",
            "Epoch 177/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3473 - accuracy: 0.8888 - val_loss: 0.5146 - val_accuracy: 0.8268\n",
            "Epoch 178/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8919 - val_loss: 0.5124 - val_accuracy: 0.8268\n",
            "Epoch 179/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8892 - val_loss: 0.5182 - val_accuracy: 0.8253\n",
            "Epoch 180/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8932 - val_loss: 0.5035 - val_accuracy: 0.8321\n",
            "Epoch 181/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.8938 - val_loss: 0.5136 - val_accuracy: 0.8276\n",
            "Epoch 182/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8943 - val_loss: 0.5115 - val_accuracy: 0.8306\n",
            "Epoch 183/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3525 - accuracy: 0.8888 - val_loss: 0.5140 - val_accuracy: 0.8263\n",
            "Epoch 184/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3331 - accuracy: 0.8982 - val_loss: 0.5081 - val_accuracy: 0.8266\n",
            "Epoch 185/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.8958 - val_loss: 0.5075 - val_accuracy: 0.8313\n",
            "Epoch 186/1000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.3393 - accuracy: 0.8952 - val_loss: 0.5121 - val_accuracy: 0.8261\n",
            "Epoch 187/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.8981 - val_loss: 0.5144 - val_accuracy: 0.8258\n",
            "Epoch 188/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8977 - val_loss: 0.5031 - val_accuracy: 0.8313\n",
            "Epoch 189/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8959 - val_loss: 0.5027 - val_accuracy: 0.8321\n",
            "Epoch 190/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3327 - accuracy: 0.8978 - val_loss: 0.5042 - val_accuracy: 0.8319\n",
            "Epoch 191/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8962 - val_loss: 0.5031 - val_accuracy: 0.8332\n",
            "Epoch 192/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8922 - val_loss: 0.5101 - val_accuracy: 0.8258\n",
            "Epoch 193/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8947 - val_loss: 0.5027 - val_accuracy: 0.8319\n",
            "Epoch 194/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8962 - val_loss: 0.4989 - val_accuracy: 0.8356\n",
            "Epoch 195/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8952 - val_loss: 0.5066 - val_accuracy: 0.8292\n",
            "Epoch 196/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.9041 - val_loss: 0.5147 - val_accuracy: 0.8250\n",
            "Epoch 197/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3306 - accuracy: 0.8989 - val_loss: 0.5031 - val_accuracy: 0.8295\n",
            "Epoch 198/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.8977 - val_loss: 0.5062 - val_accuracy: 0.8284\n",
            "Epoch 199/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8951 - val_loss: 0.5224 - val_accuracy: 0.8226\n",
            "Epoch 200/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8943 - val_loss: 0.5085 - val_accuracy: 0.8258\n",
            "Epoch 201/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.8983 - val_loss: 0.5041 - val_accuracy: 0.8324\n",
            "Epoch 202/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3310 - accuracy: 0.9008 - val_loss: 0.5019 - val_accuracy: 0.8284\n",
            "Epoch 203/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3280 - accuracy: 0.8970 - val_loss: 0.5027 - val_accuracy: 0.8306\n",
            "Epoch 204/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.9012 - val_loss: 0.5058 - val_accuracy: 0.8276\n",
            "Epoch 205/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8964 - val_loss: 0.5007 - val_accuracy: 0.8343\n",
            "Epoch 206/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.9020 - val_loss: 0.5135 - val_accuracy: 0.8231\n",
            "Epoch 207/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8968 - val_loss: 0.5173 - val_accuracy: 0.8213\n",
            "Epoch 208/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.9005 - val_loss: 0.4976 - val_accuracy: 0.8332\n",
            "Epoch 209/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3218 - accuracy: 0.9015 - val_loss: 0.4992 - val_accuracy: 0.8313\n",
            "Epoch 210/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8947 - val_loss: 0.5046 - val_accuracy: 0.8279\n",
            "Epoch 211/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.9003 - val_loss: 0.5059 - val_accuracy: 0.8268\n",
            "Epoch 212/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3251 - accuracy: 0.8968 - val_loss: 0.5069 - val_accuracy: 0.8268\n",
            "Epoch 213/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3238 - accuracy: 0.9017 - val_loss: 0.5011 - val_accuracy: 0.8295\n",
            "Epoch 214/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.9006 - val_loss: 0.5037 - val_accuracy: 0.8263\n",
            "Epoch 215/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3213 - accuracy: 0.9004 - val_loss: 0.5031 - val_accuracy: 0.8298\n",
            "Epoch 216/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.8992 - val_loss: 0.5154 - val_accuracy: 0.8216\n",
            "Epoch 217/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3112 - accuracy: 0.9013 - val_loss: 0.5023 - val_accuracy: 0.8308\n",
            "Epoch 218/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3288 - accuracy: 0.8970 - val_loss: 0.5048 - val_accuracy: 0.8282\n",
            "Epoch 219/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3160 - accuracy: 0.9038 - val_loss: 0.5061 - val_accuracy: 0.8282\n",
            "Epoch 220/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.9029 - val_loss: 0.5082 - val_accuracy: 0.8247\n",
            "Epoch 221/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3238 - accuracy: 0.8975 - val_loss: 0.5050 - val_accuracy: 0.8279\n",
            "Epoch 222/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.9036 - val_loss: 0.4980 - val_accuracy: 0.8324\n",
            "Epoch 223/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3151 - accuracy: 0.9039 - val_loss: 0.5021 - val_accuracy: 0.8253\n",
            "Epoch 224/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.9024 - val_loss: 0.4986 - val_accuracy: 0.8298\n",
            "Epoch 225/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3202 - accuracy: 0.9014 - val_loss: 0.5046 - val_accuracy: 0.8253\n",
            "Epoch 226/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.9023 - val_loss: 0.5079 - val_accuracy: 0.8271\n",
            "Epoch 227/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3202 - accuracy: 0.9020 - val_loss: 0.5066 - val_accuracy: 0.8276\n",
            "Epoch 228/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.9048 - val_loss: 0.5046 - val_accuracy: 0.8295\n",
            "Epoch 229/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3171 - accuracy: 0.9015 - val_loss: 0.5129 - val_accuracy: 0.8218\n",
            "Epoch 230/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3159 - accuracy: 0.9020 - val_loss: 0.5006 - val_accuracy: 0.8284\n",
            "Epoch 231/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.9011 - val_loss: 0.5054 - val_accuracy: 0.8255\n",
            "Epoch 232/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3114 - accuracy: 0.9018 - val_loss: 0.5003 - val_accuracy: 0.8274\n",
            "Epoch 233/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3132 - accuracy: 0.9013 - val_loss: 0.5100 - val_accuracy: 0.8253\n",
            "Epoch 234/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3111 - accuracy: 0.9030 - val_loss: 0.5049 - val_accuracy: 0.8261\n",
            "Epoch 235/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.9026 - val_loss: 0.4981 - val_accuracy: 0.8290\n",
            "Epoch 236/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3118 - accuracy: 0.9021 - val_loss: 0.5040 - val_accuracy: 0.8258\n",
            "Epoch 237/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3124 - accuracy: 0.9038 - val_loss: 0.5030 - val_accuracy: 0.8268\n",
            "Epoch 238/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3146 - accuracy: 0.9034 - val_loss: 0.5028 - val_accuracy: 0.8274\n",
            "Epoch 239/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3173 - accuracy: 0.8991 - val_loss: 0.5073 - val_accuracy: 0.8255\n",
            "Epoch 240/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3126 - accuracy: 0.9015 - val_loss: 0.4981 - val_accuracy: 0.8295\n",
            "Epoch 241/1000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.3148 - accuracy: 0.9027 - val_loss: 0.4935 - val_accuracy: 0.8321\n",
            "Epoch 242/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3080 - accuracy: 0.9006 - val_loss: 0.5045 - val_accuracy: 0.8253\n",
            "Epoch 243/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3116 - accuracy: 0.9016 - val_loss: 0.5004 - val_accuracy: 0.8268\n",
            "Epoch 244/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.9047 - val_loss: 0.4972 - val_accuracy: 0.8303\n",
            "Epoch 245/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.9009 - val_loss: 0.5005 - val_accuracy: 0.8266\n",
            "Epoch 246/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3089 - accuracy: 0.9020 - val_loss: 0.5025 - val_accuracy: 0.8282\n",
            "Epoch 247/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3083 - accuracy: 0.9060 - val_loss: 0.5055 - val_accuracy: 0.8261\n",
            "Epoch 248/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3046 - accuracy: 0.9032 - val_loss: 0.5002 - val_accuracy: 0.8274\n",
            "Epoch 249/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3070 - accuracy: 0.9037 - val_loss: 0.5024 - val_accuracy: 0.8268\n",
            "Epoch 250/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3111 - accuracy: 0.9038 - val_loss: 0.4993 - val_accuracy: 0.8290\n",
            "Epoch 251/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2993 - accuracy: 0.9060 - val_loss: 0.5020 - val_accuracy: 0.8253\n",
            "Epoch 252/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3072 - accuracy: 0.9038 - val_loss: 0.5053 - val_accuracy: 0.8258\n",
            "Epoch 253/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3002 - accuracy: 0.9071 - val_loss: 0.5033 - val_accuracy: 0.8263\n",
            "Epoch 254/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3080 - accuracy: 0.9043 - val_loss: 0.5142 - val_accuracy: 0.8237\n",
            "Epoch 255/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.9076 - val_loss: 0.5012 - val_accuracy: 0.8295\n",
            "Epoch 256/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2970 - accuracy: 0.9079 - val_loss: 0.4982 - val_accuracy: 0.8319\n",
            "Epoch 257/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3037 - accuracy: 0.9093 - val_loss: 0.5002 - val_accuracy: 0.8282\n",
            "Epoch 258/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.9057 - val_loss: 0.4972 - val_accuracy: 0.8287\n",
            "Epoch 259/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.9061 - val_loss: 0.4907 - val_accuracy: 0.8343\n",
            "Epoch 260/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3055 - accuracy: 0.9057 - val_loss: 0.4929 - val_accuracy: 0.8306\n",
            "Epoch 261/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.9074 - val_loss: 0.4984 - val_accuracy: 0.8298\n",
            "Epoch 262/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.9053 - val_loss: 0.4970 - val_accuracy: 0.8308\n",
            "Epoch 263/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.9091 - val_loss: 0.4951 - val_accuracy: 0.8303\n",
            "Epoch 264/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3050 - accuracy: 0.9082 - val_loss: 0.4972 - val_accuracy: 0.8295\n",
            "Epoch 265/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.9046 - val_loss: 0.4971 - val_accuracy: 0.8282\n",
            "Epoch 266/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2988 - accuracy: 0.9060 - val_loss: 0.4886 - val_accuracy: 0.8348\n",
            "Epoch 267/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.9033 - val_loss: 0.4933 - val_accuracy: 0.8319\n",
            "Epoch 268/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.9094 - val_loss: 0.4876 - val_accuracy: 0.8353\n",
            "Epoch 269/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3020 - accuracy: 0.9012 - val_loss: 0.5043 - val_accuracy: 0.8276\n",
            "Epoch 270/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.9046 - val_loss: 0.4902 - val_accuracy: 0.8345\n",
            "Epoch 271/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2930 - accuracy: 0.9058 - val_loss: 0.5133 - val_accuracy: 0.8247\n",
            "Epoch 272/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.9073 - val_loss: 0.4975 - val_accuracy: 0.8298\n",
            "Epoch 273/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2998 - accuracy: 0.9029 - val_loss: 0.4968 - val_accuracy: 0.8282\n",
            "Epoch 274/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2996 - accuracy: 0.9083 - val_loss: 0.4929 - val_accuracy: 0.8306\n",
            "Epoch 275/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2913 - accuracy: 0.9089 - val_loss: 0.4920 - val_accuracy: 0.8298\n",
            "Epoch 276/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.9021 - val_loss: 0.4937 - val_accuracy: 0.8316\n",
            "Epoch 277/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3025 - accuracy: 0.9034 - val_loss: 0.4937 - val_accuracy: 0.8316\n",
            "Epoch 278/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2867 - accuracy: 0.9098 - val_loss: 0.4937 - val_accuracy: 0.8303\n",
            "Epoch 279/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.9048 - val_loss: 0.4929 - val_accuracy: 0.8303\n",
            "Epoch 280/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2985 - accuracy: 0.9069 - val_loss: 0.5010 - val_accuracy: 0.8300\n",
            "Epoch 281/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.9055 - val_loss: 0.4940 - val_accuracy: 0.8316\n",
            "Epoch 282/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2859 - accuracy: 0.9139 - val_loss: 0.4796 - val_accuracy: 0.8364\n",
            "Epoch 283/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2980 - accuracy: 0.9048 - val_loss: 0.4912 - val_accuracy: 0.8306\n",
            "Epoch 284/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2945 - accuracy: 0.9103 - val_loss: 0.4902 - val_accuracy: 0.8316\n",
            "Epoch 285/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2918 - accuracy: 0.9110 - val_loss: 0.4798 - val_accuracy: 0.8374\n",
            "Epoch 286/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2916 - accuracy: 0.9078 - val_loss: 0.4972 - val_accuracy: 0.8308\n",
            "Epoch 287/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2852 - accuracy: 0.9107 - val_loss: 0.4885 - val_accuracy: 0.8303\n",
            "Epoch 288/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2937 - accuracy: 0.9064 - val_loss: 0.4909 - val_accuracy: 0.8298\n",
            "Epoch 289/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.9100 - val_loss: 0.4880 - val_accuracy: 0.8313\n",
            "Epoch 290/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2869 - accuracy: 0.9096 - val_loss: 0.4781 - val_accuracy: 0.8356\n",
            "Epoch 291/1000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.2874 - accuracy: 0.9090 - val_loss: 0.4873 - val_accuracy: 0.8303\n",
            "Epoch 292/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.9073 - val_loss: 0.4958 - val_accuracy: 0.8295\n",
            "Epoch 293/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.9070 - val_loss: 0.4970 - val_accuracy: 0.8311\n",
            "Epoch 294/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2932 - accuracy: 0.9068 - val_loss: 0.4885 - val_accuracy: 0.8319\n",
            "Epoch 295/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2899 - accuracy: 0.9072 - val_loss: 0.4819 - val_accuracy: 0.8353\n",
            "Epoch 296/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2894 - accuracy: 0.9102 - val_loss: 0.4811 - val_accuracy: 0.8353\n",
            "Epoch 297/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2896 - accuracy: 0.9078 - val_loss: 0.4973 - val_accuracy: 0.8290\n",
            "Epoch 298/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.9137 - val_loss: 0.4888 - val_accuracy: 0.8308\n",
            "Epoch 299/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.9069 - val_loss: 0.4861 - val_accuracy: 0.8321\n",
            "Epoch 300/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2888 - accuracy: 0.9068 - val_loss: 0.4858 - val_accuracy: 0.8303\n",
            "Epoch 301/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.9093 - val_loss: 0.4825 - val_accuracy: 0.8353\n",
            "Epoch 302/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.9073 - val_loss: 0.4966 - val_accuracy: 0.8292\n",
            "Epoch 303/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2858 - accuracy: 0.9104 - val_loss: 0.4991 - val_accuracy: 0.8292\n",
            "Epoch 304/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2883 - accuracy: 0.9083 - val_loss: 0.4907 - val_accuracy: 0.8300\n",
            "Epoch 305/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2828 - accuracy: 0.9106 - val_loss: 0.4862 - val_accuracy: 0.8335\n",
            "Epoch 306/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2909 - accuracy: 0.9097 - val_loss: 0.4884 - val_accuracy: 0.8311\n",
            "Epoch 307/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2834 - accuracy: 0.9106 - val_loss: 0.4916 - val_accuracy: 0.8306\n",
            "Epoch 308/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2945 - accuracy: 0.9061 - val_loss: 0.4782 - val_accuracy: 0.8361\n",
            "Epoch 309/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2849 - accuracy: 0.9083 - val_loss: 0.4991 - val_accuracy: 0.8313\n",
            "Epoch 310/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2794 - accuracy: 0.9114 - val_loss: 0.4803 - val_accuracy: 0.8356\n",
            "Epoch 311/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2741 - accuracy: 0.9135 - val_loss: 0.4901 - val_accuracy: 0.8321\n",
            "Epoch 312/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2858 - accuracy: 0.9079 - val_loss: 0.4924 - val_accuracy: 0.8300\n",
            "Epoch 313/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2910 - accuracy: 0.9071 - val_loss: 0.4848 - val_accuracy: 0.8319\n",
            "Epoch 314/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2827 - accuracy: 0.9111 - val_loss: 0.4853 - val_accuracy: 0.8348\n",
            "Epoch 315/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2878 - accuracy: 0.9115 - val_loss: 0.4785 - val_accuracy: 0.8374\n",
            "Epoch 316/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.9099 - val_loss: 0.4908 - val_accuracy: 0.8308\n",
            "Epoch 317/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2863 - accuracy: 0.9107 - val_loss: 0.4883 - val_accuracy: 0.8292\n",
            "Epoch 318/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2740 - accuracy: 0.9115 - val_loss: 0.4878 - val_accuracy: 0.8319\n",
            "Epoch 319/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2843 - accuracy: 0.9123 - val_loss: 0.4910 - val_accuracy: 0.8335\n",
            "Epoch 320/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2855 - accuracy: 0.9104 - val_loss: 0.4951 - val_accuracy: 0.8324\n",
            "Epoch 321/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2824 - accuracy: 0.9091 - val_loss: 0.4855 - val_accuracy: 0.8319\n",
            "Epoch 322/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2736 - accuracy: 0.9115 - val_loss: 0.4851 - val_accuracy: 0.8361\n",
            "Epoch 323/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2795 - accuracy: 0.9101 - val_loss: 0.4974 - val_accuracy: 0.8316\n",
            "Epoch 324/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2799 - accuracy: 0.9117 - val_loss: 0.4884 - val_accuracy: 0.8329\n",
            "Epoch 325/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2866 - accuracy: 0.9106 - val_loss: 0.4875 - val_accuracy: 0.8327\n",
            "Epoch 326/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2807 - accuracy: 0.9115 - val_loss: 0.4863 - val_accuracy: 0.8345\n",
            "Epoch 327/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2791 - accuracy: 0.9113 - val_loss: 0.4795 - val_accuracy: 0.8343\n",
            "Epoch 328/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2867 - accuracy: 0.9102 - val_loss: 0.4878 - val_accuracy: 0.8351\n",
            "Epoch 329/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2777 - accuracy: 0.9154 - val_loss: 0.4876 - val_accuracy: 0.8313\n",
            "Epoch 330/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2806 - accuracy: 0.9135 - val_loss: 0.4726 - val_accuracy: 0.8398\n",
            "Epoch 331/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2816 - accuracy: 0.9109 - val_loss: 0.4824 - val_accuracy: 0.8356\n",
            "Epoch 332/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2820 - accuracy: 0.9100 - val_loss: 0.4891 - val_accuracy: 0.8319\n",
            "Epoch 333/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2734 - accuracy: 0.9158 - val_loss: 0.4920 - val_accuracy: 0.8340\n",
            "Epoch 334/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2777 - accuracy: 0.9133 - val_loss: 0.4819 - val_accuracy: 0.8345\n",
            "Epoch 335/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2764 - accuracy: 0.9120 - val_loss: 0.4925 - val_accuracy: 0.8324\n",
            "Epoch 336/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.9143 - val_loss: 0.5101 - val_accuracy: 0.8298\n",
            "Epoch 337/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2709 - accuracy: 0.9137 - val_loss: 0.4790 - val_accuracy: 0.8369\n",
            "Epoch 338/1000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.2784 - accuracy: 0.9096 - val_loss: 0.4962 - val_accuracy: 0.8340\n",
            "Epoch 339/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2762 - accuracy: 0.9107 - val_loss: 0.4996 - val_accuracy: 0.8306\n",
            "Epoch 340/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2718 - accuracy: 0.9126 - val_loss: 0.4933 - val_accuracy: 0.8324\n",
            "Epoch 341/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2772 - accuracy: 0.9136 - val_loss: 0.4830 - val_accuracy: 0.8343\n",
            "Epoch 342/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2783 - accuracy: 0.9108 - val_loss: 0.4832 - val_accuracy: 0.8345\n",
            "Epoch 343/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2788 - accuracy: 0.9128 - val_loss: 0.4822 - val_accuracy: 0.8345\n",
            "Epoch 344/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2713 - accuracy: 0.9127 - val_loss: 0.4869 - val_accuracy: 0.8356\n",
            "Epoch 345/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2790 - accuracy: 0.9099 - val_loss: 0.4735 - val_accuracy: 0.8401\n",
            "Epoch 346/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2737 - accuracy: 0.9114 - val_loss: 0.4806 - val_accuracy: 0.8380\n",
            "Epoch 347/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2787 - accuracy: 0.9111 - val_loss: 0.4887 - val_accuracy: 0.8324\n",
            "Epoch 348/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2769 - accuracy: 0.9118 - val_loss: 0.4891 - val_accuracy: 0.8316\n",
            "Epoch 349/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2840 - accuracy: 0.9078 - val_loss: 0.4767 - val_accuracy: 0.8348\n",
            "Epoch 350/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2697 - accuracy: 0.9157 - val_loss: 0.4832 - val_accuracy: 0.8366\n",
            "Epoch 351/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.9142 - val_loss: 0.4876 - val_accuracy: 0.8369\n",
            "Epoch 352/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2777 - accuracy: 0.9119 - val_loss: 0.4849 - val_accuracy: 0.8327\n",
            "Epoch 353/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2775 - accuracy: 0.9116 - val_loss: 0.4822 - val_accuracy: 0.8366\n",
            "Epoch 354/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2737 - accuracy: 0.9137 - val_loss: 0.4895 - val_accuracy: 0.8353\n",
            "Epoch 355/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2674 - accuracy: 0.9166 - val_loss: 0.4778 - val_accuracy: 0.8403\n",
            "Epoch 356/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.9150 - val_loss: 0.4816 - val_accuracy: 0.8372\n",
            "Epoch 357/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2652 - accuracy: 0.9169 - val_loss: 0.4860 - val_accuracy: 0.8364\n",
            "Epoch 358/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2796 - accuracy: 0.9122 - val_loss: 0.4824 - val_accuracy: 0.8351\n",
            "Epoch 359/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2685 - accuracy: 0.9133 - val_loss: 0.4834 - val_accuracy: 0.8356\n",
            "Epoch 360/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2777 - accuracy: 0.9130 - val_loss: 0.4757 - val_accuracy: 0.8409\n",
            "Epoch 361/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2678 - accuracy: 0.9140 - val_loss: 0.4841 - val_accuracy: 0.8393\n",
            "Epoch 362/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2683 - accuracy: 0.9158 - val_loss: 0.4758 - val_accuracy: 0.8390\n",
            "Epoch 363/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2805 - accuracy: 0.9088 - val_loss: 0.4918 - val_accuracy: 0.8311\n",
            "Epoch 364/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2741 - accuracy: 0.9111 - val_loss: 0.4994 - val_accuracy: 0.8306\n",
            "Epoch 365/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2657 - accuracy: 0.9150 - val_loss: 0.4871 - val_accuracy: 0.8358\n",
            "Epoch 366/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2769 - accuracy: 0.9130 - val_loss: 0.4910 - val_accuracy: 0.8327\n",
            "Epoch 367/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2709 - accuracy: 0.9137 - val_loss: 0.4915 - val_accuracy: 0.8332\n",
            "Epoch 368/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2716 - accuracy: 0.9165 - val_loss: 0.4795 - val_accuracy: 0.8361\n",
            "Epoch 369/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2659 - accuracy: 0.9123 - val_loss: 0.4767 - val_accuracy: 0.8374\n",
            "Epoch 370/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2650 - accuracy: 0.9149 - val_loss: 0.4904 - val_accuracy: 0.8351\n",
            "Epoch 371/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2660 - accuracy: 0.9182 - val_loss: 0.4851 - val_accuracy: 0.8351\n",
            "Epoch 372/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2682 - accuracy: 0.9140 - val_loss: 0.4844 - val_accuracy: 0.8353\n",
            "Epoch 373/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2698 - accuracy: 0.9152 - val_loss: 0.4852 - val_accuracy: 0.8343\n",
            "Epoch 374/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.9181 - val_loss: 0.4862 - val_accuracy: 0.8382\n",
            "Epoch 375/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2656 - accuracy: 0.9168 - val_loss: 0.4846 - val_accuracy: 0.8374\n",
            "Epoch 376/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.9129 - val_loss: 0.4858 - val_accuracy: 0.8369\n",
            "Epoch 377/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2620 - accuracy: 0.9178 - val_loss: 0.4914 - val_accuracy: 0.8319\n",
            "Epoch 378/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2623 - accuracy: 0.9177 - val_loss: 0.4897 - val_accuracy: 0.8335\n",
            "Epoch 379/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2676 - accuracy: 0.9196 - val_loss: 0.4833 - val_accuracy: 0.8401\n",
            "Epoch 380/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2695 - accuracy: 0.9164 - val_loss: 0.4753 - val_accuracy: 0.8385\n",
            "Epoch 381/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2717 - accuracy: 0.9144 - val_loss: 0.4836 - val_accuracy: 0.8366\n",
            "Epoch 382/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2639 - accuracy: 0.9178 - val_loss: 0.4854 - val_accuracy: 0.8366\n",
            "Epoch 383/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2680 - accuracy: 0.9165 - val_loss: 0.4708 - val_accuracy: 0.8406\n",
            "Epoch 384/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2686 - accuracy: 0.9182 - val_loss: 0.4737 - val_accuracy: 0.8396\n",
            "Epoch 385/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2679 - accuracy: 0.9153 - val_loss: 0.4808 - val_accuracy: 0.8382\n",
            "Epoch 386/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.9184 - val_loss: 0.4852 - val_accuracy: 0.8356\n",
            "Epoch 387/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.9180 - val_loss: 0.4832 - val_accuracy: 0.8385\n",
            "Epoch 388/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2695 - accuracy: 0.9164 - val_loss: 0.4773 - val_accuracy: 0.8409\n",
            "Epoch 389/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2654 - accuracy: 0.9169 - val_loss: 0.4806 - val_accuracy: 0.8396\n",
            "Epoch 390/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.9155 - val_loss: 0.4795 - val_accuracy: 0.8390\n",
            "Epoch 391/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2684 - accuracy: 0.9167 - val_loss: 0.4797 - val_accuracy: 0.8393\n",
            "Epoch 392/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2647 - accuracy: 0.9187 - val_loss: 0.4766 - val_accuracy: 0.8406\n",
            "Epoch 393/1000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.2653 - accuracy: 0.9149 - val_loss: 0.4819 - val_accuracy: 0.8343\n",
            "Epoch 394/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2733 - accuracy: 0.9179 - val_loss: 0.4768 - val_accuracy: 0.8388\n",
            "Epoch 395/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2676 - accuracy: 0.9167 - val_loss: 0.4628 - val_accuracy: 0.8441\n",
            "Epoch 396/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2621 - accuracy: 0.9171 - val_loss: 0.4666 - val_accuracy: 0.8446\n",
            "Epoch 397/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2641 - accuracy: 0.9175 - val_loss: 0.4865 - val_accuracy: 0.8348\n",
            "Epoch 398/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2613 - accuracy: 0.9144 - val_loss: 0.4825 - val_accuracy: 0.8369\n",
            "Epoch 399/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2650 - accuracy: 0.9196 - val_loss: 0.4835 - val_accuracy: 0.8364\n",
            "Epoch 400/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2653 - accuracy: 0.9141 - val_loss: 0.4872 - val_accuracy: 0.8327\n",
            "Epoch 401/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2651 - accuracy: 0.9177 - val_loss: 0.4765 - val_accuracy: 0.8398\n",
            "Epoch 402/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2647 - accuracy: 0.9200 - val_loss: 0.4761 - val_accuracy: 0.8398\n",
            "Epoch 403/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2564 - accuracy: 0.9173 - val_loss: 0.4944 - val_accuracy: 0.8321\n",
            "Epoch 404/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2609 - accuracy: 0.9183 - val_loss: 0.4772 - val_accuracy: 0.8372\n",
            "Epoch 405/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2664 - accuracy: 0.9155 - val_loss: 0.4713 - val_accuracy: 0.8377\n",
            "Epoch 406/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2655 - accuracy: 0.9122 - val_loss: 0.4845 - val_accuracy: 0.8356\n",
            "Epoch 407/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.9157 - val_loss: 0.4744 - val_accuracy: 0.8390\n",
            "Epoch 408/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2608 - accuracy: 0.9197 - val_loss: 0.4857 - val_accuracy: 0.8372\n",
            "Epoch 409/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2679 - accuracy: 0.9135 - val_loss: 0.4883 - val_accuracy: 0.8321\n",
            "Epoch 410/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2615 - accuracy: 0.9135 - val_loss: 0.4864 - val_accuracy: 0.8353\n",
            "Epoch 411/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2616 - accuracy: 0.9157 - val_loss: 0.4823 - val_accuracy: 0.8361\n",
            "Epoch 412/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2608 - accuracy: 0.9182 - val_loss: 0.4731 - val_accuracy: 0.8396\n",
            "Epoch 413/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2654 - accuracy: 0.9161 - val_loss: 0.4793 - val_accuracy: 0.8358\n",
            "Epoch 414/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2526 - accuracy: 0.9196 - val_loss: 0.4911 - val_accuracy: 0.8372\n",
            "Epoch 415/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2553 - accuracy: 0.9228 - val_loss: 0.4708 - val_accuracy: 0.8409\n",
            "Epoch 416/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2559 - accuracy: 0.9213 - val_loss: 0.4831 - val_accuracy: 0.8358\n",
            "Epoch 417/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2594 - accuracy: 0.9186 - val_loss: 0.4702 - val_accuracy: 0.8382\n",
            "Epoch 418/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2590 - accuracy: 0.9178 - val_loss: 0.4869 - val_accuracy: 0.8332\n",
            "Epoch 419/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2576 - accuracy: 0.9199 - val_loss: 0.4770 - val_accuracy: 0.8398\n",
            "Epoch 420/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2599 - accuracy: 0.9211 - val_loss: 0.4743 - val_accuracy: 0.8398\n",
            "Epoch 421/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2567 - accuracy: 0.9190 - val_loss: 0.4669 - val_accuracy: 0.8422\n",
            "Epoch 422/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2584 - accuracy: 0.9185 - val_loss: 0.4772 - val_accuracy: 0.8385\n",
            "Epoch 423/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2458 - accuracy: 0.9216 - val_loss: 0.4811 - val_accuracy: 0.8372\n",
            "Epoch 424/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2522 - accuracy: 0.9212 - val_loss: 0.4760 - val_accuracy: 0.8427\n",
            "Epoch 425/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2600 - accuracy: 0.9178 - val_loss: 0.4775 - val_accuracy: 0.8396\n",
            "Epoch 426/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2554 - accuracy: 0.9215 - val_loss: 0.4806 - val_accuracy: 0.8366\n",
            "Epoch 427/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2606 - accuracy: 0.9180 - val_loss: 0.4895 - val_accuracy: 0.8337\n",
            "Epoch 428/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2609 - accuracy: 0.9156 - val_loss: 0.4706 - val_accuracy: 0.8411\n",
            "Epoch 429/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2559 - accuracy: 0.9197 - val_loss: 0.4727 - val_accuracy: 0.8414\n",
            "Epoch 430/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2559 - accuracy: 0.9221 - val_loss: 0.4717 - val_accuracy: 0.8377\n",
            "Epoch 431/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.9202 - val_loss: 0.4787 - val_accuracy: 0.8388\n",
            "Epoch 432/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2493 - accuracy: 0.9237 - val_loss: 0.4757 - val_accuracy: 0.8401\n",
            "Epoch 433/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2537 - accuracy: 0.9219 - val_loss: 0.4751 - val_accuracy: 0.8403\n",
            "Epoch 434/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2606 - accuracy: 0.9188 - val_loss: 0.4873 - val_accuracy: 0.8374\n",
            "Epoch 435/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2525 - accuracy: 0.9238 - val_loss: 0.4760 - val_accuracy: 0.8401\n",
            "Epoch 436/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2649 - accuracy: 0.9183 - val_loss: 0.4672 - val_accuracy: 0.8427\n",
            "Epoch 437/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2575 - accuracy: 0.9193 - val_loss: 0.4761 - val_accuracy: 0.8393\n",
            "Epoch 438/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2591 - accuracy: 0.9244 - val_loss: 0.4771 - val_accuracy: 0.8358\n",
            "Epoch 439/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2579 - accuracy: 0.9201 - val_loss: 0.4862 - val_accuracy: 0.8358\n",
            "Epoch 440/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2500 - accuracy: 0.9221 - val_loss: 0.4823 - val_accuracy: 0.8388\n",
            "Epoch 441/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.9235 - val_loss: 0.4754 - val_accuracy: 0.8422\n",
            "Epoch 442/1000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.2547 - accuracy: 0.9224 - val_loss: 0.4776 - val_accuracy: 0.8377\n",
            "Epoch 443/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2534 - accuracy: 0.9215 - val_loss: 0.4828 - val_accuracy: 0.8382\n",
            "Epoch 444/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2416 - accuracy: 0.9289 - val_loss: 0.4711 - val_accuracy: 0.8430\n",
            "Epoch 445/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2541 - accuracy: 0.9180 - val_loss: 0.4855 - val_accuracy: 0.8358\n",
            "Epoch 446/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.9212 - val_loss: 0.4784 - val_accuracy: 0.8374\n",
            "Epoch 447/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2564 - accuracy: 0.9241 - val_loss: 0.4724 - val_accuracy: 0.8430\n",
            "Epoch 448/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2504 - accuracy: 0.9220 - val_loss: 0.4684 - val_accuracy: 0.8441\n",
            "Epoch 449/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2580 - accuracy: 0.9186 - val_loss: 0.4756 - val_accuracy: 0.8380\n",
            "Epoch 450/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2558 - accuracy: 0.9229 - val_loss: 0.4838 - val_accuracy: 0.8366\n",
            "Epoch 451/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2455 - accuracy: 0.9243 - val_loss: 0.4843 - val_accuracy: 0.8382\n",
            "Epoch 452/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2540 - accuracy: 0.9214 - val_loss: 0.4836 - val_accuracy: 0.8369\n",
            "Epoch 453/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2542 - accuracy: 0.9217 - val_loss: 0.4774 - val_accuracy: 0.8393\n",
            "Epoch 454/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2475 - accuracy: 0.9214 - val_loss: 0.4709 - val_accuracy: 0.8433\n",
            "Epoch 455/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2482 - accuracy: 0.9227 - val_loss: 0.4666 - val_accuracy: 0.8433\n",
            "Epoch 456/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2549 - accuracy: 0.9205 - val_loss: 0.4783 - val_accuracy: 0.8396\n",
            "Epoch 457/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2538 - accuracy: 0.9209 - val_loss: 0.4786 - val_accuracy: 0.8385\n",
            "Epoch 458/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.9201 - val_loss: 0.4662 - val_accuracy: 0.8441\n",
            "Epoch 459/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2514 - accuracy: 0.9213 - val_loss: 0.4714 - val_accuracy: 0.8435\n",
            "Epoch 460/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2485 - accuracy: 0.9218 - val_loss: 0.4716 - val_accuracy: 0.8419\n",
            "Epoch 461/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2433 - accuracy: 0.9232 - val_loss: 0.4760 - val_accuracy: 0.8396\n",
            "Epoch 462/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2479 - accuracy: 0.9214 - val_loss: 0.4736 - val_accuracy: 0.8401\n",
            "Epoch 463/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2463 - accuracy: 0.9245 - val_loss: 0.4774 - val_accuracy: 0.8396\n",
            "Epoch 464/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.9200 - val_loss: 0.4704 - val_accuracy: 0.8388\n",
            "Epoch 465/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.9233 - val_loss: 0.4791 - val_accuracy: 0.8390\n",
            "Epoch 466/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2443 - accuracy: 0.9293 - val_loss: 0.4712 - val_accuracy: 0.8419\n",
            "Epoch 467/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2506 - accuracy: 0.9225 - val_loss: 0.4667 - val_accuracy: 0.8425\n",
            "Epoch 468/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2473 - accuracy: 0.9228 - val_loss: 0.4734 - val_accuracy: 0.8422\n",
            "Epoch 469/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2438 - accuracy: 0.9229 - val_loss: 0.4834 - val_accuracy: 0.8348\n",
            "Epoch 470/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2433 - accuracy: 0.9240 - val_loss: 0.4898 - val_accuracy: 0.8351\n",
            "Epoch 471/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2498 - accuracy: 0.9220 - val_loss: 0.4785 - val_accuracy: 0.8385\n",
            "Epoch 472/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2500 - accuracy: 0.9209 - val_loss: 0.4824 - val_accuracy: 0.8380\n",
            "Epoch 473/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2450 - accuracy: 0.9263 - val_loss: 0.4713 - val_accuracy: 0.8419\n",
            "Epoch 474/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2547 - accuracy: 0.9212 - val_loss: 0.4743 - val_accuracy: 0.8396\n",
            "Epoch 475/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2499 - accuracy: 0.9208 - val_loss: 0.4687 - val_accuracy: 0.8380\n",
            "Epoch 476/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2557 - accuracy: 0.9203 - val_loss: 0.4803 - val_accuracy: 0.8396\n",
            "Epoch 477/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2469 - accuracy: 0.9236 - val_loss: 0.4797 - val_accuracy: 0.8388\n",
            "Epoch 478/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2464 - accuracy: 0.9219 - val_loss: 0.4708 - val_accuracy: 0.8382\n",
            "Epoch 479/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2529 - accuracy: 0.9228 - val_loss: 0.4754 - val_accuracy: 0.8403\n",
            "Epoch 480/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2437 - accuracy: 0.9246 - val_loss: 0.4789 - val_accuracy: 0.8419\n",
            "Epoch 481/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2543 - accuracy: 0.9241 - val_loss: 0.4648 - val_accuracy: 0.8427\n",
            "Epoch 482/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2445 - accuracy: 0.9233 - val_loss: 0.4770 - val_accuracy: 0.8390\n",
            "Epoch 483/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.9229 - val_loss: 0.4725 - val_accuracy: 0.8411\n",
            "Epoch 484/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2543 - accuracy: 0.9193 - val_loss: 0.4925 - val_accuracy: 0.8332\n",
            "Epoch 485/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2575 - accuracy: 0.9214 - val_loss: 0.4783 - val_accuracy: 0.8393\n",
            "Epoch 486/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.9250 - val_loss: 0.4896 - val_accuracy: 0.8356\n",
            "Epoch 487/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2450 - accuracy: 0.9277 - val_loss: 0.4835 - val_accuracy: 0.8358\n",
            "Epoch 488/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2463 - accuracy: 0.9258 - val_loss: 0.4805 - val_accuracy: 0.8385\n",
            "Epoch 489/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2544 - accuracy: 0.9221 - val_loss: 0.4823 - val_accuracy: 0.8374\n",
            "Epoch 490/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2439 - accuracy: 0.9230 - val_loss: 0.4833 - val_accuracy: 0.8380\n",
            "Epoch 491/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2393 - accuracy: 0.9255 - val_loss: 0.4809 - val_accuracy: 0.8374\n",
            "Epoch 492/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2457 - accuracy: 0.9216 - val_loss: 0.4809 - val_accuracy: 0.8372\n",
            "Epoch 493/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2353 - accuracy: 0.9287 - val_loss: 0.4698 - val_accuracy: 0.8411\n",
            "Epoch 494/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2440 - accuracy: 0.9210 - val_loss: 0.4767 - val_accuracy: 0.8396\n",
            "Epoch 495/1000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.2470 - accuracy: 0.9230 - val_loss: 0.4675 - val_accuracy: 0.8435\n",
            "Epoch 496/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2470 - accuracy: 0.9250 - val_loss: 0.4701 - val_accuracy: 0.8414\n",
            "Epoch 497/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2490 - accuracy: 0.9235 - val_loss: 0.4819 - val_accuracy: 0.8369\n",
            "Epoch 498/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2398 - accuracy: 0.9273 - val_loss: 0.4876 - val_accuracy: 0.8343\n",
            "Epoch 499/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2475 - accuracy: 0.9260 - val_loss: 0.4820 - val_accuracy: 0.8382\n",
            "Epoch 500/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2474 - accuracy: 0.9238 - val_loss: 0.4780 - val_accuracy: 0.8401\n",
            "Epoch 501/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2437 - accuracy: 0.9229 - val_loss: 0.4804 - val_accuracy: 0.8377\n",
            "Epoch 502/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.9237 - val_loss: 0.4895 - val_accuracy: 0.8361\n",
            "Epoch 503/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2403 - accuracy: 0.9236 - val_loss: 0.4923 - val_accuracy: 0.8366\n",
            "Epoch 504/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2502 - accuracy: 0.9211 - val_loss: 0.4804 - val_accuracy: 0.8403\n",
            "Epoch 505/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2418 - accuracy: 0.9261 - val_loss: 0.4687 - val_accuracy: 0.8435\n",
            "Epoch 506/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2444 - accuracy: 0.9245 - val_loss: 0.4709 - val_accuracy: 0.8427\n",
            "Epoch 507/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2404 - accuracy: 0.9253 - val_loss: 0.4742 - val_accuracy: 0.8401\n",
            "Epoch 508/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2395 - accuracy: 0.9258 - val_loss: 0.4799 - val_accuracy: 0.8369\n",
            "Epoch 509/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.9250 - val_loss: 0.4731 - val_accuracy: 0.8441\n",
            "Epoch 510/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2349 - accuracy: 0.9287 - val_loss: 0.4753 - val_accuracy: 0.8398\n",
            "Epoch 511/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2453 - accuracy: 0.9241 - val_loss: 0.4788 - val_accuracy: 0.8406\n",
            "Epoch 512/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2377 - accuracy: 0.9239 - val_loss: 0.4807 - val_accuracy: 0.8382\n",
            "Epoch 513/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2470 - accuracy: 0.9258 - val_loss: 0.4732 - val_accuracy: 0.8411\n",
            "Epoch 514/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2412 - accuracy: 0.9238 - val_loss: 0.4682 - val_accuracy: 0.8417\n",
            "Epoch 515/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2467 - accuracy: 0.9205 - val_loss: 0.4717 - val_accuracy: 0.8403\n",
            "Epoch 516/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2456 - accuracy: 0.9252 - val_loss: 0.4819 - val_accuracy: 0.8382\n",
            "Epoch 517/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2350 - accuracy: 0.9280 - val_loss: 0.4772 - val_accuracy: 0.8393\n",
            "Epoch 518/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2366 - accuracy: 0.9275 - val_loss: 0.4687 - val_accuracy: 0.8414\n",
            "Epoch 519/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2333 - accuracy: 0.9286 - val_loss: 0.4832 - val_accuracy: 0.8377\n",
            "Epoch 520/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2328 - accuracy: 0.9275 - val_loss: 0.4878 - val_accuracy: 0.8372\n",
            "Epoch 521/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2439 - accuracy: 0.9233 - val_loss: 0.4840 - val_accuracy: 0.8366\n",
            "Epoch 522/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2328 - accuracy: 0.9272 - val_loss: 0.4724 - val_accuracy: 0.8390\n",
            "Epoch 523/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2392 - accuracy: 0.9254 - val_loss: 0.4888 - val_accuracy: 0.8366\n",
            "Epoch 524/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2415 - accuracy: 0.9279 - val_loss: 0.4616 - val_accuracy: 0.8430\n",
            "Epoch 525/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2450 - accuracy: 0.9254 - val_loss: 0.4849 - val_accuracy: 0.8388\n",
            "Epoch 526/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2388 - accuracy: 0.9275 - val_loss: 0.4786 - val_accuracy: 0.8390\n",
            "Epoch 527/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2389 - accuracy: 0.9264 - val_loss: 0.4795 - val_accuracy: 0.8401\n",
            "Epoch 528/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2424 - accuracy: 0.9252 - val_loss: 0.4857 - val_accuracy: 0.8377\n",
            "Epoch 529/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2468 - accuracy: 0.9207 - val_loss: 0.4746 - val_accuracy: 0.8398\n",
            "Epoch 530/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2382 - accuracy: 0.9256 - val_loss: 0.4776 - val_accuracy: 0.8396\n",
            "Epoch 531/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2476 - accuracy: 0.9242 - val_loss: 0.4779 - val_accuracy: 0.8403\n",
            "Epoch 532/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2356 - accuracy: 0.9274 - val_loss: 0.4719 - val_accuracy: 0.8409\n",
            "Epoch 533/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2345 - accuracy: 0.9258 - val_loss: 0.4653 - val_accuracy: 0.8409\n",
            "Epoch 534/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2340 - accuracy: 0.9264 - val_loss: 0.4750 - val_accuracy: 0.8411\n",
            "Epoch 535/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2437 - accuracy: 0.9241 - val_loss: 0.4909 - val_accuracy: 0.8348\n",
            "Epoch 536/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2380 - accuracy: 0.9278 - val_loss: 0.4719 - val_accuracy: 0.8419\n",
            "Epoch 537/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2389 - accuracy: 0.9257 - val_loss: 0.4702 - val_accuracy: 0.8433\n",
            "Epoch 538/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2405 - accuracy: 0.9244 - val_loss: 0.4852 - val_accuracy: 0.8377\n",
            "Epoch 539/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2364 - accuracy: 0.9282 - val_loss: 0.4740 - val_accuracy: 0.8419\n",
            "Epoch 540/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2362 - accuracy: 0.9294 - val_loss: 0.4842 - val_accuracy: 0.8366\n",
            "Epoch 541/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2392 - accuracy: 0.9272 - val_loss: 0.4695 - val_accuracy: 0.8414\n",
            "Epoch 542/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2408 - accuracy: 0.9245 - val_loss: 0.4891 - val_accuracy: 0.8353\n",
            "Epoch 543/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2339 - accuracy: 0.9258 - val_loss: 0.4625 - val_accuracy: 0.8441\n",
            "Epoch 544/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2360 - accuracy: 0.9275 - val_loss: 0.4642 - val_accuracy: 0.8433\n",
            "Epoch 545/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2320 - accuracy: 0.9301 - val_loss: 0.4870 - val_accuracy: 0.8343\n",
            "Epoch 546/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2385 - accuracy: 0.9294 - val_loss: 0.4878 - val_accuracy: 0.8348\n",
            "Epoch 547/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2374 - accuracy: 0.9275 - val_loss: 0.4924 - val_accuracy: 0.8372\n",
            "Epoch 548/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2415 - accuracy: 0.9239 - val_loss: 0.4814 - val_accuracy: 0.8393\n",
            "Epoch 549/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2365 - accuracy: 0.9266 - val_loss: 0.4725 - val_accuracy: 0.8396\n",
            "Epoch 550/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2422 - accuracy: 0.9236 - val_loss: 0.4741 - val_accuracy: 0.8419\n",
            "Epoch 551/1000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.2379 - accuracy: 0.9246 - val_loss: 0.4790 - val_accuracy: 0.8390\n",
            "Epoch 552/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2395 - accuracy: 0.9256 - val_loss: 0.4777 - val_accuracy: 0.8372\n",
            "Epoch 553/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2337 - accuracy: 0.9275 - val_loss: 0.4828 - val_accuracy: 0.8374\n",
            "Epoch 554/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2353 - accuracy: 0.9289 - val_loss: 0.4750 - val_accuracy: 0.8393\n",
            "Epoch 555/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2358 - accuracy: 0.9277 - val_loss: 0.4751 - val_accuracy: 0.8401\n",
            "Epoch 556/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2420 - accuracy: 0.9250 - val_loss: 0.4813 - val_accuracy: 0.8388\n",
            "Epoch 557/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2363 - accuracy: 0.9281 - val_loss: 0.4803 - val_accuracy: 0.8343\n",
            "Epoch 558/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2369 - accuracy: 0.9287 - val_loss: 0.4663 - val_accuracy: 0.8462\n",
            "Epoch 559/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2328 - accuracy: 0.9270 - val_loss: 0.4728 - val_accuracy: 0.8393\n",
            "Epoch 560/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.9266 - val_loss: 0.4762 - val_accuracy: 0.8398\n",
            "Epoch 561/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2371 - accuracy: 0.9230 - val_loss: 0.4758 - val_accuracy: 0.8380\n",
            "Epoch 562/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2333 - accuracy: 0.9283 - val_loss: 0.4899 - val_accuracy: 0.8369\n",
            "Epoch 563/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2377 - accuracy: 0.9245 - val_loss: 0.5038 - val_accuracy: 0.8316\n",
            "Epoch 564/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2309 - accuracy: 0.9299 - val_loss: 0.4897 - val_accuracy: 0.8366\n",
            "Epoch 565/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2384 - accuracy: 0.9263 - val_loss: 0.4733 - val_accuracy: 0.8435\n",
            "Epoch 566/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2275 - accuracy: 0.9278 - val_loss: 0.4845 - val_accuracy: 0.8353\n",
            "Epoch 567/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2285 - accuracy: 0.9303 - val_loss: 0.4761 - val_accuracy: 0.8372\n",
            "Epoch 568/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2391 - accuracy: 0.9278 - val_loss: 0.4776 - val_accuracy: 0.8377\n",
            "Epoch 569/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2360 - accuracy: 0.9282 - val_loss: 0.4687 - val_accuracy: 0.8406\n",
            "Epoch 570/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2426 - accuracy: 0.9261 - val_loss: 0.4740 - val_accuracy: 0.8374\n",
            "Epoch 571/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2388 - accuracy: 0.9221 - val_loss: 0.4740 - val_accuracy: 0.8388\n",
            "Epoch 572/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2348 - accuracy: 0.9252 - val_loss: 0.4670 - val_accuracy: 0.8425\n",
            "Epoch 573/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2279 - accuracy: 0.9308 - val_loss: 0.4814 - val_accuracy: 0.8385\n",
            "Epoch 574/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2264 - accuracy: 0.9318 - val_loss: 0.4866 - val_accuracy: 0.8382\n",
            "Epoch 575/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2330 - accuracy: 0.9282 - val_loss: 0.4785 - val_accuracy: 0.8385\n",
            "Epoch 576/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2337 - accuracy: 0.9300 - val_loss: 0.4659 - val_accuracy: 0.8409\n",
            "Epoch 577/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2332 - accuracy: 0.9270 - val_loss: 0.4846 - val_accuracy: 0.8369\n",
            "Epoch 578/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2273 - accuracy: 0.9304 - val_loss: 0.4840 - val_accuracy: 0.8337\n",
            "Epoch 579/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2247 - accuracy: 0.9317 - val_loss: 0.4775 - val_accuracy: 0.8382\n",
            "Epoch 580/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2326 - accuracy: 0.9275 - val_loss: 0.4784 - val_accuracy: 0.8422\n",
            "Epoch 581/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2350 - accuracy: 0.9239 - val_loss: 0.4846 - val_accuracy: 0.8348\n",
            "Epoch 582/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2373 - accuracy: 0.9279 - val_loss: 0.4724 - val_accuracy: 0.8417\n",
            "Epoch 583/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2344 - accuracy: 0.9273 - val_loss: 0.4743 - val_accuracy: 0.8385\n",
            "Epoch 584/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2368 - accuracy: 0.9225 - val_loss: 0.4806 - val_accuracy: 0.8374\n",
            "Epoch 585/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2299 - accuracy: 0.9282 - val_loss: 0.4714 - val_accuracy: 0.8398\n",
            "Epoch 586/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2380 - accuracy: 0.9262 - val_loss: 0.4694 - val_accuracy: 0.8438\n",
            "Epoch 587/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2329 - accuracy: 0.9291 - val_loss: 0.4826 - val_accuracy: 0.8388\n",
            "Epoch 588/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2348 - accuracy: 0.9278 - val_loss: 0.4759 - val_accuracy: 0.8417\n",
            "Epoch 589/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2335 - accuracy: 0.9288 - val_loss: 0.4819 - val_accuracy: 0.8372\n",
            "Epoch 590/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2320 - accuracy: 0.9282 - val_loss: 0.4836 - val_accuracy: 0.8401\n",
            "Epoch 591/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2307 - accuracy: 0.9280 - val_loss: 0.4707 - val_accuracy: 0.8422\n",
            "Epoch 592/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2277 - accuracy: 0.9305 - val_loss: 0.4937 - val_accuracy: 0.8335\n",
            "Epoch 593/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2324 - accuracy: 0.9253 - val_loss: 0.4934 - val_accuracy: 0.8343\n",
            "Epoch 594/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2294 - accuracy: 0.9303 - val_loss: 0.4735 - val_accuracy: 0.8417\n",
            "Epoch 595/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2367 - accuracy: 0.9241 - val_loss: 0.4726 - val_accuracy: 0.8406\n",
            "Epoch 596/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2246 - accuracy: 0.9281 - val_loss: 0.4797 - val_accuracy: 0.8361\n",
            "Epoch 597/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2314 - accuracy: 0.9273 - val_loss: 0.4848 - val_accuracy: 0.8377\n",
            "Epoch 598/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2280 - accuracy: 0.9286 - val_loss: 0.4665 - val_accuracy: 0.8417\n",
            "Epoch 599/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2314 - accuracy: 0.9292 - val_loss: 0.4815 - val_accuracy: 0.8396\n",
            "Epoch 600/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2314 - accuracy: 0.9294 - val_loss: 0.4800 - val_accuracy: 0.8406\n",
            "Epoch 601/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2306 - accuracy: 0.9299 - val_loss: 0.4804 - val_accuracy: 0.8388\n",
            "Epoch 602/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2291 - accuracy: 0.9287 - val_loss: 0.4884 - val_accuracy: 0.8345\n",
            "Epoch 603/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2208 - accuracy: 0.9304 - val_loss: 0.4909 - val_accuracy: 0.8369\n",
            "Epoch 604/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2212 - accuracy: 0.9308 - val_loss: 0.4905 - val_accuracy: 0.8351\n",
            "Epoch 605/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2288 - accuracy: 0.9259 - val_loss: 0.4721 - val_accuracy: 0.8385\n",
            "Epoch 606/1000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.2318 - accuracy: 0.9307 - val_loss: 0.4748 - val_accuracy: 0.8401\n",
            "Epoch 607/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2262 - accuracy: 0.9313 - val_loss: 0.4827 - val_accuracy: 0.8382\n",
            "Epoch 608/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2293 - accuracy: 0.9314 - val_loss: 0.4742 - val_accuracy: 0.8419\n",
            "Epoch 609/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2323 - accuracy: 0.9273 - val_loss: 0.4821 - val_accuracy: 0.8385\n",
            "Epoch 610/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2191 - accuracy: 0.9328 - val_loss: 0.4950 - val_accuracy: 0.8316\n",
            "Epoch 611/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2381 - accuracy: 0.9264 - val_loss: 0.4722 - val_accuracy: 0.8419\n",
            "Epoch 612/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2307 - accuracy: 0.9292 - val_loss: 0.4679 - val_accuracy: 0.8441\n",
            "Epoch 613/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2293 - accuracy: 0.9289 - val_loss: 0.4686 - val_accuracy: 0.8422\n",
            "Epoch 614/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2290 - accuracy: 0.9297 - val_loss: 0.4940 - val_accuracy: 0.8319\n",
            "Epoch 615/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2280 - accuracy: 0.9303 - val_loss: 0.4830 - val_accuracy: 0.8348\n",
            "Epoch 616/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2313 - accuracy: 0.9294 - val_loss: 0.4786 - val_accuracy: 0.8340\n",
            "Epoch 617/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2190 - accuracy: 0.9332 - val_loss: 0.4680 - val_accuracy: 0.8438\n",
            "Epoch 618/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2300 - accuracy: 0.9275 - val_loss: 0.4919 - val_accuracy: 0.8308\n",
            "Epoch 619/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2253 - accuracy: 0.9301 - val_loss: 0.4777 - val_accuracy: 0.8393\n",
            "Epoch 620/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2220 - accuracy: 0.9303 - val_loss: 0.4868 - val_accuracy: 0.8353\n",
            "Epoch 621/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2202 - accuracy: 0.9309 - val_loss: 0.4831 - val_accuracy: 0.8329\n",
            "Epoch 622/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2288 - accuracy: 0.9291 - val_loss: 0.4894 - val_accuracy: 0.8337\n",
            "Epoch 623/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2247 - accuracy: 0.9290 - val_loss: 0.4799 - val_accuracy: 0.8396\n",
            "Epoch 624/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2259 - accuracy: 0.9276 - val_loss: 0.4895 - val_accuracy: 0.8332\n",
            "Epoch 625/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2284 - accuracy: 0.9284 - val_loss: 0.4854 - val_accuracy: 0.8372\n",
            "Epoch 626/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2335 - accuracy: 0.9271 - val_loss: 0.4982 - val_accuracy: 0.8306\n",
            "Epoch 627/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2350 - accuracy: 0.9258 - val_loss: 0.4721 - val_accuracy: 0.8417\n",
            "Epoch 628/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2326 - accuracy: 0.9270 - val_loss: 0.5061 - val_accuracy: 0.8274\n",
            "Epoch 629/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2273 - accuracy: 0.9300 - val_loss: 0.5129 - val_accuracy: 0.8263\n",
            "Epoch 630/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2355 - accuracy: 0.9254 - val_loss: 0.4902 - val_accuracy: 0.8356\n",
            "Epoch 631/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2324 - accuracy: 0.9257 - val_loss: 0.4764 - val_accuracy: 0.8406\n",
            "Epoch 632/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2223 - accuracy: 0.9315 - val_loss: 0.4825 - val_accuracy: 0.8380\n",
            "Epoch 633/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2243 - accuracy: 0.9294 - val_loss: 0.4968 - val_accuracy: 0.8282\n",
            "Epoch 634/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2189 - accuracy: 0.9321 - val_loss: 0.4743 - val_accuracy: 0.8430\n",
            "Epoch 635/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2270 - accuracy: 0.9317 - val_loss: 0.4877 - val_accuracy: 0.8372\n",
            "Epoch 636/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2298 - accuracy: 0.9291 - val_loss: 0.4964 - val_accuracy: 0.8345\n",
            "Epoch 637/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2251 - accuracy: 0.9306 - val_loss: 0.4879 - val_accuracy: 0.8348\n",
            "Epoch 638/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2266 - accuracy: 0.9330 - val_loss: 0.4826 - val_accuracy: 0.8364\n",
            "Epoch 639/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2170 - accuracy: 0.9319 - val_loss: 0.4921 - val_accuracy: 0.8340\n",
            "Epoch 640/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2230 - accuracy: 0.9294 - val_loss: 0.4801 - val_accuracy: 0.8366\n",
            "Epoch 641/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2250 - accuracy: 0.9262 - val_loss: 0.4729 - val_accuracy: 0.8398\n",
            "Epoch 642/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2263 - accuracy: 0.9309 - val_loss: 0.4652 - val_accuracy: 0.8414\n",
            "Epoch 643/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2241 - accuracy: 0.9295 - val_loss: 0.4828 - val_accuracy: 0.8348\n",
            "Epoch 644/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2279 - accuracy: 0.9282 - val_loss: 0.4735 - val_accuracy: 0.8422\n",
            "Epoch 645/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2236 - accuracy: 0.9317 - val_loss: 0.4725 - val_accuracy: 0.8425\n",
            "Epoch 646/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2208 - accuracy: 0.9331 - val_loss: 0.4798 - val_accuracy: 0.8353\n",
            "Epoch 647/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2282 - accuracy: 0.9308 - val_loss: 0.4916 - val_accuracy: 0.8313\n",
            "Epoch 648/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2231 - accuracy: 0.9298 - val_loss: 0.4851 - val_accuracy: 0.8335\n",
            "Epoch 649/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2241 - accuracy: 0.9306 - val_loss: 0.4954 - val_accuracy: 0.8276\n",
            "Epoch 650/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2255 - accuracy: 0.9274 - val_loss: 0.4899 - val_accuracy: 0.8345\n",
            "Epoch 651/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2247 - accuracy: 0.9292 - val_loss: 0.4637 - val_accuracy: 0.8449\n",
            "Epoch 652/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2230 - accuracy: 0.9317 - val_loss: 0.4717 - val_accuracy: 0.8401\n",
            "Epoch 653/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2251 - accuracy: 0.9276 - val_loss: 0.4882 - val_accuracy: 0.8361\n",
            "Epoch 654/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2162 - accuracy: 0.9334 - val_loss: 0.4927 - val_accuracy: 0.8306\n",
            "Epoch 655/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2208 - accuracy: 0.9298 - val_loss: 0.4907 - val_accuracy: 0.8308\n",
            "Epoch 656/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2235 - accuracy: 0.9281 - val_loss: 0.4864 - val_accuracy: 0.8364\n",
            "Epoch 657/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2158 - accuracy: 0.9358 - val_loss: 0.4774 - val_accuracy: 0.8396\n",
            "Epoch 658/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2196 - accuracy: 0.9315 - val_loss: 0.4767 - val_accuracy: 0.8380\n",
            "Epoch 659/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2190 - accuracy: 0.9321 - val_loss: 0.4733 - val_accuracy: 0.8417\n",
            "Epoch 660/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2195 - accuracy: 0.9318 - val_loss: 0.4744 - val_accuracy: 0.8414\n",
            "Epoch 661/1000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.2294 - accuracy: 0.9292 - val_loss: 0.4827 - val_accuracy: 0.8324\n",
            "Epoch 662/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2195 - accuracy: 0.9311 - val_loss: 0.4737 - val_accuracy: 0.8409\n",
            "Epoch 663/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2198 - accuracy: 0.9322 - val_loss: 0.4896 - val_accuracy: 0.8253\n",
            "Epoch 664/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2246 - accuracy: 0.9311 - val_loss: 0.4832 - val_accuracy: 0.8327\n",
            "Epoch 665/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2326 - accuracy: 0.9251 - val_loss: 0.4680 - val_accuracy: 0.8398\n",
            "Epoch 666/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2188 - accuracy: 0.9338 - val_loss: 0.4774 - val_accuracy: 0.8321\n",
            "Epoch 667/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2276 - accuracy: 0.9287 - val_loss: 0.4945 - val_accuracy: 0.8276\n",
            "Epoch 668/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2153 - accuracy: 0.9335 - val_loss: 0.4955 - val_accuracy: 0.8258\n",
            "Epoch 669/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2227 - accuracy: 0.9297 - val_loss: 0.4745 - val_accuracy: 0.8345\n",
            "Epoch 670/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2231 - accuracy: 0.9304 - val_loss: 0.4892 - val_accuracy: 0.8303\n",
            "Epoch 671/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2212 - accuracy: 0.9305 - val_loss: 0.4836 - val_accuracy: 0.8303\n",
            "Epoch 672/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2186 - accuracy: 0.9320 - val_loss: 0.4893 - val_accuracy: 0.8316\n",
            "Epoch 673/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2197 - accuracy: 0.9310 - val_loss: 0.4674 - val_accuracy: 0.8372\n",
            "Epoch 674/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2252 - accuracy: 0.9305 - val_loss: 0.4806 - val_accuracy: 0.8380\n",
            "Epoch 675/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2249 - accuracy: 0.9287 - val_loss: 0.4867 - val_accuracy: 0.8332\n",
            "Epoch 676/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2218 - accuracy: 0.9309 - val_loss: 0.4802 - val_accuracy: 0.8313\n",
            "Epoch 677/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2258 - accuracy: 0.9325 - val_loss: 0.4716 - val_accuracy: 0.8393\n",
            "Epoch 678/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2182 - accuracy: 0.9315 - val_loss: 0.4862 - val_accuracy: 0.8345\n",
            "Epoch 679/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2266 - accuracy: 0.9268 - val_loss: 0.4972 - val_accuracy: 0.8274\n",
            "Epoch 680/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.9351 - val_loss: 0.4896 - val_accuracy: 0.8250\n",
            "Epoch 681/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2221 - accuracy: 0.9303 - val_loss: 0.4542 - val_accuracy: 0.8438\n",
            "Epoch 682/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2206 - accuracy: 0.9312 - val_loss: 0.4865 - val_accuracy: 0.8311\n",
            "Epoch 683/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2158 - accuracy: 0.9332 - val_loss: 0.4963 - val_accuracy: 0.8306\n",
            "Epoch 684/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2181 - accuracy: 0.9325 - val_loss: 0.4784 - val_accuracy: 0.8366\n",
            "Epoch 685/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2175 - accuracy: 0.9313 - val_loss: 0.4769 - val_accuracy: 0.8356\n",
            "Epoch 686/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2240 - accuracy: 0.9276 - val_loss: 0.4894 - val_accuracy: 0.8303\n",
            "Epoch 687/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2183 - accuracy: 0.9319 - val_loss: 0.4642 - val_accuracy: 0.8419\n",
            "Epoch 688/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2291 - accuracy: 0.9272 - val_loss: 0.5021 - val_accuracy: 0.8268\n",
            "Epoch 689/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2152 - accuracy: 0.9338 - val_loss: 0.4835 - val_accuracy: 0.8324\n",
            "Epoch 690/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2179 - accuracy: 0.9355 - val_loss: 0.4830 - val_accuracy: 0.8321\n",
            "Epoch 691/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2187 - accuracy: 0.9318 - val_loss: 0.5276 - val_accuracy: 0.8163\n",
            "Epoch 692/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.9303 - val_loss: 0.4985 - val_accuracy: 0.8279\n",
            "Epoch 693/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2174 - accuracy: 0.9327 - val_loss: 0.4784 - val_accuracy: 0.8374\n",
            "Epoch 694/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2193 - accuracy: 0.9301 - val_loss: 0.5063 - val_accuracy: 0.8276\n",
            "Epoch 695/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 0.9281 - val_loss: 0.4949 - val_accuracy: 0.8282\n",
            "Epoch 696/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2177 - accuracy: 0.9310 - val_loss: 0.4976 - val_accuracy: 0.8303\n",
            "Epoch 697/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2226 - accuracy: 0.9320 - val_loss: 0.5085 - val_accuracy: 0.8274\n",
            "Epoch 698/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2137 - accuracy: 0.9307 - val_loss: 0.4874 - val_accuracy: 0.8284\n",
            "Epoch 699/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2123 - accuracy: 0.9358 - val_loss: 0.4774 - val_accuracy: 0.8396\n",
            "Epoch 700/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2178 - accuracy: 0.9340 - val_loss: 0.4847 - val_accuracy: 0.8321\n",
            "Epoch 701/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2172 - accuracy: 0.9343 - val_loss: 0.4779 - val_accuracy: 0.8382\n",
            "Epoch 702/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2227 - accuracy: 0.9289 - val_loss: 0.4679 - val_accuracy: 0.8393\n",
            "Epoch 703/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2209 - accuracy: 0.9342 - val_loss: 0.4692 - val_accuracy: 0.8356\n",
            "Epoch 704/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2209 - accuracy: 0.9317 - val_loss: 0.5178 - val_accuracy: 0.8202\n",
            "Epoch 705/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2132 - accuracy: 0.9319 - val_loss: 0.4766 - val_accuracy: 0.8366\n",
            "Epoch 706/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2186 - accuracy: 0.9314 - val_loss: 0.5139 - val_accuracy: 0.8234\n",
            "Epoch 707/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2173 - accuracy: 0.9342 - val_loss: 0.4865 - val_accuracy: 0.8340\n",
            "Epoch 708/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2217 - accuracy: 0.9308 - val_loss: 0.4953 - val_accuracy: 0.8271\n",
            "Epoch 709/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 0.9320 - val_loss: 0.4978 - val_accuracy: 0.8263\n",
            "Epoch 710/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2157 - accuracy: 0.9339 - val_loss: 0.4869 - val_accuracy: 0.8284\n",
            "Epoch 711/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2233 - accuracy: 0.9326 - val_loss: 0.4990 - val_accuracy: 0.8311\n",
            "Epoch 712/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2198 - accuracy: 0.9317 - val_loss: 0.5139 - val_accuracy: 0.8226\n",
            "Epoch 713/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2135 - accuracy: 0.9334 - val_loss: 0.4894 - val_accuracy: 0.8335\n",
            "Epoch 714/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2140 - accuracy: 0.9305 - val_loss: 0.4936 - val_accuracy: 0.8298\n",
            "Epoch 715/1000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.2219 - accuracy: 0.9312 - val_loss: 0.5018 - val_accuracy: 0.8268\n",
            "Epoch 716/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 0.9304 - val_loss: 0.5089 - val_accuracy: 0.8242\n",
            "Epoch 717/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2092 - accuracy: 0.9312 - val_loss: 0.4682 - val_accuracy: 0.8390\n",
            "Epoch 718/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2262 - accuracy: 0.9257 - val_loss: 0.4940 - val_accuracy: 0.8284\n",
            "Epoch 719/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2136 - accuracy: 0.9360 - val_loss: 0.4929 - val_accuracy: 0.8290\n",
            "Epoch 720/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2111 - accuracy: 0.9323 - val_loss: 0.4670 - val_accuracy: 0.8382\n",
            "Epoch 721/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2210 - accuracy: 0.9299 - val_loss: 0.4777 - val_accuracy: 0.8356\n",
            "Epoch 722/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2195 - accuracy: 0.9280 - val_loss: 0.4786 - val_accuracy: 0.8345\n",
            "Epoch 723/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2141 - accuracy: 0.9326 - val_loss: 0.4960 - val_accuracy: 0.8300\n",
            "Epoch 724/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2182 - accuracy: 0.9302 - val_loss: 0.5077 - val_accuracy: 0.8261\n",
            "Epoch 725/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2149 - accuracy: 0.9320 - val_loss: 0.5081 - val_accuracy: 0.8253\n",
            "Epoch 726/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2084 - accuracy: 0.9352 - val_loss: 0.5330 - val_accuracy: 0.8160\n",
            "Epoch 727/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2135 - accuracy: 0.9335 - val_loss: 0.4701 - val_accuracy: 0.8409\n",
            "Epoch 728/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2181 - accuracy: 0.9322 - val_loss: 0.5120 - val_accuracy: 0.8258\n",
            "Epoch 729/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2108 - accuracy: 0.9341 - val_loss: 0.4975 - val_accuracy: 0.8284\n",
            "Epoch 730/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2076 - accuracy: 0.9351 - val_loss: 0.4849 - val_accuracy: 0.8313\n",
            "Epoch 731/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2160 - accuracy: 0.9337 - val_loss: 0.4787 - val_accuracy: 0.8335\n",
            "Epoch 732/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2168 - accuracy: 0.9335 - val_loss: 0.4748 - val_accuracy: 0.8351\n",
            "Epoch 733/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2160 - accuracy: 0.9315 - val_loss: 0.4660 - val_accuracy: 0.8393\n",
            "Epoch 734/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2158 - accuracy: 0.9325 - val_loss: 0.5109 - val_accuracy: 0.8253\n",
            "Epoch 735/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2229 - accuracy: 0.9289 - val_loss: 0.4816 - val_accuracy: 0.8337\n",
            "Epoch 736/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2109 - accuracy: 0.9335 - val_loss: 0.4705 - val_accuracy: 0.8345\n",
            "Epoch 737/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2158 - accuracy: 0.9322 - val_loss: 0.4870 - val_accuracy: 0.8287\n",
            "Epoch 738/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2171 - accuracy: 0.9301 - val_loss: 0.4720 - val_accuracy: 0.8393\n",
            "Epoch 739/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2144 - accuracy: 0.9313 - val_loss: 0.5159 - val_accuracy: 0.8247\n",
            "Epoch 740/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2135 - accuracy: 0.9335 - val_loss: 0.5003 - val_accuracy: 0.8279\n",
            "Epoch 741/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2130 - accuracy: 0.9329 - val_loss: 0.5065 - val_accuracy: 0.8226\n",
            "Epoch 742/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2193 - accuracy: 0.9306 - val_loss: 0.4747 - val_accuracy: 0.8390\n",
            "Epoch 743/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2097 - accuracy: 0.9337 - val_loss: 0.4953 - val_accuracy: 0.8274\n",
            "Epoch 744/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2198 - accuracy: 0.9312 - val_loss: 0.4871 - val_accuracy: 0.8290\n",
            "Epoch 745/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2142 - accuracy: 0.9301 - val_loss: 0.4859 - val_accuracy: 0.8292\n",
            "Epoch 746/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2139 - accuracy: 0.9315 - val_loss: 0.4968 - val_accuracy: 0.8279\n",
            "Epoch 747/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2133 - accuracy: 0.9324 - val_loss: 0.4984 - val_accuracy: 0.8282\n",
            "Epoch 748/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2138 - accuracy: 0.9322 - val_loss: 0.5170 - val_accuracy: 0.8226\n",
            "Epoch 749/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2179 - accuracy: 0.9302 - val_loss: 0.4905 - val_accuracy: 0.8287\n",
            "Epoch 750/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2116 - accuracy: 0.9327 - val_loss: 0.4899 - val_accuracy: 0.8282\n",
            "Epoch 751/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2085 - accuracy: 0.9351 - val_loss: 0.4834 - val_accuracy: 0.8335\n",
            "Epoch 752/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2104 - accuracy: 0.9335 - val_loss: 0.4967 - val_accuracy: 0.8279\n",
            "Epoch 753/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2175 - accuracy: 0.9353 - val_loss: 0.5118 - val_accuracy: 0.8194\n",
            "Epoch 754/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2147 - accuracy: 0.9299 - val_loss: 0.4754 - val_accuracy: 0.8353\n",
            "Epoch 755/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.9354 - val_loss: 0.4993 - val_accuracy: 0.8274\n",
            "Epoch 756/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2057 - accuracy: 0.9342 - val_loss: 0.5046 - val_accuracy: 0.8282\n",
            "Epoch 757/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2110 - accuracy: 0.9342 - val_loss: 0.4814 - val_accuracy: 0.8351\n",
            "Epoch 758/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2096 - accuracy: 0.9348 - val_loss: 0.4846 - val_accuracy: 0.8313\n",
            "Epoch 759/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2066 - accuracy: 0.9372 - val_loss: 0.4928 - val_accuracy: 0.8266\n",
            "Epoch 760/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2117 - accuracy: 0.9364 - val_loss: 0.4727 - val_accuracy: 0.8353\n",
            "Epoch 761/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2079 - accuracy: 0.9344 - val_loss: 0.4798 - val_accuracy: 0.8321\n",
            "Epoch 762/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2111 - accuracy: 0.9347 - val_loss: 0.4809 - val_accuracy: 0.8361\n",
            "Epoch 763/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2159 - accuracy: 0.9327 - val_loss: 0.4787 - val_accuracy: 0.8351\n",
            "Epoch 764/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2057 - accuracy: 0.9364 - val_loss: 0.4898 - val_accuracy: 0.8308\n",
            "Epoch 765/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2168 - accuracy: 0.9334 - val_loss: 0.4883 - val_accuracy: 0.8303\n",
            "Epoch 766/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2114 - accuracy: 0.9320 - val_loss: 0.4892 - val_accuracy: 0.8295\n",
            "Epoch 767/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2125 - accuracy: 0.9354 - val_loss: 0.4889 - val_accuracy: 0.8345\n",
            "Epoch 768/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1983 - accuracy: 0.9383 - val_loss: 0.4881 - val_accuracy: 0.8316\n",
            "Epoch 769/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2005 - accuracy: 0.9367 - val_loss: 0.4848 - val_accuracy: 0.8335\n",
            "Epoch 770/1000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.2079 - accuracy: 0.9322 - val_loss: 0.4943 - val_accuracy: 0.8306\n",
            "Epoch 771/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2130 - accuracy: 0.9338 - val_loss: 0.4889 - val_accuracy: 0.8298\n",
            "Epoch 772/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2075 - accuracy: 0.9375 - val_loss: 0.4878 - val_accuracy: 0.8329\n",
            "Epoch 773/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2077 - accuracy: 0.9341 - val_loss: 0.4710 - val_accuracy: 0.8356\n",
            "Epoch 774/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2064 - accuracy: 0.9355 - val_loss: 0.4849 - val_accuracy: 0.8321\n",
            "Epoch 775/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2087 - accuracy: 0.9344 - val_loss: 0.4811 - val_accuracy: 0.8351\n",
            "Epoch 776/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2156 - accuracy: 0.9296 - val_loss: 0.4999 - val_accuracy: 0.8292\n",
            "Epoch 777/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2059 - accuracy: 0.9339 - val_loss: 0.4757 - val_accuracy: 0.8382\n",
            "Epoch 778/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2112 - accuracy: 0.9340 - val_loss: 0.4784 - val_accuracy: 0.8337\n",
            "Epoch 779/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2078 - accuracy: 0.9352 - val_loss: 0.4981 - val_accuracy: 0.8287\n",
            "Epoch 780/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2088 - accuracy: 0.9331 - val_loss: 0.4942 - val_accuracy: 0.8287\n",
            "Epoch 781/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2181 - accuracy: 0.9297 - val_loss: 0.4789 - val_accuracy: 0.8337\n",
            "Epoch 782/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2098 - accuracy: 0.9336 - val_loss: 0.4917 - val_accuracy: 0.8279\n",
            "Epoch 783/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2136 - accuracy: 0.9317 - val_loss: 0.4905 - val_accuracy: 0.8290\n",
            "Epoch 784/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2071 - accuracy: 0.9340 - val_loss: 0.4850 - val_accuracy: 0.8311\n",
            "Epoch 785/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2095 - accuracy: 0.9329 - val_loss: 0.5064 - val_accuracy: 0.8221\n",
            "Epoch 786/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2103 - accuracy: 0.9341 - val_loss: 0.4707 - val_accuracy: 0.8356\n",
            "Epoch 787/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2113 - accuracy: 0.9350 - val_loss: 0.4985 - val_accuracy: 0.8279\n",
            "Epoch 788/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2094 - accuracy: 0.9346 - val_loss: 0.4747 - val_accuracy: 0.8353\n",
            "Epoch 789/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2067 - accuracy: 0.9373 - val_loss: 0.4814 - val_accuracy: 0.8329\n",
            "Epoch 790/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2026 - accuracy: 0.9376 - val_loss: 0.5003 - val_accuracy: 0.8284\n",
            "Epoch 791/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2067 - accuracy: 0.9353 - val_loss: 0.5135 - val_accuracy: 0.8178\n",
            "Epoch 792/1000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2059 - accuracy: 0.9363 - val_loss: 0.5062 - val_accuracy: 0.8242\n",
            "Epoch 793/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2112 - accuracy: 0.9335 - val_loss: 0.5142 - val_accuracy: 0.8242\n",
            "Epoch 794/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2021 - accuracy: 0.9369 - val_loss: 0.5089 - val_accuracy: 0.8223\n",
            "Epoch 795/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2048 - accuracy: 0.9361 - val_loss: 0.5035 - val_accuracy: 0.8221\n",
            "Epoch 796/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2136 - accuracy: 0.9324 - val_loss: 0.4738 - val_accuracy: 0.8393\n",
            "Epoch 797/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2156 - accuracy: 0.9338 - val_loss: 0.5008 - val_accuracy: 0.8266\n",
            "Epoch 798/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2125 - accuracy: 0.9335 - val_loss: 0.5233 - val_accuracy: 0.8208\n",
            "Epoch 799/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2064 - accuracy: 0.9332 - val_loss: 0.5083 - val_accuracy: 0.8261\n",
            "Epoch 800/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2056 - accuracy: 0.9349 - val_loss: 0.5301 - val_accuracy: 0.8157\n",
            "Epoch 801/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2067 - accuracy: 0.9362 - val_loss: 0.5013 - val_accuracy: 0.8253\n",
            "Epoch 802/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2110 - accuracy: 0.9337 - val_loss: 0.4825 - val_accuracy: 0.8313\n",
            "Epoch 803/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2053 - accuracy: 0.9343 - val_loss: 0.5090 - val_accuracy: 0.8226\n",
            "Epoch 804/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2112 - accuracy: 0.9338 - val_loss: 0.4971 - val_accuracy: 0.8253\n",
            "Epoch 805/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2059 - accuracy: 0.9348 - val_loss: 0.4938 - val_accuracy: 0.8298\n",
            "Epoch 806/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2076 - accuracy: 0.9366 - val_loss: 0.4999 - val_accuracy: 0.8300\n",
            "Epoch 807/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2148 - accuracy: 0.9304 - val_loss: 0.4719 - val_accuracy: 0.8385\n",
            "Epoch 808/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2111 - accuracy: 0.9344 - val_loss: 0.5004 - val_accuracy: 0.8287\n",
            "Epoch 809/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2068 - accuracy: 0.9372 - val_loss: 0.4975 - val_accuracy: 0.8287\n",
            "Epoch 810/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2048 - accuracy: 0.9355 - val_loss: 0.5064 - val_accuracy: 0.8242\n",
            "Epoch 811/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2126 - accuracy: 0.9330 - val_loss: 0.4991 - val_accuracy: 0.8242\n",
            "Epoch 812/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2097 - accuracy: 0.9327 - val_loss: 0.5322 - val_accuracy: 0.8139\n",
            "Epoch 813/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2013 - accuracy: 0.9384 - val_loss: 0.4923 - val_accuracy: 0.8287\n",
            "Epoch 814/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2051 - accuracy: 0.9339 - val_loss: 0.4988 - val_accuracy: 0.8287\n",
            "Epoch 815/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2020 - accuracy: 0.9373 - val_loss: 0.5109 - val_accuracy: 0.8163\n",
            "Epoch 816/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2082 - accuracy: 0.9330 - val_loss: 0.5343 - val_accuracy: 0.8160\n",
            "Epoch 817/1000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.2036 - accuracy: 0.9359 - val_loss: 0.4912 - val_accuracy: 0.8321\n",
            "Epoch 818/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2094 - accuracy: 0.9321 - val_loss: 0.4833 - val_accuracy: 0.8329\n",
            "Epoch 819/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2098 - accuracy: 0.9346 - val_loss: 0.5085 - val_accuracy: 0.8221\n",
            "Epoch 820/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2050 - accuracy: 0.9380 - val_loss: 0.4793 - val_accuracy: 0.8343\n",
            "Epoch 821/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2035 - accuracy: 0.9355 - val_loss: 0.4866 - val_accuracy: 0.8298\n",
            "Epoch 822/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2033 - accuracy: 0.9360 - val_loss: 0.4832 - val_accuracy: 0.8306\n",
            "Epoch 823/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1986 - accuracy: 0.9371 - val_loss: 0.4844 - val_accuracy: 0.8306\n",
            "Epoch 824/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2040 - accuracy: 0.9401 - val_loss: 0.4947 - val_accuracy: 0.8284\n",
            "Epoch 825/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2085 - accuracy: 0.9346 - val_loss: 0.4881 - val_accuracy: 0.8303\n",
            "Epoch 826/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2076 - accuracy: 0.9350 - val_loss: 0.5071 - val_accuracy: 0.8210\n",
            "Epoch 827/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2012 - accuracy: 0.9370 - val_loss: 0.5029 - val_accuracy: 0.8276\n",
            "Epoch 828/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2078 - accuracy: 0.9363 - val_loss: 0.5090 - val_accuracy: 0.8242\n",
            "Epoch 829/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2064 - accuracy: 0.9362 - val_loss: 0.4708 - val_accuracy: 0.8372\n",
            "Epoch 830/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2101 - accuracy: 0.9352 - val_loss: 0.4986 - val_accuracy: 0.8261\n",
            "Epoch 831/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2021 - accuracy: 0.9364 - val_loss: 0.4836 - val_accuracy: 0.8308\n",
            "Epoch 832/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2019 - accuracy: 0.9368 - val_loss: 0.5148 - val_accuracy: 0.8181\n",
            "Epoch 833/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2016 - accuracy: 0.9373 - val_loss: 0.4960 - val_accuracy: 0.8319\n",
            "Epoch 834/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1952 - accuracy: 0.9387 - val_loss: 0.4907 - val_accuracy: 0.8319\n",
            "Epoch 835/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2062 - accuracy: 0.9354 - val_loss: 0.5092 - val_accuracy: 0.8234\n",
            "Epoch 836/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2037 - accuracy: 0.9362 - val_loss: 0.4961 - val_accuracy: 0.8279\n",
            "Epoch 837/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2029 - accuracy: 0.9378 - val_loss: 0.4677 - val_accuracy: 0.8382\n",
            "Epoch 838/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2166 - accuracy: 0.9314 - val_loss: 0.4569 - val_accuracy: 0.8438\n",
            "Epoch 839/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2068 - accuracy: 0.9347 - val_loss: 0.4908 - val_accuracy: 0.8261\n",
            "Epoch 840/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1988 - accuracy: 0.9377 - val_loss: 0.5044 - val_accuracy: 0.8255\n",
            "Epoch 841/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1993 - accuracy: 0.9378 - val_loss: 0.4752 - val_accuracy: 0.8345\n",
            "Epoch 842/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2064 - accuracy: 0.9355 - val_loss: 0.4872 - val_accuracy: 0.8290\n",
            "Epoch 843/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2016 - accuracy: 0.9381 - val_loss: 0.5024 - val_accuracy: 0.8255\n",
            "Epoch 844/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2022 - accuracy: 0.9373 - val_loss: 0.5077 - val_accuracy: 0.8247\n",
            "Epoch 845/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2023 - accuracy: 0.9378 - val_loss: 0.4917 - val_accuracy: 0.8292\n",
            "Epoch 846/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1988 - accuracy: 0.9364 - val_loss: 0.4927 - val_accuracy: 0.8287\n",
            "Epoch 847/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.9385 - val_loss: 0.5039 - val_accuracy: 0.8242\n",
            "Epoch 848/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2078 - accuracy: 0.9331 - val_loss: 0.5022 - val_accuracy: 0.8239\n",
            "Epoch 849/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2109 - accuracy: 0.9386 - val_loss: 0.4755 - val_accuracy: 0.8366\n",
            "Epoch 850/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2016 - accuracy: 0.9383 - val_loss: 0.5256 - val_accuracy: 0.8144\n",
            "Epoch 851/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1949 - accuracy: 0.9390 - val_loss: 0.5044 - val_accuracy: 0.8216\n",
            "Epoch 852/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1982 - accuracy: 0.9374 - val_loss: 0.4911 - val_accuracy: 0.8308\n",
            "Epoch 853/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2044 - accuracy: 0.9351 - val_loss: 0.5060 - val_accuracy: 0.8221\n",
            "Epoch 854/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2005 - accuracy: 0.9393 - val_loss: 0.5354 - val_accuracy: 0.8088\n",
            "Epoch 855/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2086 - accuracy: 0.9334 - val_loss: 0.5039 - val_accuracy: 0.8271\n",
            "Epoch 856/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2028 - accuracy: 0.9389 - val_loss: 0.5038 - val_accuracy: 0.8253\n",
            "Epoch 857/1000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.2005 - accuracy: 0.9374 - val_loss: 0.5065 - val_accuracy: 0.8234\n",
            "Epoch 858/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2036 - accuracy: 0.9363 - val_loss: 0.4900 - val_accuracy: 0.8319\n",
            "Epoch 859/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2047 - accuracy: 0.9354 - val_loss: 0.4811 - val_accuracy: 0.8337\n",
            "Epoch 860/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2004 - accuracy: 0.9368 - val_loss: 0.5237 - val_accuracy: 0.8178\n",
            "Epoch 861/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2084 - accuracy: 0.9362 - val_loss: 0.5033 - val_accuracy: 0.8271\n",
            "Epoch 862/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2049 - accuracy: 0.9379 - val_loss: 0.4921 - val_accuracy: 0.8292\n",
            "Epoch 863/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2035 - accuracy: 0.9343 - val_loss: 0.5098 - val_accuracy: 0.8242\n",
            "Epoch 864/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2015 - accuracy: 0.9387 - val_loss: 0.4985 - val_accuracy: 0.8290\n",
            "Epoch 865/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2038 - accuracy: 0.9353 - val_loss: 0.4844 - val_accuracy: 0.8300\n",
            "Epoch 866/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2068 - accuracy: 0.9337 - val_loss: 0.4967 - val_accuracy: 0.8284\n",
            "Epoch 867/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2014 - accuracy: 0.9371 - val_loss: 0.5058 - val_accuracy: 0.8210\n",
            "Epoch 868/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1981 - accuracy: 0.9358 - val_loss: 0.4829 - val_accuracy: 0.8292\n",
            "Epoch 869/1000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.2077 - accuracy: 0.9344 - val_loss: 0.4918 - val_accuracy: 0.8266\n",
            "Epoch 870/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2020 - accuracy: 0.9378 - val_loss: 0.4865 - val_accuracy: 0.8303\n",
            "Epoch 871/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2061 - accuracy: 0.9355 - val_loss: 0.4829 - val_accuracy: 0.8348\n",
            "Epoch 872/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1993 - accuracy: 0.9375 - val_loss: 0.5093 - val_accuracy: 0.8200\n",
            "Epoch 873/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1990 - accuracy: 0.9385 - val_loss: 0.4999 - val_accuracy: 0.8274\n",
            "Epoch 874/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1963 - accuracy: 0.9382 - val_loss: 0.5060 - val_accuracy: 0.8216\n",
            "Epoch 875/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1989 - accuracy: 0.9405 - val_loss: 0.5033 - val_accuracy: 0.8245\n",
            "Epoch 876/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1962 - accuracy: 0.9352 - val_loss: 0.5049 - val_accuracy: 0.8239\n",
            "Epoch 877/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1994 - accuracy: 0.9395 - val_loss: 0.4922 - val_accuracy: 0.8311\n",
            "Epoch 878/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2036 - accuracy: 0.9351 - val_loss: 0.4729 - val_accuracy: 0.8356\n",
            "Epoch 879/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2007 - accuracy: 0.9376 - val_loss: 0.5007 - val_accuracy: 0.8284\n",
            "Epoch 880/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2017 - accuracy: 0.9347 - val_loss: 0.4931 - val_accuracy: 0.8306\n",
            "Epoch 881/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1995 - accuracy: 0.9366 - val_loss: 0.4969 - val_accuracy: 0.8266\n",
            "Epoch 882/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2045 - accuracy: 0.9356 - val_loss: 0.4618 - val_accuracy: 0.8411\n",
            "Epoch 883/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2034 - accuracy: 0.9355 - val_loss: 0.4998 - val_accuracy: 0.8258\n",
            "Epoch 884/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1994 - accuracy: 0.9387 - val_loss: 0.4913 - val_accuracy: 0.8303\n",
            "Epoch 885/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1951 - accuracy: 0.9387 - val_loss: 0.4917 - val_accuracy: 0.8287\n",
            "Epoch 886/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1995 - accuracy: 0.9365 - val_loss: 0.4935 - val_accuracy: 0.8255\n",
            "Epoch 887/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1983 - accuracy: 0.9396 - val_loss: 0.5081 - val_accuracy: 0.8234\n",
            "Epoch 888/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1970 - accuracy: 0.9401 - val_loss: 0.5301 - val_accuracy: 0.8112\n",
            "Epoch 889/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1900 - accuracy: 0.9412 - val_loss: 0.4933 - val_accuracy: 0.8306\n",
            "Epoch 890/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1941 - accuracy: 0.9425 - val_loss: 0.5445 - val_accuracy: 0.8035\n",
            "Epoch 891/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2020 - accuracy: 0.9361 - val_loss: 0.5282 - val_accuracy: 0.8144\n",
            "Epoch 892/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2019 - accuracy: 0.9385 - val_loss: 0.4786 - val_accuracy: 0.8340\n",
            "Epoch 893/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1944 - accuracy: 0.9404 - val_loss: 0.4929 - val_accuracy: 0.8303\n",
            "Epoch 894/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2053 - accuracy: 0.9351 - val_loss: 0.5165 - val_accuracy: 0.8181\n",
            "Epoch 895/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1991 - accuracy: 0.9383 - val_loss: 0.4881 - val_accuracy: 0.8282\n",
            "Epoch 896/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1918 - accuracy: 0.9404 - val_loss: 0.5084 - val_accuracy: 0.8181\n",
            "Epoch 897/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2019 - accuracy: 0.9358 - val_loss: 0.5033 - val_accuracy: 0.8276\n",
            "Epoch 898/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1972 - accuracy: 0.9358 - val_loss: 0.5341 - val_accuracy: 0.8133\n",
            "Epoch 899/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2071 - accuracy: 0.9353 - val_loss: 0.4825 - val_accuracy: 0.8311\n",
            "Epoch 900/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2082 - accuracy: 0.9349 - val_loss: 0.5062 - val_accuracy: 0.8216\n",
            "Epoch 901/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1971 - accuracy: 0.9403 - val_loss: 0.5097 - val_accuracy: 0.8197\n",
            "Epoch 902/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2029 - accuracy: 0.9381 - val_loss: 0.5169 - val_accuracy: 0.8160\n",
            "Epoch 903/1000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1949 - accuracy: 0.9414 - val_loss: 0.5019 - val_accuracy: 0.8250\n",
            "Epoch 904/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2016 - accuracy: 0.9378 - val_loss: 0.5088 - val_accuracy: 0.8245\n",
            "Epoch 905/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2030 - accuracy: 0.9331 - val_loss: 0.5138 - val_accuracy: 0.8192\n",
            "Epoch 906/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2054 - accuracy: 0.9376 - val_loss: 0.5052 - val_accuracy: 0.8237\n",
            "Epoch 907/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2003 - accuracy: 0.9375 - val_loss: 0.5180 - val_accuracy: 0.8176\n",
            "Epoch 908/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2028 - accuracy: 0.9379 - val_loss: 0.5034 - val_accuracy: 0.8242\n",
            "Epoch 909/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1966 - accuracy: 0.9398 - val_loss: 0.5081 - val_accuracy: 0.8231\n",
            "Epoch 910/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1972 - accuracy: 0.9370 - val_loss: 0.5003 - val_accuracy: 0.8274\n",
            "Epoch 911/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2033 - accuracy: 0.9359 - val_loss: 0.4922 - val_accuracy: 0.8311\n",
            "Epoch 912/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2024 - accuracy: 0.9363 - val_loss: 0.4956 - val_accuracy: 0.8287\n",
            "Epoch 913/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2007 - accuracy: 0.9359 - val_loss: 0.5055 - val_accuracy: 0.8263\n",
            "Epoch 914/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1966 - accuracy: 0.9388 - val_loss: 0.4774 - val_accuracy: 0.8340\n",
            "Epoch 915/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1978 - accuracy: 0.9358 - val_loss: 0.5140 - val_accuracy: 0.8226\n",
            "Epoch 916/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2026 - accuracy: 0.9377 - val_loss: 0.4821 - val_accuracy: 0.8332\n",
            "Epoch 917/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1982 - accuracy: 0.9386 - val_loss: 0.4857 - val_accuracy: 0.8292\n",
            "Epoch 918/1000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.1954 - accuracy: 0.9394 - val_loss: 0.4907 - val_accuracy: 0.8311\n",
            "Epoch 919/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1944 - accuracy: 0.9398 - val_loss: 0.4726 - val_accuracy: 0.8356\n",
            "Epoch 920/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1933 - accuracy: 0.9416 - val_loss: 0.4869 - val_accuracy: 0.8298\n",
            "Epoch 921/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1942 - accuracy: 0.9380 - val_loss: 0.5084 - val_accuracy: 0.8197\n",
            "Epoch 922/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1912 - accuracy: 0.9388 - val_loss: 0.5060 - val_accuracy: 0.8266\n",
            "Epoch 923/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2007 - accuracy: 0.9349 - val_loss: 0.5131 - val_accuracy: 0.8186\n",
            "Epoch 924/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1925 - accuracy: 0.9415 - val_loss: 0.5144 - val_accuracy: 0.8186\n",
            "Epoch 925/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1985 - accuracy: 0.9362 - val_loss: 0.4945 - val_accuracy: 0.8271\n",
            "Epoch 926/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1945 - accuracy: 0.9380 - val_loss: 0.4910 - val_accuracy: 0.8284\n",
            "Epoch 927/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1951 - accuracy: 0.9380 - val_loss: 0.4899 - val_accuracy: 0.8284\n",
            "Epoch 928/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1938 - accuracy: 0.9392 - val_loss: 0.5062 - val_accuracy: 0.8242\n",
            "Epoch 929/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2017 - accuracy: 0.9358 - val_loss: 0.5334 - val_accuracy: 0.8123\n",
            "Epoch 930/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1956 - accuracy: 0.9386 - val_loss: 0.5094 - val_accuracy: 0.8263\n",
            "Epoch 931/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1982 - accuracy: 0.9389 - val_loss: 0.4890 - val_accuracy: 0.8300\n",
            "Epoch 932/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1996 - accuracy: 0.9376 - val_loss: 0.5305 - val_accuracy: 0.8147\n",
            "Epoch 933/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2017 - accuracy: 0.9399 - val_loss: 0.4759 - val_accuracy: 0.8327\n",
            "Epoch 934/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2022 - accuracy: 0.9341 - val_loss: 0.4801 - val_accuracy: 0.8319\n",
            "Epoch 935/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2015 - accuracy: 0.9356 - val_loss: 0.5175 - val_accuracy: 0.8178\n",
            "Epoch 936/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1974 - accuracy: 0.9361 - val_loss: 0.5283 - val_accuracy: 0.8115\n",
            "Epoch 937/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1984 - accuracy: 0.9396 - val_loss: 0.4934 - val_accuracy: 0.8266\n",
            "Epoch 938/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1899 - accuracy: 0.9422 - val_loss: 0.5133 - val_accuracy: 0.8205\n",
            "Epoch 939/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2010 - accuracy: 0.9364 - val_loss: 0.5225 - val_accuracy: 0.8176\n",
            "Epoch 940/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2015 - accuracy: 0.9368 - val_loss: 0.5479 - val_accuracy: 0.8091\n",
            "Epoch 941/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1932 - accuracy: 0.9379 - val_loss: 0.5114 - val_accuracy: 0.8226\n",
            "Epoch 942/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1973 - accuracy: 0.9397 - val_loss: 0.5261 - val_accuracy: 0.8160\n",
            "Epoch 943/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2040 - accuracy: 0.9343 - val_loss: 0.5000 - val_accuracy: 0.8226\n",
            "Epoch 944/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2041 - accuracy: 0.9369 - val_loss: 0.4634 - val_accuracy: 0.8398\n",
            "Epoch 945/1000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1986 - accuracy: 0.9387 - val_loss: 0.5074 - val_accuracy: 0.8221\n",
            "Epoch 946/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1977 - accuracy: 0.9399 - val_loss: 0.4986 - val_accuracy: 0.8255\n",
            "Epoch 947/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2027 - accuracy: 0.9381 - val_loss: 0.4821 - val_accuracy: 0.8298\n",
            "Epoch 948/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1977 - accuracy: 0.9418 - val_loss: 0.4867 - val_accuracy: 0.8303\n",
            "Epoch 949/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1951 - accuracy: 0.9389 - val_loss: 0.5087 - val_accuracy: 0.8234\n",
            "Epoch 950/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1955 - accuracy: 0.9397 - val_loss: 0.5164 - val_accuracy: 0.8213\n",
            "Epoch 951/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1920 - accuracy: 0.9400 - val_loss: 0.5461 - val_accuracy: 0.8086\n",
            "Epoch 952/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1973 - accuracy: 0.9362 - val_loss: 0.5040 - val_accuracy: 0.8255\n",
            "Epoch 953/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2048 - accuracy: 0.9352 - val_loss: 0.5129 - val_accuracy: 0.8189\n",
            "Epoch 954/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1965 - accuracy: 0.9388 - val_loss: 0.5386 - val_accuracy: 0.8131\n",
            "Epoch 955/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1926 - accuracy: 0.9398 - val_loss: 0.5314 - val_accuracy: 0.8128\n",
            "Epoch 956/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1925 - accuracy: 0.9398 - val_loss: 0.5429 - val_accuracy: 0.8115\n",
            "Epoch 957/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1939 - accuracy: 0.9419 - val_loss: 0.5140 - val_accuracy: 0.8176\n",
            "Epoch 958/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2020 - accuracy: 0.9361 - val_loss: 0.4980 - val_accuracy: 0.8276\n",
            "Epoch 959/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1943 - accuracy: 0.9399 - val_loss: 0.4804 - val_accuracy: 0.8337\n",
            "Epoch 960/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1965 - accuracy: 0.9386 - val_loss: 0.5373 - val_accuracy: 0.8139\n",
            "Epoch 961/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1910 - accuracy: 0.9437 - val_loss: 0.5256 - val_accuracy: 0.8139\n",
            "Epoch 962/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1958 - accuracy: 0.9390 - val_loss: 0.5010 - val_accuracy: 0.8242\n",
            "Epoch 963/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1984 - accuracy: 0.9372 - val_loss: 0.4988 - val_accuracy: 0.8266\n",
            "Epoch 964/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1936 - accuracy: 0.9397 - val_loss: 0.5057 - val_accuracy: 0.8247\n",
            "Epoch 965/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1984 - accuracy: 0.9391 - val_loss: 0.5046 - val_accuracy: 0.8245\n",
            "Epoch 966/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1964 - accuracy: 0.9386 - val_loss: 0.5004 - val_accuracy: 0.8253\n",
            "Epoch 967/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1902 - accuracy: 0.9382 - val_loss: 0.5070 - val_accuracy: 0.8221\n",
            "Epoch 968/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1893 - accuracy: 0.9437 - val_loss: 0.5268 - val_accuracy: 0.8192\n",
            "Epoch 969/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1977 - accuracy: 0.9374 - val_loss: 0.5211 - val_accuracy: 0.8155\n",
            "Epoch 970/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1912 - accuracy: 0.9407 - val_loss: 0.4777 - val_accuracy: 0.8351\n",
            "Epoch 971/1000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.2066 - accuracy: 0.9332 - val_loss: 0.4767 - val_accuracy: 0.8377\n",
            "Epoch 972/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1972 - accuracy: 0.9397 - val_loss: 0.4910 - val_accuracy: 0.8255\n",
            "Epoch 973/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1928 - accuracy: 0.9406 - val_loss: 0.5034 - val_accuracy: 0.8218\n",
            "Epoch 974/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1964 - accuracy: 0.9402 - val_loss: 0.4992 - val_accuracy: 0.8253\n",
            "Epoch 975/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1990 - accuracy: 0.9382 - val_loss: 0.5038 - val_accuracy: 0.8268\n",
            "Epoch 976/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1873 - accuracy: 0.9430 - val_loss: 0.4949 - val_accuracy: 0.8290\n",
            "Epoch 977/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1900 - accuracy: 0.9424 - val_loss: 0.5058 - val_accuracy: 0.8242\n",
            "Epoch 978/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1959 - accuracy: 0.9354 - val_loss: 0.4978 - val_accuracy: 0.8279\n",
            "Epoch 979/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1971 - accuracy: 0.9386 - val_loss: 0.5251 - val_accuracy: 0.8152\n",
            "Epoch 980/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1925 - accuracy: 0.9378 - val_loss: 0.5240 - val_accuracy: 0.8192\n",
            "Epoch 981/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1898 - accuracy: 0.9395 - val_loss: 0.4954 - val_accuracy: 0.8284\n",
            "Epoch 982/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1944 - accuracy: 0.9392 - val_loss: 0.5140 - val_accuracy: 0.8202\n",
            "Epoch 983/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1887 - accuracy: 0.9420 - val_loss: 0.5357 - val_accuracy: 0.8120\n",
            "Epoch 984/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2023 - accuracy: 0.9373 - val_loss: 0.5110 - val_accuracy: 0.8208\n",
            "Epoch 985/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1921 - accuracy: 0.9401 - val_loss: 0.4976 - val_accuracy: 0.8247\n",
            "Epoch 986/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1928 - accuracy: 0.9410 - val_loss: 0.5001 - val_accuracy: 0.8274\n",
            "Epoch 987/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1913 - accuracy: 0.9401 - val_loss: 0.4666 - val_accuracy: 0.8398\n",
            "Epoch 988/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1972 - accuracy: 0.9358 - val_loss: 0.5114 - val_accuracy: 0.8213\n",
            "Epoch 989/1000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1919 - accuracy: 0.9402 - val_loss: 0.5111 - val_accuracy: 0.8229\n",
            "Epoch 990/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1925 - accuracy: 0.9407 - val_loss: 0.5317 - val_accuracy: 0.8149\n",
            "Epoch 991/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1965 - accuracy: 0.9386 - val_loss: 0.5061 - val_accuracy: 0.8221\n",
            "Epoch 992/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1893 - accuracy: 0.9408 - val_loss: 0.5323 - val_accuracy: 0.8171\n",
            "Epoch 993/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1957 - accuracy: 0.9373 - val_loss: 0.5040 - val_accuracy: 0.8221\n",
            "Epoch 994/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1956 - accuracy: 0.9385 - val_loss: 0.5401 - val_accuracy: 0.8062\n",
            "Epoch 995/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1978 - accuracy: 0.9396 - val_loss: 0.5017 - val_accuracy: 0.8295\n",
            "Epoch 996/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1936 - accuracy: 0.9382 - val_loss: 0.4983 - val_accuracy: 0.8247\n",
            "Epoch 997/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1950 - accuracy: 0.9401 - val_loss: 0.5400 - val_accuracy: 0.8083\n",
            "Epoch 998/1000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1955 - accuracy: 0.9389 - val_loss: 0.5170 - val_accuracy: 0.8176\n",
            "Epoch 999/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1973 - accuracy: 0.9395 - val_loss: 0.5112 - val_accuracy: 0.8218\n",
            "Epoch 1000/1000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1962 - accuracy: 0.9381 - val_loss: 0.5321 - val_accuracy: 0.8131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwreC3XQQFTJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "9c74eb8e-28a3-4d62-b3f8-010bea57c6e1"
      },
      "source": [
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "ypred=model.predict_classes(X_test)\n",
        "ypred=pd.get_dummies(ypred)\n",
        "\n",
        "print(classification_report(y_test[list(ypred.columns+1)],ypred ))\n",
        "accuracy_score(ypred,y_test[list(ypred.columns+1)])\n",
        "ypred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.81      0.88        83\n",
            "           1       1.00      0.88      0.93        80\n",
            "           2       0.99      0.99      0.99       191\n",
            "           3       1.00      0.98      0.99       203\n",
            "           4       0.70      0.98      0.82        93\n",
            "           5       0.92      0.88      0.90       190\n",
            "\n",
            "   micro avg       0.93      0.93      0.93       840\n",
            "   macro avg       0.93      0.92      0.92       840\n",
            "weighted avg       0.95      0.93      0.94       840\n",
            " samples avg       0.93      0.93      0.93       840\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>836</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>838</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>840 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0  1  2  3  4  5\n",
              "0    0  1  0  0  0  0\n",
              "1    0  0  0  1  0  0\n",
              "2    0  0  0  0  1  0\n",
              "3    1  0  0  0  0  0\n",
              "4    0  0  1  0  0  0\n",
              "..  .. .. .. .. .. ..\n",
              "835  0  0  0  1  0  0\n",
              "836  1  0  0  0  0  0\n",
              "837  0  1  0  0  0  0\n",
              "838  0  0  1  0  0  0\n",
              "839  0  0  0  0  0  1\n",
              "\n",
              "[840 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX3ZUB_YQwwi"
      },
      "source": [
        "##model2 (10,6) relu,sigmoid adam , 1000, 512 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORDUYfDvQwwu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c6e19f8-2e0b-453e-91e4-1c7f693e4b3f"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(10, activation='relu', input_shape = (X_train.shape[1],)))\n",
        "model.add(layers.Dense(6, activation='sigmoid'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_32 (Dense)             (None, 10)                460       \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 6)                 66        \n",
            "=================================================================\n",
            "Total params: 526\n",
            "Trainable params: 526\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlxJS3XvQwwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f2869a9-ef50-4298-e2df-8f7956907c3c"
      },
      "source": [
        "history = model.fit(X_train_aug,\n",
        "                   y_train_aug,\n",
        "                   epochs=1000,\n",
        "                   batch_size=512,verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.1723 - accuracy: 0.1867\n",
            "Epoch 2/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.6691 - accuracy: 0.3267\n",
            "Epoch 3/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.5178 - accuracy: 0.4816\n",
            "Epoch 4/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.4201 - accuracy: 0.5342\n",
            "Epoch 5/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.3300 - accuracy: 0.5689\n",
            "Epoch 6/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.2469 - accuracy: 0.5935\n",
            "Epoch 7/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.1783 - accuracy: 0.5999\n",
            "Epoch 8/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.1112 - accuracy: 0.6229\n",
            "Epoch 9/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.0573 - accuracy: 0.6352\n",
            "Epoch 10/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0097 - accuracy: 0.6460\n",
            "Epoch 11/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9639 - accuracy: 0.6535\n",
            "Epoch 12/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9225 - accuracy: 0.6649\n",
            "Epoch 13/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.8841 - accuracy: 0.6882\n",
            "Epoch 14/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8463 - accuracy: 0.7017\n",
            "Epoch 15/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8142 - accuracy: 0.7093\n",
            "Epoch 16/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7868 - accuracy: 0.7205\n",
            "Epoch 17/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7598 - accuracy: 0.7349\n",
            "Epoch 18/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7334 - accuracy: 0.7442\n",
            "Epoch 19/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7189 - accuracy: 0.7532\n",
            "Epoch 20/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.7643\n",
            "Epoch 21/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6772 - accuracy: 0.7714\n",
            "Epoch 22/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.7826\n",
            "Epoch 23/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.7876\n",
            "Epoch 24/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.7860\n",
            "Epoch 25/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.7969\n",
            "Epoch 26/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.8009\n",
            "Epoch 27/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.8028\n",
            "Epoch 28/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.8144\n",
            "Epoch 29/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5531 - accuracy: 0.8099\n",
            "Epoch 30/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.8132\n",
            "Epoch 31/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.8124\n",
            "Epoch 32/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.8210\n",
            "Epoch 33/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.8206\n",
            "Epoch 34/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.8271\n",
            "Epoch 35/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8239\n",
            "Epoch 36/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.8277\n",
            "Epoch 37/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8266\n",
            "Epoch 38/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.8336\n",
            "Epoch 39/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8308\n",
            "Epoch 40/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.8324\n",
            "Epoch 41/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.8335\n",
            "Epoch 42/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.8475\n",
            "Epoch 43/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8431\n",
            "Epoch 44/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8442\n",
            "Epoch 45/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8421\n",
            "Epoch 46/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8465\n",
            "Epoch 47/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8469\n",
            "Epoch 48/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8479\n",
            "Epoch 49/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8508\n",
            "Epoch 50/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8542\n",
            "Epoch 51/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8552\n",
            "Epoch 52/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8554\n",
            "Epoch 53/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4118 - accuracy: 0.8606\n",
            "Epoch 54/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8604\n",
            "Epoch 55/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8627\n",
            "Epoch 56/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8613\n",
            "Epoch 57/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.8637\n",
            "Epoch 58/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8665\n",
            "Epoch 59/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8630\n",
            "Epoch 60/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8646\n",
            "Epoch 61/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 0.8659\n",
            "Epoch 62/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8706\n",
            "Epoch 63/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8690\n",
            "Epoch 64/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8692\n",
            "Epoch 65/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8663\n",
            "Epoch 66/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8660\n",
            "Epoch 67/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8673\n",
            "Epoch 68/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8716\n",
            "Epoch 69/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8732\n",
            "Epoch 70/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8761\n",
            "Epoch 71/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8763\n",
            "Epoch 72/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8807\n",
            "Epoch 73/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8715\n",
            "Epoch 74/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8741\n",
            "Epoch 75/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8774\n",
            "Epoch 76/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8766\n",
            "Epoch 77/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3582 - accuracy: 0.8742\n",
            "Epoch 78/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.8780\n",
            "Epoch 79/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3457 - accuracy: 0.8806\n",
            "Epoch 80/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8777\n",
            "Epoch 81/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8790\n",
            "Epoch 82/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8774\n",
            "Epoch 83/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8807\n",
            "Epoch 84/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8830\n",
            "Epoch 85/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8834\n",
            "Epoch 86/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8815\n",
            "Epoch 87/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8826\n",
            "Epoch 88/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8859\n",
            "Epoch 89/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8860\n",
            "Epoch 90/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8875\n",
            "Epoch 91/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8833\n",
            "Epoch 92/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.8891\n",
            "Epoch 93/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8856\n",
            "Epoch 94/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8880\n",
            "Epoch 95/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8901\n",
            "Epoch 96/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8846\n",
            "Epoch 97/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8899\n",
            "Epoch 98/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8928\n",
            "Epoch 99/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8889\n",
            "Epoch 100/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8900\n",
            "Epoch 101/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.8894\n",
            "Epoch 102/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8892\n",
            "Epoch 103/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8901\n",
            "Epoch 104/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8930\n",
            "Epoch 105/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8944\n",
            "Epoch 106/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8926\n",
            "Epoch 107/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8930\n",
            "Epoch 108/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8918\n",
            "Epoch 109/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8952\n",
            "Epoch 110/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8901\n",
            "Epoch 111/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8938\n",
            "Epoch 112/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8920\n",
            "Epoch 113/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8926\n",
            "Epoch 114/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8946\n",
            "Epoch 115/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8977\n",
            "Epoch 116/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8953\n",
            "Epoch 117/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8929\n",
            "Epoch 118/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8984\n",
            "Epoch 119/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8963\n",
            "Epoch 120/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8985\n",
            "Epoch 121/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8971\n",
            "Epoch 122/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8952\n",
            "Epoch 123/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8975\n",
            "Epoch 124/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.9008\n",
            "Epoch 125/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3014 - accuracy: 0.8988\n",
            "Epoch 126/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8974\n",
            "Epoch 127/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.8995\n",
            "Epoch 128/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.9004\n",
            "Epoch 129/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8987\n",
            "Epoch 130/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8992\n",
            "Epoch 131/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8989\n",
            "Epoch 132/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.9001\n",
            "Epoch 133/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.9021\n",
            "Epoch 134/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.9023\n",
            "Epoch 135/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8972\n",
            "Epoch 136/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.8972\n",
            "Epoch 137/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.8972\n",
            "Epoch 138/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 0.8991\n",
            "Epoch 139/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8978\n",
            "Epoch 140/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.9014\n",
            "Epoch 141/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.9005\n",
            "Epoch 142/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.9011\n",
            "Epoch 143/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.9006\n",
            "Epoch 144/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8987\n",
            "Epoch 145/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.8990\n",
            "Epoch 146/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.9021\n",
            "Epoch 147/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.9019\n",
            "Epoch 148/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.9035\n",
            "Epoch 149/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.8990\n",
            "Epoch 150/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.9000\n",
            "Epoch 151/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.9034\n",
            "Epoch 152/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.9004\n",
            "Epoch 153/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.9017\n",
            "Epoch 154/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2882 - accuracy: 0.9051\n",
            "Epoch 155/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2841 - accuracy: 0.9031\n",
            "Epoch 156/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.9037\n",
            "Epoch 157/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.9025\n",
            "Epoch 158/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2838 - accuracy: 0.9027\n",
            "Epoch 159/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.9063\n",
            "Epoch 160/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2931 - accuracy: 0.8996\n",
            "Epoch 161/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2908 - accuracy: 0.9010\n",
            "Epoch 162/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.9061\n",
            "Epoch 163/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.9042\n",
            "Epoch 164/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.9066\n",
            "Epoch 165/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.9014\n",
            "Epoch 166/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.9030\n",
            "Epoch 167/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.9071\n",
            "Epoch 168/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.9039\n",
            "Epoch 169/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.9082\n",
            "Epoch 170/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.9055\n",
            "Epoch 171/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.9036\n",
            "Epoch 172/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.9071\n",
            "Epoch 173/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.9069\n",
            "Epoch 174/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.9049\n",
            "Epoch 175/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.9053\n",
            "Epoch 176/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.9072\n",
            "Epoch 177/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.9063\n",
            "Epoch 178/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2812 - accuracy: 0.9031\n",
            "Epoch 179/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.9049\n",
            "Epoch 180/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2836 - accuracy: 0.9053\n",
            "Epoch 181/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.9071\n",
            "Epoch 182/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.9097\n",
            "Epoch 183/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.9069\n",
            "Epoch 184/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.9065\n",
            "Epoch 185/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.9086\n",
            "Epoch 186/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.9058\n",
            "Epoch 187/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 0.9058\n",
            "Epoch 188/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.9104\n",
            "Epoch 189/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.9047\n",
            "Epoch 190/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.9101\n",
            "Epoch 191/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.9042\n",
            "Epoch 192/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.9101\n",
            "Epoch 193/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.9102\n",
            "Epoch 194/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.9107\n",
            "Epoch 195/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.9072\n",
            "Epoch 196/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.9082\n",
            "Epoch 197/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.9087\n",
            "Epoch 198/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.9078\n",
            "Epoch 199/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.9078\n",
            "Epoch 200/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.9096\n",
            "Epoch 201/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.9063\n",
            "Epoch 202/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.9103\n",
            "Epoch 203/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.9101\n",
            "Epoch 204/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.9103\n",
            "Epoch 205/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.9122\n",
            "Epoch 206/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.9077\n",
            "Epoch 207/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.9084\n",
            "Epoch 208/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2727 - accuracy: 0.9078\n",
            "Epoch 209/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.9086\n",
            "Epoch 210/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.9138\n",
            "Epoch 211/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.9128\n",
            "Epoch 212/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.9096\n",
            "Epoch 213/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.9084\n",
            "Epoch 214/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.9112\n",
            "Epoch 215/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.9088\n",
            "Epoch 216/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.9075\n",
            "Epoch 217/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.9095\n",
            "Epoch 218/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.9122\n",
            "Epoch 219/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.9090\n",
            "Epoch 220/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.9088\n",
            "Epoch 221/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.9138\n",
            "Epoch 222/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.9101\n",
            "Epoch 223/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.9132\n",
            "Epoch 224/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.9090\n",
            "Epoch 225/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2667 - accuracy: 0.9096\n",
            "Epoch 226/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.9119\n",
            "Epoch 227/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.9130\n",
            "Epoch 228/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.9113\n",
            "Epoch 229/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.9128\n",
            "Epoch 230/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9126\n",
            "Epoch 231/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.9148\n",
            "Epoch 232/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.9102\n",
            "Epoch 233/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.9142\n",
            "Epoch 234/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.9123\n",
            "Epoch 235/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.9112\n",
            "Epoch 236/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.9128\n",
            "Epoch 237/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.9101\n",
            "Epoch 238/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9153\n",
            "Epoch 239/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.9116\n",
            "Epoch 240/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.9118\n",
            "Epoch 241/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.9112\n",
            "Epoch 242/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.9132\n",
            "Epoch 243/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.9127\n",
            "Epoch 244/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9132\n",
            "Epoch 245/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.9130\n",
            "Epoch 246/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.9122\n",
            "Epoch 247/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.9118\n",
            "Epoch 248/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.9163\n",
            "Epoch 249/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.9120\n",
            "Epoch 250/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.9142\n",
            "Epoch 251/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.9120\n",
            "Epoch 252/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9130\n",
            "Epoch 253/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.9119\n",
            "Epoch 254/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9132\n",
            "Epoch 255/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.9130\n",
            "Epoch 256/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.9094\n",
            "Epoch 257/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.9116\n",
            "Epoch 258/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.9136\n",
            "Epoch 259/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.9135\n",
            "Epoch 260/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9124\n",
            "Epoch 261/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.9122\n",
            "Epoch 262/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.9097\n",
            "Epoch 263/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.9138\n",
            "Epoch 264/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.9147\n",
            "Epoch 265/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.9113\n",
            "Epoch 266/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.9123\n",
            "Epoch 267/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.9141\n",
            "Epoch 268/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9132\n",
            "Epoch 269/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.9125\n",
            "Epoch 270/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.9138\n",
            "Epoch 271/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.9152\n",
            "Epoch 272/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.9134\n",
            "Epoch 273/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.9120\n",
            "Epoch 274/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.9148\n",
            "Epoch 275/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.9150\n",
            "Epoch 276/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.9107\n",
            "Epoch 277/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9113\n",
            "Epoch 278/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.9178\n",
            "Epoch 279/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.9141\n",
            "Epoch 280/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.9161\n",
            "Epoch 281/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.9152\n",
            "Epoch 282/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.9135\n",
            "Epoch 283/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.9119\n",
            "Epoch 284/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.9121\n",
            "Epoch 285/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.9162\n",
            "Epoch 286/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.9142\n",
            "Epoch 287/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.9164\n",
            "Epoch 288/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.9124\n",
            "Epoch 289/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9155\n",
            "Epoch 290/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.9145\n",
            "Epoch 291/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.9141\n",
            "Epoch 292/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.9164\n",
            "Epoch 293/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.9171\n",
            "Epoch 294/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.9165\n",
            "Epoch 295/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.9144\n",
            "Epoch 296/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9173\n",
            "Epoch 297/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.9126\n",
            "Epoch 298/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9177\n",
            "Epoch 299/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9175\n",
            "Epoch 300/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.9143\n",
            "Epoch 301/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.9159\n",
            "Epoch 302/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.9183\n",
            "Epoch 303/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.9142\n",
            "Epoch 304/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9194\n",
            "Epoch 305/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.9142\n",
            "Epoch 306/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.9162\n",
            "Epoch 307/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.9133\n",
            "Epoch 308/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.9181\n",
            "Epoch 309/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2381 - accuracy: 0.9187\n",
            "Epoch 310/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.9194\n",
            "Epoch 311/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.9153\n",
            "Epoch 312/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.9175\n",
            "Epoch 313/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9206\n",
            "Epoch 314/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.9170\n",
            "Epoch 315/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2370 - accuracy: 0.9195\n",
            "Epoch 316/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.9177\n",
            "Epoch 317/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.9169\n",
            "Epoch 318/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.9179\n",
            "Epoch 319/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.9154\n",
            "Epoch 320/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.9156\n",
            "Epoch 321/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.9147\n",
            "Epoch 322/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.9217\n",
            "Epoch 323/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2484 - accuracy: 0.9150\n",
            "Epoch 324/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9171\n",
            "Epoch 325/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.9183\n",
            "Epoch 326/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9180\n",
            "Epoch 327/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.9158\n",
            "Epoch 328/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.9133\n",
            "Epoch 329/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.9159\n",
            "Epoch 330/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2369 - accuracy: 0.9171\n",
            "Epoch 331/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.9149\n",
            "Epoch 332/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9153\n",
            "Epoch 333/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.9164\n",
            "Epoch 334/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2369 - accuracy: 0.9189\n",
            "Epoch 335/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9192\n",
            "Epoch 336/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.9200\n",
            "Epoch 337/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.9202\n",
            "Epoch 338/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.9137\n",
            "Epoch 339/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9208\n",
            "Epoch 340/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.9163\n",
            "Epoch 341/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9208\n",
            "Epoch 342/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.9162\n",
            "Epoch 343/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9170\n",
            "Epoch 344/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2336 - accuracy: 0.9190\n",
            "Epoch 345/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9222\n",
            "Epoch 346/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.9167\n",
            "Epoch 347/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.9198\n",
            "Epoch 348/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9204\n",
            "Epoch 349/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.9188\n",
            "Epoch 350/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9164\n",
            "Epoch 351/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9201\n",
            "Epoch 352/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9151\n",
            "Epoch 353/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9195\n",
            "Epoch 354/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9173\n",
            "Epoch 355/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9204\n",
            "Epoch 356/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9210\n",
            "Epoch 357/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2406 - accuracy: 0.9178\n",
            "Epoch 358/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9187\n",
            "Epoch 359/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9222\n",
            "Epoch 360/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9177\n",
            "Epoch 361/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9199\n",
            "Epoch 362/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9210\n",
            "Epoch 363/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.9175\n",
            "Epoch 364/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.9162\n",
            "Epoch 365/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9199\n",
            "Epoch 366/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9209\n",
            "Epoch 367/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9178\n",
            "Epoch 368/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9195\n",
            "Epoch 369/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.9196\n",
            "Epoch 370/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.9142\n",
            "Epoch 371/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.9202\n",
            "Epoch 372/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9198\n",
            "Epoch 373/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9181\n",
            "Epoch 374/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.9213\n",
            "Epoch 375/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.9191\n",
            "Epoch 376/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.9184\n",
            "Epoch 377/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9214\n",
            "Epoch 378/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9209\n",
            "Epoch 379/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9207\n",
            "Epoch 380/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9213\n",
            "Epoch 381/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9221\n",
            "Epoch 382/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9212\n",
            "Epoch 383/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.9191\n",
            "Epoch 384/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9195\n",
            "Epoch 385/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9237\n",
            "Epoch 386/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9197\n",
            "Epoch 387/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.9185\n",
            "Epoch 388/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9225\n",
            "Epoch 389/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9226\n",
            "Epoch 390/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9224\n",
            "Epoch 391/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9229\n",
            "Epoch 392/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2345 - accuracy: 0.9189\n",
            "Epoch 393/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9202\n",
            "Epoch 394/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9169\n",
            "Epoch 395/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2284 - accuracy: 0.9238\n",
            "Epoch 396/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9177\n",
            "Epoch 397/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9195\n",
            "Epoch 398/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9181\n",
            "Epoch 399/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9222\n",
            "Epoch 400/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9217\n",
            "Epoch 401/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9206\n",
            "Epoch 402/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9208\n",
            "Epoch 403/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9233\n",
            "Epoch 404/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.9233\n",
            "Epoch 405/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.9194\n",
            "Epoch 406/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9231\n",
            "Epoch 407/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2285 - accuracy: 0.9202\n",
            "Epoch 408/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9210\n",
            "Epoch 409/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9209\n",
            "Epoch 410/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9239\n",
            "Epoch 411/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2271 - accuracy: 0.9217\n",
            "Epoch 412/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9210\n",
            "Epoch 413/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9212\n",
            "Epoch 414/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.9239\n",
            "Epoch 415/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9197\n",
            "Epoch 416/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9241\n",
            "Epoch 417/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9206\n",
            "Epoch 418/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.9200\n",
            "Epoch 419/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9224\n",
            "Epoch 420/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2216 - accuracy: 0.9251\n",
            "Epoch 421/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 0.9242\n",
            "Epoch 422/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9198\n",
            "Epoch 423/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9219\n",
            "Epoch 424/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9228\n",
            "Epoch 425/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9208\n",
            "Epoch 426/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2299 - accuracy: 0.9205\n",
            "Epoch 427/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9247\n",
            "Epoch 428/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2271 - accuracy: 0.9200\n",
            "Epoch 429/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9212\n",
            "Epoch 430/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9234\n",
            "Epoch 431/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9247\n",
            "Epoch 432/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9227\n",
            "Epoch 433/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9221\n",
            "Epoch 434/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9224\n",
            "Epoch 435/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9212\n",
            "Epoch 436/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.9205\n",
            "Epoch 437/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9236\n",
            "Epoch 438/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9228\n",
            "Epoch 439/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9225\n",
            "Epoch 440/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9166\n",
            "Epoch 441/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9248\n",
            "Epoch 442/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9260\n",
            "Epoch 443/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2285 - accuracy: 0.9224\n",
            "Epoch 444/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9230\n",
            "Epoch 445/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.9281\n",
            "Epoch 446/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.9274\n",
            "Epoch 447/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.9245\n",
            "Epoch 448/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9226\n",
            "Epoch 449/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9243\n",
            "Epoch 450/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9221\n",
            "Epoch 451/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9239\n",
            "Epoch 452/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9219\n",
            "Epoch 453/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.9229\n",
            "Epoch 454/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9223\n",
            "Epoch 455/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9218\n",
            "Epoch 456/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9247\n",
            "Epoch 457/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9225\n",
            "Epoch 458/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9234\n",
            "Epoch 459/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2271 - accuracy: 0.9231\n",
            "Epoch 460/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9235\n",
            "Epoch 461/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2271 - accuracy: 0.9235\n",
            "Epoch 462/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9277\n",
            "Epoch 463/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.9261\n",
            "Epoch 464/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9245\n",
            "Epoch 465/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9234\n",
            "Epoch 466/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9255\n",
            "Epoch 467/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9272\n",
            "Epoch 468/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9239\n",
            "Epoch 469/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9294\n",
            "Epoch 470/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9249\n",
            "Epoch 471/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.9237\n",
            "Epoch 472/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9278\n",
            "Epoch 473/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9227\n",
            "Epoch 474/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9255\n",
            "Epoch 475/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9240\n",
            "Epoch 476/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.9269\n",
            "Epoch 477/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9253\n",
            "Epoch 478/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9268\n",
            "Epoch 479/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9267\n",
            "Epoch 480/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2171 - accuracy: 0.9265\n",
            "Epoch 481/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9254\n",
            "Epoch 482/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 0.9266\n",
            "Epoch 483/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2263 - accuracy: 0.9212\n",
            "Epoch 484/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9250\n",
            "Epoch 485/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9247\n",
            "Epoch 486/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9237\n",
            "Epoch 487/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9262\n",
            "Epoch 488/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9242\n",
            "Epoch 489/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9254\n",
            "Epoch 490/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9234\n",
            "Epoch 491/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9275\n",
            "Epoch 492/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9237\n",
            "Epoch 493/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9258\n",
            "Epoch 494/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9232\n",
            "Epoch 495/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9274\n",
            "Epoch 496/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9257\n",
            "Epoch 497/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9234\n",
            "Epoch 498/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9224\n",
            "Epoch 499/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9239\n",
            "Epoch 500/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.9257\n",
            "Epoch 501/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9245\n",
            "Epoch 502/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9256\n",
            "Epoch 503/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9248\n",
            "Epoch 504/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9274\n",
            "Epoch 505/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9249\n",
            "Epoch 506/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9269\n",
            "Epoch 507/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9248\n",
            "Epoch 508/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9247\n",
            "Epoch 509/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9255\n",
            "Epoch 510/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.9264\n",
            "Epoch 511/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9268\n",
            "Epoch 512/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9290\n",
            "Epoch 513/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9261\n",
            "Epoch 514/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9264\n",
            "Epoch 515/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9295\n",
            "Epoch 516/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9270\n",
            "Epoch 517/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9245\n",
            "Epoch 518/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9285\n",
            "Epoch 519/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9260\n",
            "Epoch 520/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9248\n",
            "Epoch 521/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9265\n",
            "Epoch 522/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9256\n",
            "Epoch 523/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9224\n",
            "Epoch 524/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9286\n",
            "Epoch 525/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.9269\n",
            "Epoch 526/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.9268\n",
            "Epoch 527/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9244\n",
            "Epoch 528/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9288\n",
            "Epoch 529/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9258\n",
            "Epoch 530/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9325\n",
            "Epoch 531/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9302\n",
            "Epoch 532/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2064 - accuracy: 0.9289\n",
            "Epoch 533/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9262\n",
            "Epoch 534/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9255\n",
            "Epoch 535/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.9251\n",
            "Epoch 536/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9257\n",
            "Epoch 537/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9313\n",
            "Epoch 538/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9254\n",
            "Epoch 539/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9227\n",
            "Epoch 540/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9246\n",
            "Epoch 541/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9274\n",
            "Epoch 542/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9271\n",
            "Epoch 543/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.9239\n",
            "Epoch 544/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9291\n",
            "Epoch 545/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9308\n",
            "Epoch 546/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9271\n",
            "Epoch 547/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9252\n",
            "Epoch 548/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2100 - accuracy: 0.9276\n",
            "Epoch 549/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.9286\n",
            "Epoch 550/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9292\n",
            "Epoch 551/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9305\n",
            "Epoch 552/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9269\n",
            "Epoch 553/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9245\n",
            "Epoch 554/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9256\n",
            "Epoch 555/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9261\n",
            "Epoch 556/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9290\n",
            "Epoch 557/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9256\n",
            "Epoch 558/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9271\n",
            "Epoch 559/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9287\n",
            "Epoch 560/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9283\n",
            "Epoch 561/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9310\n",
            "Epoch 562/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9257\n",
            "Epoch 563/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9286\n",
            "Epoch 564/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9270\n",
            "Epoch 565/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9266\n",
            "Epoch 566/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2092 - accuracy: 0.9259\n",
            "Epoch 567/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9282\n",
            "Epoch 568/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2056 - accuracy: 0.9293\n",
            "Epoch 569/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9270\n",
            "Epoch 570/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9263\n",
            "Epoch 571/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9317\n",
            "Epoch 572/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9246\n",
            "Epoch 573/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9269\n",
            "Epoch 574/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9273\n",
            "Epoch 575/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9282\n",
            "Epoch 576/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9282\n",
            "Epoch 577/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9263\n",
            "Epoch 578/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9302\n",
            "Epoch 579/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9287\n",
            "Epoch 580/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9274\n",
            "Epoch 581/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9281\n",
            "Epoch 582/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9265\n",
            "Epoch 583/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.9254\n",
            "Epoch 584/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9274\n",
            "Epoch 585/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9297\n",
            "Epoch 586/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9272\n",
            "Epoch 587/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9296\n",
            "Epoch 588/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9260\n",
            "Epoch 589/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9270\n",
            "Epoch 590/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9275\n",
            "Epoch 591/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9280\n",
            "Epoch 592/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9262\n",
            "Epoch 593/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 0.9251\n",
            "Epoch 594/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9263\n",
            "Epoch 595/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.9272\n",
            "Epoch 596/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9267\n",
            "Epoch 597/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9293\n",
            "Epoch 598/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9305\n",
            "Epoch 599/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9274\n",
            "Epoch 600/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9281\n",
            "Epoch 601/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9277\n",
            "Epoch 602/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9288\n",
            "Epoch 603/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9311\n",
            "Epoch 604/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9305\n",
            "Epoch 605/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9272\n",
            "Epoch 606/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 0.9216\n",
            "Epoch 607/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.9280\n",
            "Epoch 608/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2146 - accuracy: 0.9240\n",
            "Epoch 609/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9300\n",
            "Epoch 610/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2101 - accuracy: 0.9259\n",
            "Epoch 611/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9279\n",
            "Epoch 612/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.9278\n",
            "Epoch 613/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9279\n",
            "Epoch 614/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.9283\n",
            "Epoch 615/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.9327\n",
            "Epoch 616/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.9281\n",
            "Epoch 617/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9307\n",
            "Epoch 618/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.9288\n",
            "Epoch 619/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9288\n",
            "Epoch 620/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9277\n",
            "Epoch 621/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2045 - accuracy: 0.9288\n",
            "Epoch 622/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9288\n",
            "Epoch 623/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.9302\n",
            "Epoch 624/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9281\n",
            "Epoch 625/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9320\n",
            "Epoch 626/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9299\n",
            "Epoch 627/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9270\n",
            "Epoch 628/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2019 - accuracy: 0.9275\n",
            "Epoch 629/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9291\n",
            "Epoch 630/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2057 - accuracy: 0.9283\n",
            "Epoch 631/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9267\n",
            "Epoch 632/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2096 - accuracy: 0.9255\n",
            "Epoch 633/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9288\n",
            "Epoch 634/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9283\n",
            "Epoch 635/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9260\n",
            "Epoch 636/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2045 - accuracy: 0.9290\n",
            "Epoch 637/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9305\n",
            "Epoch 638/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9248\n",
            "Epoch 639/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9305\n",
            "Epoch 640/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9302\n",
            "Epoch 641/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9284\n",
            "Epoch 642/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9305\n",
            "Epoch 643/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2025 - accuracy: 0.9272\n",
            "Epoch 644/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9283\n",
            "Epoch 645/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9298\n",
            "Epoch 646/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9278\n",
            "Epoch 647/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9287\n",
            "Epoch 648/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9278\n",
            "Epoch 649/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9301\n",
            "Epoch 650/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9278\n",
            "Epoch 651/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9309\n",
            "Epoch 652/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9314\n",
            "Epoch 653/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2052 - accuracy: 0.9269\n",
            "Epoch 654/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9294\n",
            "Epoch 655/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.9297\n",
            "Epoch 656/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9298\n",
            "Epoch 657/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9300\n",
            "Epoch 658/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9294\n",
            "Epoch 659/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9292\n",
            "Epoch 660/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1962 - accuracy: 0.9309\n",
            "Epoch 661/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1981 - accuracy: 0.9314\n",
            "Epoch 662/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9325\n",
            "Epoch 663/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9317\n",
            "Epoch 664/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9301\n",
            "Epoch 665/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9289\n",
            "Epoch 666/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9280\n",
            "Epoch 667/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2030 - accuracy: 0.9299\n",
            "Epoch 668/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1981 - accuracy: 0.9312\n",
            "Epoch 669/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9294\n",
            "Epoch 670/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9304\n",
            "Epoch 671/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9304\n",
            "Epoch 672/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9251\n",
            "Epoch 673/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9321\n",
            "Epoch 674/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9303\n",
            "Epoch 675/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9298\n",
            "Epoch 676/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9313\n",
            "Epoch 677/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9309\n",
            "Epoch 678/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9313\n",
            "Epoch 679/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9282\n",
            "Epoch 680/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.9274\n",
            "Epoch 681/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9271\n",
            "Epoch 682/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9301\n",
            "Epoch 683/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9337\n",
            "Epoch 684/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9287\n",
            "Epoch 685/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9319\n",
            "Epoch 686/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9293\n",
            "Epoch 687/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9275\n",
            "Epoch 688/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.9293\n",
            "Epoch 689/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9311\n",
            "Epoch 690/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9301\n",
            "Epoch 691/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9301\n",
            "Epoch 692/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9277\n",
            "Epoch 693/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.9282\n",
            "Epoch 694/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9287\n",
            "Epoch 695/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9276\n",
            "Epoch 696/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9327\n",
            "Epoch 697/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9306\n",
            "Epoch 698/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9278\n",
            "Epoch 699/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9282\n",
            "Epoch 700/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9322\n",
            "Epoch 701/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9333\n",
            "Epoch 702/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9304\n",
            "Epoch 703/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.9278\n",
            "Epoch 704/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9290\n",
            "Epoch 705/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1999 - accuracy: 0.9288\n",
            "Epoch 706/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.9277\n",
            "Epoch 707/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9302\n",
            "Epoch 708/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9328\n",
            "Epoch 709/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9277\n",
            "Epoch 710/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9318\n",
            "Epoch 711/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9294\n",
            "Epoch 712/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9330\n",
            "Epoch 713/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9283\n",
            "Epoch 714/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9305\n",
            "Epoch 715/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9348\n",
            "Epoch 716/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9291\n",
            "Epoch 717/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1996 - accuracy: 0.9296\n",
            "Epoch 718/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9300\n",
            "Epoch 719/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9292\n",
            "Epoch 720/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2015 - accuracy: 0.9280\n",
            "Epoch 721/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1974 - accuracy: 0.9299\n",
            "Epoch 722/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9274\n",
            "Epoch 723/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9287\n",
            "Epoch 724/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9265\n",
            "Epoch 725/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9311\n",
            "Epoch 726/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9313\n",
            "Epoch 727/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9316\n",
            "Epoch 728/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9301\n",
            "Epoch 729/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9286\n",
            "Epoch 730/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1933 - accuracy: 0.9301\n",
            "Epoch 731/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9312\n",
            "Epoch 732/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9284\n",
            "Epoch 733/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9329\n",
            "Epoch 734/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9288\n",
            "Epoch 735/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2025 - accuracy: 0.9289\n",
            "Epoch 736/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9312\n",
            "Epoch 737/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9288\n",
            "Epoch 738/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1908 - accuracy: 0.9324\n",
            "Epoch 739/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9304\n",
            "Epoch 740/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9333\n",
            "Epoch 741/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9339\n",
            "Epoch 742/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9303\n",
            "Epoch 743/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9277\n",
            "Epoch 744/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9309\n",
            "Epoch 745/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1971 - accuracy: 0.9318\n",
            "Epoch 746/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9268\n",
            "Epoch 747/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9316\n",
            "Epoch 748/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9311\n",
            "Epoch 749/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9290\n",
            "Epoch 750/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9300\n",
            "Epoch 751/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9309\n",
            "Epoch 752/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9301\n",
            "Epoch 753/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9308\n",
            "Epoch 754/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9305\n",
            "Epoch 755/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9297\n",
            "Epoch 756/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9319\n",
            "Epoch 757/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9331\n",
            "Epoch 758/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9300\n",
            "Epoch 759/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9302\n",
            "Epoch 760/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9310\n",
            "Epoch 761/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9287\n",
            "Epoch 762/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9321\n",
            "Epoch 763/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9275\n",
            "Epoch 764/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9310\n",
            "Epoch 765/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9314\n",
            "Epoch 766/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9314\n",
            "Epoch 767/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1929 - accuracy: 0.9327\n",
            "Epoch 768/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9294\n",
            "Epoch 769/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9308\n",
            "Epoch 770/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9297\n",
            "Epoch 771/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.9292\n",
            "Epoch 772/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9332\n",
            "Epoch 773/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9291\n",
            "Epoch 774/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9295\n",
            "Epoch 775/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.9344\n",
            "Epoch 776/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9325\n",
            "Epoch 777/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9330\n",
            "Epoch 778/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9323\n",
            "Epoch 779/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1996 - accuracy: 0.9301\n",
            "Epoch 780/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9297\n",
            "Epoch 781/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9319\n",
            "Epoch 782/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9311\n",
            "Epoch 783/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9306\n",
            "Epoch 784/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.9317\n",
            "Epoch 785/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9326\n",
            "Epoch 786/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9343\n",
            "Epoch 787/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9316\n",
            "Epoch 788/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9315\n",
            "Epoch 789/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9294\n",
            "Epoch 790/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9292\n",
            "Epoch 791/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9290\n",
            "Epoch 792/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9332\n",
            "Epoch 793/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9315\n",
            "Epoch 794/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9326\n",
            "Epoch 795/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9296\n",
            "Epoch 796/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9321\n",
            "Epoch 797/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9308\n",
            "Epoch 798/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9354\n",
            "Epoch 799/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9342\n",
            "Epoch 800/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9335\n",
            "Epoch 801/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9330\n",
            "Epoch 802/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9332\n",
            "Epoch 803/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9311\n",
            "Epoch 804/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9327\n",
            "Epoch 805/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9311\n",
            "Epoch 806/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9330\n",
            "Epoch 807/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9302\n",
            "Epoch 808/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9308\n",
            "Epoch 809/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9321\n",
            "Epoch 810/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9317\n",
            "Epoch 811/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9330\n",
            "Epoch 812/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9317\n",
            "Epoch 813/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9345\n",
            "Epoch 814/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9298\n",
            "Epoch 815/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1911 - accuracy: 0.9341\n",
            "Epoch 816/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9309\n",
            "Epoch 817/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9318\n",
            "Epoch 818/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9325\n",
            "Epoch 819/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9303\n",
            "Epoch 820/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 0.9322\n",
            "Epoch 821/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9312\n",
            "Epoch 822/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9332\n",
            "Epoch 823/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9310\n",
            "Epoch 824/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1925 - accuracy: 0.9334\n",
            "Epoch 825/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9322\n",
            "Epoch 826/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1923 - accuracy: 0.9326\n",
            "Epoch 827/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9321\n",
            "Epoch 828/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9340\n",
            "Epoch 829/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9309\n",
            "Epoch 830/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9316\n",
            "Epoch 831/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.9291\n",
            "Epoch 832/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9337\n",
            "Epoch 833/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9312\n",
            "Epoch 834/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9288\n",
            "Epoch 835/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9313\n",
            "Epoch 836/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9341\n",
            "Epoch 837/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9290\n",
            "Epoch 838/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1977 - accuracy: 0.9307\n",
            "Epoch 839/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.9312\n",
            "Epoch 840/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9310\n",
            "Epoch 841/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9307\n",
            "Epoch 842/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9333\n",
            "Epoch 843/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9341\n",
            "Epoch 844/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9317\n",
            "Epoch 845/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9333\n",
            "Epoch 846/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9293\n",
            "Epoch 847/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.9346\n",
            "Epoch 848/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9315\n",
            "Epoch 849/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9331\n",
            "Epoch 850/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1931 - accuracy: 0.9335\n",
            "Epoch 851/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9300\n",
            "Epoch 852/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1903 - accuracy: 0.9330\n",
            "Epoch 853/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1886 - accuracy: 0.9353\n",
            "Epoch 854/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9329\n",
            "Epoch 855/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9306\n",
            "Epoch 856/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9339\n",
            "Epoch 857/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9345\n",
            "Epoch 858/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1859 - accuracy: 0.9347\n",
            "Epoch 859/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9324\n",
            "Epoch 860/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.9314\n",
            "Epoch 861/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.9332\n",
            "Epoch 862/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9319\n",
            "Epoch 863/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9293\n",
            "Epoch 864/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9318\n",
            "Epoch 865/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9345\n",
            "Epoch 866/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9301\n",
            "Epoch 867/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9324\n",
            "Epoch 868/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1817 - accuracy: 0.9385\n",
            "Epoch 869/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.9356\n",
            "Epoch 870/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9294\n",
            "Epoch 871/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9368\n",
            "Epoch 872/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9331\n",
            "Epoch 873/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9367\n",
            "Epoch 874/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9323\n",
            "Epoch 875/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9341\n",
            "Epoch 876/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9327\n",
            "Epoch 877/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9342\n",
            "Epoch 878/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9304\n",
            "Epoch 879/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9328\n",
            "Epoch 880/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1890 - accuracy: 0.9332\n",
            "Epoch 881/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9338\n",
            "Epoch 882/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9350\n",
            "Epoch 883/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9326\n",
            "Epoch 884/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1909 - accuracy: 0.9337\n",
            "Epoch 885/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9308\n",
            "Epoch 886/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9314\n",
            "Epoch 887/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9335\n",
            "Epoch 888/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9306\n",
            "Epoch 889/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9345\n",
            "Epoch 890/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9327\n",
            "Epoch 891/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1856 - accuracy: 0.9329\n",
            "Epoch 892/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9330\n",
            "Epoch 893/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9338\n",
            "Epoch 894/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9330\n",
            "Epoch 895/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1861 - accuracy: 0.9330\n",
            "Epoch 896/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9349\n",
            "Epoch 897/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.9341\n",
            "Epoch 898/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1867 - accuracy: 0.9330\n",
            "Epoch 899/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9324\n",
            "Epoch 900/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9320\n",
            "Epoch 901/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9338\n",
            "Epoch 902/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9327\n",
            "Epoch 903/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9341\n",
            "Epoch 904/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9320\n",
            "Epoch 905/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9324\n",
            "Epoch 906/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9329\n",
            "Epoch 907/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.9339\n",
            "Epoch 908/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9315\n",
            "Epoch 909/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1927 - accuracy: 0.9337\n",
            "Epoch 910/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9344\n",
            "Epoch 911/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9341\n",
            "Epoch 912/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.9343\n",
            "Epoch 913/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9327\n",
            "Epoch 914/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9359\n",
            "Epoch 915/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9361\n",
            "Epoch 916/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9309\n",
            "Epoch 917/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9364\n",
            "Epoch 918/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9354\n",
            "Epoch 919/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1884 - accuracy: 0.9326\n",
            "Epoch 920/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9319\n",
            "Epoch 921/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9353\n",
            "Epoch 922/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9351\n",
            "Epoch 923/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9356\n",
            "Epoch 924/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9331\n",
            "Epoch 925/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.9345\n",
            "Epoch 926/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9332\n",
            "Epoch 927/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.9363\n",
            "Epoch 928/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9352\n",
            "Epoch 929/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9356\n",
            "Epoch 930/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1870 - accuracy: 0.9353\n",
            "Epoch 931/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9315\n",
            "Epoch 932/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9350\n",
            "Epoch 933/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.9335\n",
            "Epoch 934/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9330\n",
            "Epoch 935/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.9339\n",
            "Epoch 936/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9315\n",
            "Epoch 937/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9337\n",
            "Epoch 938/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9351\n",
            "Epoch 939/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9341\n",
            "Epoch 940/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9343\n",
            "Epoch 941/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9337\n",
            "Epoch 942/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9354\n",
            "Epoch 943/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.9370\n",
            "Epoch 944/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9354\n",
            "Epoch 945/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9334\n",
            "Epoch 946/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9356\n",
            "Epoch 947/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.9345\n",
            "Epoch 948/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9346\n",
            "Epoch 949/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9331\n",
            "Epoch 950/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9364\n",
            "Epoch 951/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9354\n",
            "Epoch 952/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1892 - accuracy: 0.9324\n",
            "Epoch 953/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9343\n",
            "Epoch 954/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9362\n",
            "Epoch 955/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9347\n",
            "Epoch 956/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9337\n",
            "Epoch 957/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9341\n",
            "Epoch 958/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9351\n",
            "Epoch 959/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9365\n",
            "Epoch 960/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9331\n",
            "Epoch 961/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9339\n",
            "Epoch 962/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9319\n",
            "Epoch 963/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1929 - accuracy: 0.9329\n",
            "Epoch 964/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1904 - accuracy: 0.9329\n",
            "Epoch 965/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9361\n",
            "Epoch 966/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9338\n",
            "Epoch 967/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9368\n",
            "Epoch 968/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9342\n",
            "Epoch 969/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9365\n",
            "Epoch 970/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9334\n",
            "Epoch 971/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9379\n",
            "Epoch 972/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9359\n",
            "Epoch 973/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.9384\n",
            "Epoch 974/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9359\n",
            "Epoch 975/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9358\n",
            "Epoch 976/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9338\n",
            "Epoch 977/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9362\n",
            "Epoch 978/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1831 - accuracy: 0.9345\n",
            "Epoch 979/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9331\n",
            "Epoch 980/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9362\n",
            "Epoch 981/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1855 - accuracy: 0.9343\n",
            "Epoch 982/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9345\n",
            "Epoch 983/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9331\n",
            "Epoch 984/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9352\n",
            "Epoch 985/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.9341\n",
            "Epoch 986/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.9337\n",
            "Epoch 987/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9320\n",
            "Epoch 988/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1867 - accuracy: 0.9338\n",
            "Epoch 989/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1802 - accuracy: 0.9372\n",
            "Epoch 990/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9381\n",
            "Epoch 991/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9342\n",
            "Epoch 992/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9345\n",
            "Epoch 993/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1879 - accuracy: 0.9349\n",
            "Epoch 994/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9361\n",
            "Epoch 995/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9353\n",
            "Epoch 996/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9360\n",
            "Epoch 997/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1932 - accuracy: 0.9327\n",
            "Epoch 998/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.9364\n",
            "Epoch 999/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9400\n",
            "Epoch 1000/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHrPvAuYQwww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d37d4cf-2b22-4e0c-91a8-f70565eca31d"
      },
      "source": [
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "ypred=model.predict_classes(X_test)\n",
        "ypred=pd.get_dummies(ypred)\n",
        "\n",
        "print(classification_report(y_test[list(ypred.columns+1)],ypred ))\n",
        "accuracy_score(ypred,y_test[list(ypred.columns+1)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.92      0.80        83\n",
            "           1       0.91      0.74      0.81        80\n",
            "           2       1.00      0.98      0.99       191\n",
            "           3       1.00      1.00      1.00       203\n",
            "           4       0.91      0.86      0.88        93\n",
            "           5       0.97      0.96      0.97       190\n",
            "\n",
            "   micro avg       0.94      0.94      0.94       840\n",
            "   macro avg       0.91      0.91      0.91       840\n",
            "weighted avg       0.94      0.94      0.94       840\n",
            " samples avg       0.94      0.94      0.94       840\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9369047619047619"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IsI6gyUQsLQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9MkbN5pRGLC"
      },
      "source": [
        "##model3 (6) sigmoid adam , 1000, 512 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69pAw_WCRGLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb99a7c0-dbd1-45a9-8bf1-1642f0dedfcc"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(6, activation='sigmoid', input_shape = (X_train.shape[1],)))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_34 (Dense)             (None, 6)                 276       \n",
            "=================================================================\n",
            "Total params: 276\n",
            "Trainable params: 276\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh8VeiilRGLE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d481c85-474f-4b0b-d5a7-1a20ef63f370"
      },
      "source": [
        "history = model.fit(X_train_aug,\n",
        "                   y_train_aug,\n",
        "                   epochs=1000,\n",
        "                   batch_size=512,verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.3593 - accuracy: 0.1504\n",
            "Epoch 2/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.9777 - accuracy: 0.2034\n",
            "Epoch 3/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.7485 - accuracy: 0.2888\n",
            "Epoch 4/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.6281 - accuracy: 0.3677\n",
            "Epoch 5/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.5264 - accuracy: 0.4305\n",
            "Epoch 6/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.4686 - accuracy: 0.4735\n",
            "Epoch 7/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.4117 - accuracy: 0.5034\n",
            "Epoch 8/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.3721 - accuracy: 0.5264\n",
            "Epoch 9/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.3327 - accuracy: 0.5382\n",
            "Epoch 10/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.2972 - accuracy: 0.5599\n",
            "Epoch 11/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.2738 - accuracy: 0.5714\n",
            "Epoch 12/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.2452 - accuracy: 0.5805\n",
            "Epoch 13/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.2196 - accuracy: 0.5955\n",
            "Epoch 14/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.1913 - accuracy: 0.6093\n",
            "Epoch 15/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.1731 - accuracy: 0.6118\n",
            "Epoch 16/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.1553 - accuracy: 0.6191\n",
            "Epoch 17/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.1326 - accuracy: 0.6302\n",
            "Epoch 18/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.1235 - accuracy: 0.6308\n",
            "Epoch 19/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.0984 - accuracy: 0.6455\n",
            "Epoch 20/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.0827 - accuracy: 0.6442\n",
            "Epoch 21/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.0642 - accuracy: 0.6557\n",
            "Epoch 22/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.0559 - accuracy: 0.6517\n",
            "Epoch 23/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.0337 - accuracy: 0.6666\n",
            "Epoch 24/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.0249 - accuracy: 0.6620\n",
            "Epoch 25/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0088 - accuracy: 0.6667\n",
            "Epoch 26/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0011 - accuracy: 0.6738\n",
            "Epoch 27/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.9991 - accuracy: 0.6724\n",
            "Epoch 28/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.9845 - accuracy: 0.6662\n",
            "Epoch 29/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.9679 - accuracy: 0.6755\n",
            "Epoch 30/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9564 - accuracy: 0.6811\n",
            "Epoch 31/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9472 - accuracy: 0.6814\n",
            "Epoch 32/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.9423 - accuracy: 0.6818\n",
            "Epoch 33/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9301 - accuracy: 0.6843\n",
            "Epoch 34/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9202 - accuracy: 0.6884\n",
            "Epoch 35/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9165 - accuracy: 0.6850\n",
            "Epoch 36/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9098 - accuracy: 0.6881\n",
            "Epoch 37/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8964 - accuracy: 0.6890\n",
            "Epoch 38/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8927 - accuracy: 0.6919\n",
            "Epoch 39/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8889 - accuracy: 0.6924\n",
            "Epoch 40/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8774 - accuracy: 0.6952\n",
            "Epoch 41/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8720 - accuracy: 0.6962\n",
            "Epoch 42/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8676 - accuracy: 0.6965\n",
            "Epoch 43/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.8584 - accuracy: 0.6965\n",
            "Epoch 44/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.8502 - accuracy: 0.7002\n",
            "Epoch 45/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8418 - accuracy: 0.7051\n",
            "Epoch 46/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8398 - accuracy: 0.7003\n",
            "Epoch 47/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8388 - accuracy: 0.6991\n",
            "Epoch 48/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8266 - accuracy: 0.7026\n",
            "Epoch 49/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.8235 - accuracy: 0.7042\n",
            "Epoch 50/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.8188 - accuracy: 0.7034\n",
            "Epoch 51/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.8128 - accuracy: 0.7084\n",
            "Epoch 52/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7957 - accuracy: 0.7137\n",
            "Epoch 53/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7975 - accuracy: 0.7073\n",
            "Epoch 54/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7907 - accuracy: 0.7142\n",
            "Epoch 55/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7941 - accuracy: 0.7089\n",
            "Epoch 56/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7875 - accuracy: 0.7137\n",
            "Epoch 57/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7864 - accuracy: 0.7123\n",
            "Epoch 58/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7778 - accuracy: 0.7145\n",
            "Epoch 59/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7713 - accuracy: 0.7197\n",
            "Epoch 60/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7670 - accuracy: 0.7201\n",
            "Epoch 61/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7613 - accuracy: 0.7208\n",
            "Epoch 62/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7562 - accuracy: 0.7217\n",
            "Epoch 63/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7575 - accuracy: 0.7201\n",
            "Epoch 64/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7490 - accuracy: 0.7226\n",
            "Epoch 65/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7424 - accuracy: 0.7219\n",
            "Epoch 66/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7416 - accuracy: 0.7224\n",
            "Epoch 67/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7377 - accuracy: 0.7273\n",
            "Epoch 68/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7327 - accuracy: 0.7278\n",
            "Epoch 69/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7322 - accuracy: 0.7259\n",
            "Epoch 70/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.7296\n",
            "Epoch 71/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7269 - accuracy: 0.7302\n",
            "Epoch 72/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7170 - accuracy: 0.7323\n",
            "Epoch 73/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7201 - accuracy: 0.7312\n",
            "Epoch 74/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.7258\n",
            "Epoch 75/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.7364\n",
            "Epoch 76/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.7336\n",
            "Epoch 77/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.7336\n",
            "Epoch 78/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.7343\n",
            "Epoch 79/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7000 - accuracy: 0.7386\n",
            "Epoch 80/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.7379\n",
            "Epoch 81/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.7386\n",
            "Epoch 82/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7006 - accuracy: 0.7349\n",
            "Epoch 83/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.7425\n",
            "Epoch 84/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.7396\n",
            "Epoch 85/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.7437\n",
            "Epoch 86/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.7425\n",
            "Epoch 87/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6738 - accuracy: 0.7478\n",
            "Epoch 88/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.7388\n",
            "Epoch 89/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.7492\n",
            "Epoch 90/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.7531\n",
            "Epoch 91/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.7538\n",
            "Epoch 92/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.7451\n",
            "Epoch 93/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.7568\n",
            "Epoch 94/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6547 - accuracy: 0.7549\n",
            "Epoch 95/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.7499\n",
            "Epoch 96/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.7559\n",
            "Epoch 97/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.7538\n",
            "Epoch 98/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.7563\n",
            "Epoch 99/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.7529\n",
            "Epoch 100/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.7527\n",
            "Epoch 101/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.7576\n",
            "Epoch 102/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.7600\n",
            "Epoch 103/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.7595\n",
            "Epoch 104/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6356 - accuracy: 0.7620\n",
            "Epoch 105/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6445 - accuracy: 0.7570\n",
            "Epoch 106/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.7598\n",
            "Epoch 107/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6309 - accuracy: 0.7652\n",
            "Epoch 108/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.7620\n",
            "Epoch 109/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.7653\n",
            "Epoch 110/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.7664\n",
            "Epoch 111/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6298 - accuracy: 0.7616\n",
            "Epoch 112/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.7624\n",
            "Epoch 113/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.7716\n",
            "Epoch 114/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6219 - accuracy: 0.7624\n",
            "Epoch 115/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.7655\n",
            "Epoch 116/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.7649\n",
            "Epoch 117/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.7661\n",
            "Epoch 118/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6162 - accuracy: 0.7659\n",
            "Epoch 119/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.7743\n",
            "Epoch 120/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.7678\n",
            "Epoch 121/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.7727\n",
            "Epoch 122/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.7764\n",
            "Epoch 123/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6098 - accuracy: 0.7719\n",
            "Epoch 124/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.7719\n",
            "Epoch 125/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.7725\n",
            "Epoch 126/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.7731\n",
            "Epoch 127/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.7767\n",
            "Epoch 128/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.7782\n",
            "Epoch 129/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.7768\n",
            "Epoch 130/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.7777\n",
            "Epoch 131/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5959 - accuracy: 0.7747\n",
            "Epoch 132/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5959 - accuracy: 0.7761\n",
            "Epoch 133/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5863 - accuracy: 0.7820\n",
            "Epoch 134/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.7799\n",
            "Epoch 135/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7839\n",
            "Epoch 136/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7835\n",
            "Epoch 137/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7798\n",
            "Epoch 138/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.7854\n",
            "Epoch 139/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7880\n",
            "Epoch 140/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7883\n",
            "Epoch 141/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.7844\n",
            "Epoch 142/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7845\n",
            "Epoch 143/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.7817\n",
            "Epoch 144/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7850\n",
            "Epoch 145/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7885\n",
            "Epoch 146/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7892\n",
            "Epoch 147/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7858\n",
            "Epoch 148/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7838\n",
            "Epoch 149/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7902\n",
            "Epoch 150/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7895\n",
            "Epoch 151/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7897\n",
            "Epoch 152/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.7900\n",
            "Epoch 153/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7911\n",
            "Epoch 154/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7885\n",
            "Epoch 155/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7905\n",
            "Epoch 156/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7862\n",
            "Epoch 157/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5568 - accuracy: 0.7945\n",
            "Epoch 158/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7910\n",
            "Epoch 159/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7913\n",
            "Epoch 160/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7905\n",
            "Epoch 161/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5493 - accuracy: 0.7971\n",
            "Epoch 162/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7932\n",
            "Epoch 163/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7954\n",
            "Epoch 164/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7938\n",
            "Epoch 165/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7946\n",
            "Epoch 166/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7981\n",
            "Epoch 167/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5570 - accuracy: 0.7961\n",
            "Epoch 168/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7938\n",
            "Epoch 169/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7941\n",
            "Epoch 170/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7940\n",
            "Epoch 171/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7942\n",
            "Epoch 172/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7968\n",
            "Epoch 173/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5442 - accuracy: 0.7996\n",
            "Epoch 174/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.8007\n",
            "Epoch 175/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.8019\n",
            "Epoch 176/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.8033\n",
            "Epoch 177/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.8020\n",
            "Epoch 178/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.8054\n",
            "Epoch 179/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.8023\n",
            "Epoch 180/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.8032\n",
            "Epoch 181/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7993\n",
            "Epoch 182/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.8070\n",
            "Epoch 183/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.8053\n",
            "Epoch 184/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7989\n",
            "Epoch 185/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5400 - accuracy: 0.8042\n",
            "Epoch 186/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.8024\n",
            "Epoch 187/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.8004\n",
            "Epoch 188/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.8061\n",
            "Epoch 189/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5301 - accuracy: 0.8017\n",
            "Epoch 190/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.8034\n",
            "Epoch 191/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.8036\n",
            "Epoch 192/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.8035\n",
            "Epoch 193/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.8076\n",
            "Epoch 194/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.8069\n",
            "Epoch 195/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.8063\n",
            "Epoch 196/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.8116\n",
            "Epoch 197/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.8057\n",
            "Epoch 198/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7989\n",
            "Epoch 199/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.8069\n",
            "Epoch 200/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.8080\n",
            "Epoch 201/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.8064\n",
            "Epoch 202/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.8065\n",
            "Epoch 203/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.8101\n",
            "Epoch 204/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.8040\n",
            "Epoch 205/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.8086\n",
            "Epoch 206/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.8134\n",
            "Epoch 207/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.8097\n",
            "Epoch 208/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.8043\n",
            "Epoch 209/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5220 - accuracy: 0.8103\n",
            "Epoch 210/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.8143\n",
            "Epoch 211/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.8098\n",
            "Epoch 212/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.8070\n",
            "Epoch 213/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.8135\n",
            "Epoch 214/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.8082\n",
            "Epoch 215/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.8105\n",
            "Epoch 216/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.8081\n",
            "Epoch 217/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5221 - accuracy: 0.8060\n",
            "Epoch 218/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.8084\n",
            "Epoch 219/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.8096\n",
            "Epoch 220/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.8115\n",
            "Epoch 221/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.8108\n",
            "Epoch 222/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5075 - accuracy: 0.8125\n",
            "Epoch 223/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.8103\n",
            "Epoch 224/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.8150\n",
            "Epoch 225/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.8192\n",
            "Epoch 226/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.8126\n",
            "Epoch 227/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.8105\n",
            "Epoch 228/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.8087\n",
            "Epoch 229/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.8121\n",
            "Epoch 230/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.8120\n",
            "Epoch 231/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.8146\n",
            "Epoch 232/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8130\n",
            "Epoch 233/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.8137\n",
            "Epoch 234/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.8148\n",
            "Epoch 235/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.8110\n",
            "Epoch 236/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.8153\n",
            "Epoch 237/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.8148\n",
            "Epoch 238/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.8157\n",
            "Epoch 239/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.8156\n",
            "Epoch 240/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.8116\n",
            "Epoch 241/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.8198\n",
            "Epoch 242/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.8125\n",
            "Epoch 243/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.8119\n",
            "Epoch 244/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.8145\n",
            "Epoch 245/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.8149\n",
            "Epoch 246/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.8142\n",
            "Epoch 247/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8150\n",
            "Epoch 248/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8175\n",
            "Epoch 249/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.8160\n",
            "Epoch 250/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8188\n",
            "Epoch 251/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.8142\n",
            "Epoch 252/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.8188\n",
            "Epoch 253/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.8148\n",
            "Epoch 254/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.8149\n",
            "Epoch 255/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.8216\n",
            "Epoch 256/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.8190\n",
            "Epoch 257/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.8227\n",
            "Epoch 258/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.8165\n",
            "Epoch 259/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.8140\n",
            "Epoch 260/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.8188\n",
            "Epoch 261/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8150\n",
            "Epoch 262/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.8201\n",
            "Epoch 263/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8177\n",
            "Epoch 264/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8217\n",
            "Epoch 265/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.8193\n",
            "Epoch 266/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.8221\n",
            "Epoch 267/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8243\n",
            "Epoch 268/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8216\n",
            "Epoch 269/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.8184\n",
            "Epoch 270/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.8270\n",
            "Epoch 271/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.8186\n",
            "Epoch 272/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8243\n",
            "Epoch 273/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8204\n",
            "Epoch 274/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8190\n",
            "Epoch 275/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8250\n",
            "Epoch 276/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8224\n",
            "Epoch 277/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.8208\n",
            "Epoch 278/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8204\n",
            "Epoch 279/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.8202\n",
            "Epoch 280/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.8217\n",
            "Epoch 281/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.8184\n",
            "Epoch 282/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8231\n",
            "Epoch 283/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.8179\n",
            "Epoch 284/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.8218\n",
            "Epoch 285/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.8252\n",
            "Epoch 286/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.8225\n",
            "Epoch 287/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8236\n",
            "Epoch 288/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.8233\n",
            "Epoch 289/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.8180\n",
            "Epoch 290/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.8217\n",
            "Epoch 291/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.8208\n",
            "Epoch 292/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8274\n",
            "Epoch 293/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.8202\n",
            "Epoch 294/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.8266\n",
            "Epoch 295/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.8217\n",
            "Epoch 296/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.8208\n",
            "Epoch 297/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8274\n",
            "Epoch 298/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8239\n",
            "Epoch 299/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8246\n",
            "Epoch 300/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8234\n",
            "Epoch 301/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8234\n",
            "Epoch 302/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.8278\n",
            "Epoch 303/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8305\n",
            "Epoch 304/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8225\n",
            "Epoch 305/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.8236\n",
            "Epoch 306/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.8231\n",
            "Epoch 307/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8253\n",
            "Epoch 308/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8262\n",
            "Epoch 309/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8279\n",
            "Epoch 310/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.8269\n",
            "Epoch 311/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.8283\n",
            "Epoch 312/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8282\n",
            "Epoch 313/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8301\n",
            "Epoch 314/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8302\n",
            "Epoch 315/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.8225\n",
            "Epoch 316/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8257\n",
            "Epoch 317/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8291\n",
            "Epoch 318/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8300\n",
            "Epoch 319/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.8270\n",
            "Epoch 320/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.8300\n",
            "Epoch 321/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.8307\n",
            "Epoch 322/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8281\n",
            "Epoch 323/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.8217\n",
            "Epoch 324/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.8263\n",
            "Epoch 325/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8290\n",
            "Epoch 326/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.8328\n",
            "Epoch 327/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.8339\n",
            "Epoch 328/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8253\n",
            "Epoch 329/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8282\n",
            "Epoch 330/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8313\n",
            "Epoch 331/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8297\n",
            "Epoch 332/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8293\n",
            "Epoch 333/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8305\n",
            "Epoch 334/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8251\n",
            "Epoch 335/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.8295\n",
            "Epoch 336/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8260\n",
            "Epoch 337/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8300\n",
            "Epoch 338/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8312\n",
            "Epoch 339/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8320\n",
            "Epoch 340/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8332\n",
            "Epoch 341/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.8327\n",
            "Epoch 342/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8303\n",
            "Epoch 343/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8322\n",
            "Epoch 344/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8342\n",
            "Epoch 345/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.8325\n",
            "Epoch 346/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8303\n",
            "Epoch 347/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.8369\n",
            "Epoch 348/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8327\n",
            "Epoch 349/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8332\n",
            "Epoch 350/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8288\n",
            "Epoch 351/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8342\n",
            "Epoch 352/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.8338\n",
            "Epoch 353/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8289\n",
            "Epoch 354/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.8365\n",
            "Epoch 355/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8376\n",
            "Epoch 356/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8334\n",
            "Epoch 357/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8306\n",
            "Epoch 358/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8331\n",
            "Epoch 359/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8350\n",
            "Epoch 360/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8356\n",
            "Epoch 361/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8326\n",
            "Epoch 362/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8334\n",
            "Epoch 363/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8353\n",
            "Epoch 364/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8308\n",
            "Epoch 365/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.8323\n",
            "Epoch 366/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8370\n",
            "Epoch 367/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.8314\n",
            "Epoch 368/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8338\n",
            "Epoch 369/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8344\n",
            "Epoch 370/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8360\n",
            "Epoch 371/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.8306\n",
            "Epoch 372/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8357\n",
            "Epoch 373/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8337\n",
            "Epoch 374/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8357\n",
            "Epoch 375/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8361\n",
            "Epoch 376/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8332\n",
            "Epoch 377/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8339\n",
            "Epoch 378/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.8361\n",
            "Epoch 379/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8351\n",
            "Epoch 380/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8379\n",
            "Epoch 381/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8375\n",
            "Epoch 382/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8347\n",
            "Epoch 383/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8379\n",
            "Epoch 384/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8371\n",
            "Epoch 385/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8346\n",
            "Epoch 386/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8392\n",
            "Epoch 387/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8377\n",
            "Epoch 388/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8314\n",
            "Epoch 389/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8337\n",
            "Epoch 390/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8354\n",
            "Epoch 391/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8367\n",
            "Epoch 392/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8375\n",
            "Epoch 393/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8377\n",
            "Epoch 394/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.8392\n",
            "Epoch 395/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8316\n",
            "Epoch 396/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.8376\n",
            "Epoch 397/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8361\n",
            "Epoch 398/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8343\n",
            "Epoch 399/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8426\n",
            "Epoch 400/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8352\n",
            "Epoch 401/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8369\n",
            "Epoch 402/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.8332\n",
            "Epoch 403/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8381\n",
            "Epoch 404/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8390\n",
            "Epoch 405/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8346\n",
            "Epoch 406/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8332\n",
            "Epoch 407/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8408\n",
            "Epoch 408/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8410\n",
            "Epoch 409/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8413\n",
            "Epoch 410/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8372\n",
            "Epoch 411/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8375\n",
            "Epoch 412/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8324\n",
            "Epoch 413/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8383\n",
            "Epoch 414/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.8404\n",
            "Epoch 415/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8361\n",
            "Epoch 416/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8371\n",
            "Epoch 417/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8360\n",
            "Epoch 418/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8426\n",
            "Epoch 419/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8342\n",
            "Epoch 420/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8330\n",
            "Epoch 421/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8350\n",
            "Epoch 422/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8407\n",
            "Epoch 423/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8406\n",
            "Epoch 424/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8363\n",
            "Epoch 425/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8419\n",
            "Epoch 426/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8384\n",
            "Epoch 427/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8430\n",
            "Epoch 428/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8395\n",
            "Epoch 429/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8390\n",
            "Epoch 430/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8410\n",
            "Epoch 431/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8407\n",
            "Epoch 432/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8384\n",
            "Epoch 433/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.8383\n",
            "Epoch 434/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.8382\n",
            "Epoch 435/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8355\n",
            "Epoch 436/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8408\n",
            "Epoch 437/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8343\n",
            "Epoch 438/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8432\n",
            "Epoch 439/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8403\n",
            "Epoch 440/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8355\n",
            "Epoch 441/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8419\n",
            "Epoch 442/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8417\n",
            "Epoch 443/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8404\n",
            "Epoch 444/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8402\n",
            "Epoch 445/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8433\n",
            "Epoch 446/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8412\n",
            "Epoch 447/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8405\n",
            "Epoch 448/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.8407\n",
            "Epoch 449/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8370\n",
            "Epoch 450/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8438\n",
            "Epoch 451/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8356\n",
            "Epoch 452/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8423\n",
            "Epoch 453/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8449\n",
            "Epoch 454/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8380\n",
            "Epoch 455/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8432\n",
            "Epoch 456/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8393\n",
            "Epoch 457/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8420\n",
            "Epoch 458/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8373\n",
            "Epoch 459/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8417\n",
            "Epoch 460/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8425\n",
            "Epoch 461/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8439\n",
            "Epoch 462/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8431\n",
            "Epoch 463/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8380\n",
            "Epoch 464/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8402\n",
            "Epoch 465/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8351\n",
            "Epoch 466/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8357\n",
            "Epoch 467/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.8359\n",
            "Epoch 468/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8368\n",
            "Epoch 469/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.8479\n",
            "Epoch 470/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8424\n",
            "Epoch 471/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8387\n",
            "Epoch 472/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.8426\n",
            "Epoch 473/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8419\n",
            "Epoch 474/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8418\n",
            "Epoch 475/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8383\n",
            "Epoch 476/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8407\n",
            "Epoch 477/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8490\n",
            "Epoch 478/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8427\n",
            "Epoch 479/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8446\n",
            "Epoch 480/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8409\n",
            "Epoch 481/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8437\n",
            "Epoch 482/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8414\n",
            "Epoch 483/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8441\n",
            "Epoch 484/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8413\n",
            "Epoch 485/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8424\n",
            "Epoch 486/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8467\n",
            "Epoch 487/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.8432\n",
            "Epoch 488/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8452\n",
            "Epoch 489/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8437\n",
            "Epoch 490/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8435\n",
            "Epoch 491/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8410\n",
            "Epoch 492/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8465\n",
            "Epoch 493/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8417\n",
            "Epoch 494/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8432\n",
            "Epoch 495/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8448\n",
            "Epoch 496/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8464\n",
            "Epoch 497/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8453\n",
            "Epoch 498/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8442\n",
            "Epoch 499/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8400\n",
            "Epoch 500/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8440\n",
            "Epoch 501/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8411\n",
            "Epoch 502/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8439\n",
            "Epoch 503/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8450\n",
            "Epoch 504/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8474\n",
            "Epoch 505/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8418\n",
            "Epoch 506/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8472\n",
            "Epoch 507/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8420\n",
            "Epoch 508/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8480\n",
            "Epoch 509/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8481\n",
            "Epoch 510/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8454\n",
            "Epoch 511/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8408\n",
            "Epoch 512/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8491\n",
            "Epoch 513/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8458\n",
            "Epoch 514/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8455\n",
            "Epoch 515/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8443\n",
            "Epoch 516/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8450\n",
            "Epoch 517/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8429\n",
            "Epoch 518/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8409\n",
            "Epoch 519/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8483\n",
            "Epoch 520/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8457\n",
            "Epoch 521/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8448\n",
            "Epoch 522/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8417\n",
            "Epoch 523/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8427\n",
            "Epoch 524/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8419\n",
            "Epoch 525/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8446\n",
            "Epoch 526/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8448\n",
            "Epoch 527/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8434\n",
            "Epoch 528/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8450\n",
            "Epoch 529/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8424\n",
            "Epoch 530/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8464\n",
            "Epoch 531/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8475\n",
            "Epoch 532/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8469\n",
            "Epoch 533/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8494\n",
            "Epoch 534/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8406\n",
            "Epoch 535/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8450\n",
            "Epoch 536/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8488\n",
            "Epoch 537/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8472\n",
            "Epoch 538/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8429\n",
            "Epoch 539/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8430\n",
            "Epoch 540/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8440\n",
            "Epoch 541/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8444\n",
            "Epoch 542/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8456\n",
            "Epoch 543/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8436\n",
            "Epoch 544/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8429\n",
            "Epoch 545/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8480\n",
            "Epoch 546/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8454\n",
            "Epoch 547/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8491\n",
            "Epoch 548/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8474\n",
            "Epoch 549/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8480\n",
            "Epoch 550/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8483\n",
            "Epoch 551/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8463\n",
            "Epoch 552/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8428\n",
            "Epoch 553/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.8495\n",
            "Epoch 554/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8503\n",
            "Epoch 555/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8437\n",
            "Epoch 556/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8475\n",
            "Epoch 557/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8472\n",
            "Epoch 558/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.8424\n",
            "Epoch 559/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8464\n",
            "Epoch 560/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8492\n",
            "Epoch 561/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8467\n",
            "Epoch 562/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8482\n",
            "Epoch 563/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8469\n",
            "Epoch 564/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8493\n",
            "Epoch 565/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8458\n",
            "Epoch 566/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8503\n",
            "Epoch 567/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8428\n",
            "Epoch 568/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8442\n",
            "Epoch 569/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8485\n",
            "Epoch 570/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8479\n",
            "Epoch 571/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8462\n",
            "Epoch 572/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8523\n",
            "Epoch 573/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8485\n",
            "Epoch 574/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8489\n",
            "Epoch 575/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8465\n",
            "Epoch 576/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8481\n",
            "Epoch 577/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8473\n",
            "Epoch 578/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8490\n",
            "Epoch 579/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8493\n",
            "Epoch 580/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8463\n",
            "Epoch 581/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8494\n",
            "Epoch 582/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8479\n",
            "Epoch 583/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8494\n",
            "Epoch 584/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8446\n",
            "Epoch 585/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8493\n",
            "Epoch 586/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8532\n",
            "Epoch 587/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8469\n",
            "Epoch 588/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8481\n",
            "Epoch 589/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8434\n",
            "Epoch 590/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8475\n",
            "Epoch 591/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8489\n",
            "Epoch 592/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8508\n",
            "Epoch 593/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8525\n",
            "Epoch 594/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8505\n",
            "Epoch 595/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8495\n",
            "Epoch 596/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8534\n",
            "Epoch 597/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8500\n",
            "Epoch 598/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8460\n",
            "Epoch 599/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8506\n",
            "Epoch 600/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8521\n",
            "Epoch 601/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8485\n",
            "Epoch 602/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8516\n",
            "Epoch 603/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8479\n",
            "Epoch 604/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8509\n",
            "Epoch 605/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8521\n",
            "Epoch 606/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8503\n",
            "Epoch 607/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8452\n",
            "Epoch 608/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8522\n",
            "Epoch 609/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8547\n",
            "Epoch 610/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8489\n",
            "Epoch 611/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8501\n",
            "Epoch 612/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8464\n",
            "Epoch 613/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8458\n",
            "Epoch 614/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8516\n",
            "Epoch 615/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8526\n",
            "Epoch 616/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8469\n",
            "Epoch 617/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8540\n",
            "Epoch 618/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8495\n",
            "Epoch 619/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8528\n",
            "Epoch 620/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8498\n",
            "Epoch 621/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8485\n",
            "Epoch 622/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8505\n",
            "Epoch 623/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8480\n",
            "Epoch 624/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8524\n",
            "Epoch 625/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8483\n",
            "Epoch 626/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8504\n",
            "Epoch 627/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8486\n",
            "Epoch 628/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8470\n",
            "Epoch 629/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8519\n",
            "Epoch 630/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8497\n",
            "Epoch 631/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8509\n",
            "Epoch 632/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8485\n",
            "Epoch 633/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8518\n",
            "Epoch 634/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4157 - accuracy: 0.8498\n",
            "Epoch 635/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8523\n",
            "Epoch 636/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8507\n",
            "Epoch 637/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8510\n",
            "Epoch 638/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8492\n",
            "Epoch 639/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8512\n",
            "Epoch 640/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8510\n",
            "Epoch 641/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8527\n",
            "Epoch 642/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8470\n",
            "Epoch 643/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8473\n",
            "Epoch 644/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8530\n",
            "Epoch 645/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8533\n",
            "Epoch 646/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8501\n",
            "Epoch 647/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8513\n",
            "Epoch 648/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8501\n",
            "Epoch 649/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8519\n",
            "Epoch 650/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8540\n",
            "Epoch 651/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8530\n",
            "Epoch 652/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8524\n",
            "Epoch 653/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8517\n",
            "Epoch 654/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8552\n",
            "Epoch 655/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8533\n",
            "Epoch 656/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8536\n",
            "Epoch 657/1000\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.8496\n",
            "Epoch 658/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8508\n",
            "Epoch 659/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8515\n",
            "Epoch 660/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8500\n",
            "Epoch 661/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8536\n",
            "Epoch 662/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8438\n",
            "Epoch 663/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8516\n",
            "Epoch 664/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8562\n",
            "Epoch 665/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8479\n",
            "Epoch 666/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8502\n",
            "Epoch 667/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8536\n",
            "Epoch 668/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8510\n",
            "Epoch 669/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8537\n",
            "Epoch 670/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8526\n",
            "Epoch 671/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8495\n",
            "Epoch 672/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8500\n",
            "Epoch 673/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8570\n",
            "Epoch 674/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8549\n",
            "Epoch 675/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8536\n",
            "Epoch 676/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8495\n",
            "Epoch 677/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8492\n",
            "Epoch 678/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8528\n",
            "Epoch 679/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8528\n",
            "Epoch 680/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8520\n",
            "Epoch 681/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8552\n",
            "Epoch 682/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8556\n",
            "Epoch 683/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8566\n",
            "Epoch 684/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8545\n",
            "Epoch 685/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8504\n",
            "Epoch 686/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8507\n",
            "Epoch 687/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8591\n",
            "Epoch 688/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8552\n",
            "Epoch 689/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8498\n",
            "Epoch 690/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8494\n",
            "Epoch 691/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8523\n",
            "Epoch 692/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8529\n",
            "Epoch 693/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8557\n",
            "Epoch 694/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8527\n",
            "Epoch 695/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8511\n",
            "Epoch 696/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8537\n",
            "Epoch 697/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8542\n",
            "Epoch 698/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8552\n",
            "Epoch 699/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8524\n",
            "Epoch 700/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8541\n",
            "Epoch 701/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8542\n",
            "Epoch 702/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8587\n",
            "Epoch 703/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8526\n",
            "Epoch 704/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8537\n",
            "Epoch 705/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8540\n",
            "Epoch 706/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8545\n",
            "Epoch 707/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8529\n",
            "Epoch 708/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8535\n",
            "Epoch 709/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8576\n",
            "Epoch 710/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8576\n",
            "Epoch 711/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8527\n",
            "Epoch 712/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8554\n",
            "Epoch 713/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8554\n",
            "Epoch 714/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8587\n",
            "Epoch 715/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8569\n",
            "Epoch 716/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8519\n",
            "Epoch 717/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8558\n",
            "Epoch 718/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8501\n",
            "Epoch 719/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8550\n",
            "Epoch 720/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8552\n",
            "Epoch 721/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8551\n",
            "Epoch 722/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8569\n",
            "Epoch 723/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8562\n",
            "Epoch 724/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8554\n",
            "Epoch 725/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8560\n",
            "Epoch 726/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8559\n",
            "Epoch 727/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8561\n",
            "Epoch 728/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8567\n",
            "Epoch 729/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8588\n",
            "Epoch 730/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8615\n",
            "Epoch 731/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8565\n",
            "Epoch 732/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8546\n",
            "Epoch 733/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8550\n",
            "Epoch 734/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8612\n",
            "Epoch 735/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8592\n",
            "Epoch 736/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8580\n",
            "Epoch 737/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8590\n",
            "Epoch 738/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8552\n",
            "Epoch 739/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8571\n",
            "Epoch 740/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8572\n",
            "Epoch 741/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8570\n",
            "Epoch 742/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8568\n",
            "Epoch 743/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8527\n",
            "Epoch 744/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8552\n",
            "Epoch 745/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8569\n",
            "Epoch 746/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8497\n",
            "Epoch 747/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8562\n",
            "Epoch 748/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8510\n",
            "Epoch 749/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8577\n",
            "Epoch 750/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8596\n",
            "Epoch 751/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8594\n",
            "Epoch 752/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8537\n",
            "Epoch 753/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8544\n",
            "Epoch 754/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8553\n",
            "Epoch 755/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8562\n",
            "Epoch 756/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8536\n",
            "Epoch 757/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8567\n",
            "Epoch 758/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8594\n",
            "Epoch 759/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8586\n",
            "Epoch 760/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8546\n",
            "Epoch 761/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8554\n",
            "Epoch 762/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8531\n",
            "Epoch 763/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8551\n",
            "Epoch 764/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8541\n",
            "Epoch 765/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8532\n",
            "Epoch 766/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8547\n",
            "Epoch 767/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8571\n",
            "Epoch 768/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8550\n",
            "Epoch 769/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8558\n",
            "Epoch 770/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8562\n",
            "Epoch 771/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8574\n",
            "Epoch 772/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8546\n",
            "Epoch 773/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8548\n",
            "Epoch 774/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8552\n",
            "Epoch 775/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8609\n",
            "Epoch 776/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8562\n",
            "Epoch 777/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8583\n",
            "Epoch 778/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8556\n",
            "Epoch 779/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8588\n",
            "Epoch 780/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8577\n",
            "Epoch 781/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8532\n",
            "Epoch 782/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8601\n",
            "Epoch 783/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8571\n",
            "Epoch 784/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8555\n",
            "Epoch 785/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8598\n",
            "Epoch 786/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8580\n",
            "Epoch 787/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8592\n",
            "Epoch 788/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8559\n",
            "Epoch 789/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8525\n",
            "Epoch 790/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8569\n",
            "Epoch 791/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8541\n",
            "Epoch 792/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8567\n",
            "Epoch 793/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8627\n",
            "Epoch 794/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8587\n",
            "Epoch 795/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8557\n",
            "Epoch 796/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8584\n",
            "Epoch 797/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8586\n",
            "Epoch 798/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8545\n",
            "Epoch 799/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8538\n",
            "Epoch 800/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8562\n",
            "Epoch 801/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8603\n",
            "Epoch 802/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8494\n",
            "Epoch 803/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8569\n",
            "Epoch 804/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8607\n",
            "Epoch 805/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8595\n",
            "Epoch 806/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8559\n",
            "Epoch 807/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8582\n",
            "Epoch 808/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8588\n",
            "Epoch 809/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8592\n",
            "Epoch 810/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8620\n",
            "Epoch 811/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8619\n",
            "Epoch 812/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8603\n",
            "Epoch 813/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8579\n",
            "Epoch 814/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8578\n",
            "Epoch 815/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8565\n",
            "Epoch 816/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8562\n",
            "Epoch 817/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8579\n",
            "Epoch 818/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8569\n",
            "Epoch 819/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8595\n",
            "Epoch 820/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8603\n",
            "Epoch 821/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8574\n",
            "Epoch 822/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8622\n",
            "Epoch 823/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8588\n",
            "Epoch 824/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8564\n",
            "Epoch 825/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8586\n",
            "Epoch 826/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8565\n",
            "Epoch 827/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8561\n",
            "Epoch 828/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8564\n",
            "Epoch 829/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8561\n",
            "Epoch 830/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8592\n",
            "Epoch 831/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8576\n",
            "Epoch 832/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8595\n",
            "Epoch 833/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8582\n",
            "Epoch 834/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8565\n",
            "Epoch 835/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8584\n",
            "Epoch 836/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8594\n",
            "Epoch 837/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8597\n",
            "Epoch 838/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8595\n",
            "Epoch 839/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8587\n",
            "Epoch 840/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8581\n",
            "Epoch 841/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8594\n",
            "Epoch 842/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8643\n",
            "Epoch 843/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8597\n",
            "Epoch 844/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8576\n",
            "Epoch 845/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8534\n",
            "Epoch 846/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8571\n",
            "Epoch 847/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8636\n",
            "Epoch 848/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8654\n",
            "Epoch 849/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8582\n",
            "Epoch 850/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8610\n",
            "Epoch 851/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8575\n",
            "Epoch 852/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8582\n",
            "Epoch 853/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8605\n",
            "Epoch 854/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8623\n",
            "Epoch 855/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8579\n",
            "Epoch 856/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8590\n",
            "Epoch 857/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8605\n",
            "Epoch 858/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8634\n",
            "Epoch 859/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8608\n",
            "Epoch 860/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8625\n",
            "Epoch 861/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8587\n",
            "Epoch 862/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8579\n",
            "Epoch 863/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8591\n",
            "Epoch 864/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8580\n",
            "Epoch 865/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8535\n",
            "Epoch 866/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8569\n",
            "Epoch 867/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8592\n",
            "Epoch 868/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8649\n",
            "Epoch 869/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8594\n",
            "Epoch 870/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8609\n",
            "Epoch 871/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8599\n",
            "Epoch 872/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8561\n",
            "Epoch 873/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8580\n",
            "Epoch 874/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8629\n",
            "Epoch 875/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8593\n",
            "Epoch 876/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8583\n",
            "Epoch 877/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8615\n",
            "Epoch 878/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8605\n",
            "Epoch 879/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8575\n",
            "Epoch 880/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8612\n",
            "Epoch 881/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8595\n",
            "Epoch 882/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8606\n",
            "Epoch 883/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8594\n",
            "Epoch 884/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8577\n",
            "Epoch 885/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8619\n",
            "Epoch 886/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8627\n",
            "Epoch 887/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8583\n",
            "Epoch 888/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8614\n",
            "Epoch 889/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8633\n",
            "Epoch 890/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8613\n",
            "Epoch 891/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8642\n",
            "Epoch 892/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8570\n",
            "Epoch 893/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8633\n",
            "Epoch 894/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8604\n",
            "Epoch 895/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8636\n",
            "Epoch 896/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8634\n",
            "Epoch 897/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8597\n",
            "Epoch 898/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8599\n",
            "Epoch 899/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8561\n",
            "Epoch 900/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8639\n",
            "Epoch 901/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8628\n",
            "Epoch 902/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8624\n",
            "Epoch 903/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8576\n",
            "Epoch 904/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8640\n",
            "Epoch 905/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8611\n",
            "Epoch 906/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8607\n",
            "Epoch 907/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8616\n",
            "Epoch 908/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8601\n",
            "Epoch 909/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8576\n",
            "Epoch 910/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8629\n",
            "Epoch 911/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8623\n",
            "Epoch 912/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8705\n",
            "Epoch 913/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8597\n",
            "Epoch 914/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8610\n",
            "Epoch 915/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8584\n",
            "Epoch 916/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8622\n",
            "Epoch 917/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8573\n",
            "Epoch 918/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8641\n",
            "Epoch 919/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8649\n",
            "Epoch 920/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8620\n",
            "Epoch 921/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8670\n",
            "Epoch 922/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8612\n",
            "Epoch 923/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8646\n",
            "Epoch 924/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8600\n",
            "Epoch 925/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8592\n",
            "Epoch 926/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8613\n",
            "Epoch 927/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8590\n",
            "Epoch 928/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8636\n",
            "Epoch 929/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8631\n",
            "Epoch 930/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8612\n",
            "Epoch 931/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8618\n",
            "Epoch 932/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8593\n",
            "Epoch 933/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8569\n",
            "Epoch 934/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8594\n",
            "Epoch 935/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8604\n",
            "Epoch 936/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8603\n",
            "Epoch 937/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8616\n",
            "Epoch 938/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8627\n",
            "Epoch 939/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8664\n",
            "Epoch 940/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8611\n",
            "Epoch 941/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8603\n",
            "Epoch 942/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8624\n",
            "Epoch 943/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8574\n",
            "Epoch 944/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8624\n",
            "Epoch 945/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8630\n",
            "Epoch 946/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8612\n",
            "Epoch 947/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8672\n",
            "Epoch 948/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8616\n",
            "Epoch 949/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8603\n",
            "Epoch 950/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8579\n",
            "Epoch 951/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8591\n",
            "Epoch 952/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8660\n",
            "Epoch 953/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8635\n",
            "Epoch 954/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8609\n",
            "Epoch 955/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8626\n",
            "Epoch 956/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8633\n",
            "Epoch 957/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8595\n",
            "Epoch 958/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8675\n",
            "Epoch 959/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8588\n",
            "Epoch 960/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8592\n",
            "Epoch 961/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8628\n",
            "Epoch 962/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8635\n",
            "Epoch 963/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8669\n",
            "Epoch 964/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8629\n",
            "Epoch 965/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8628\n",
            "Epoch 966/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8585\n",
            "Epoch 967/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8626\n",
            "Epoch 968/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8659\n",
            "Epoch 969/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8648\n",
            "Epoch 970/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8639\n",
            "Epoch 971/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8590\n",
            "Epoch 972/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8594\n",
            "Epoch 973/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8590\n",
            "Epoch 974/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8629\n",
            "Epoch 975/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8610\n",
            "Epoch 976/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8654\n",
            "Epoch 977/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8643\n",
            "Epoch 978/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8632\n",
            "Epoch 979/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8637\n",
            "Epoch 980/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8639\n",
            "Epoch 981/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8669\n",
            "Epoch 982/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8586\n",
            "Epoch 983/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8642\n",
            "Epoch 984/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8646\n",
            "Epoch 985/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8687\n",
            "Epoch 986/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8646\n",
            "Epoch 987/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8645\n",
            "Epoch 988/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8585\n",
            "Epoch 989/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8647\n",
            "Epoch 990/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8646\n",
            "Epoch 991/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8653\n",
            "Epoch 992/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8641\n",
            "Epoch 993/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8666\n",
            "Epoch 994/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8618\n",
            "Epoch 995/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8637\n",
            "Epoch 996/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8623\n",
            "Epoch 997/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8604\n",
            "Epoch 998/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8583\n",
            "Epoch 999/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8634\n",
            "Epoch 1000/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EEgj71oRGLE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b0aab11-955d-4478-cd87-aef274c90be7"
      },
      "source": [
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "ypred=model.predict_classes(X_test)\n",
        "ypred=pd.get_dummies(ypred)\n",
        "\n",
        "print(classification_report(y_test[list(ypred.columns+1)],ypred ))\n",
        "accuracy_score(ypred,y_test[list(ypred.columns+1)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.86      0.89        83\n",
            "           1       0.97      0.95      0.96        80\n",
            "           2       0.96      0.85      0.91       191\n",
            "           3       0.89      0.96      0.92       203\n",
            "           4       0.88      0.96      0.92        93\n",
            "           5       0.96      0.99      0.97       190\n",
            "\n",
            "   micro avg       0.93      0.93      0.93       840\n",
            "   macro avg       0.93      0.93      0.93       840\n",
            "weighted avg       0.93      0.93      0.93       840\n",
            " samples avg       0.93      0.93      0.93       840\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.930952380952381"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiMnzoYGRWDH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suzd-oWPNSaV"
      },
      "source": [
        "#compare models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmP1ZrrDMyq7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}